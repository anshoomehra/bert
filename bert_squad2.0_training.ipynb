{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:navy\"> <center>Bert Learning SQUAD 2.0 Training</center> </span>\n",
    "\n",
    "####  <span style=\"color:navy\"> <center>Anshoo Mehra</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# <span style=\"color:navy\"> Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. [Python Libraries](#py_libs)\n",
    "2. [Data Exploration, Study & Statistics](#data_study)\n",
    "3. [Training Data Preparation](#training_data_prep)\n",
    "4. [Model Architecture & Training](#model_arch_trng)\n",
    "5. [Evaluation Metrics](#eval_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# <span style=\"color:navy\"> Import & Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#!pip install bert-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#!pip install modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anmehra/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0502 00:51:49.998626 140153102087936 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import collections\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import modeling\n",
    "import optimization\n",
    "import tokenization\n",
    "import six\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow_hub as hub\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/anmehra/code/bert'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#os.chdir('models')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "repo = 'models/model_repo'\n",
    "squad_dir = 'squad'\n",
    "tpu_name = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# <span style=\"color:navy\"> Download Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#downloading weights and cofiguration file for the model\n",
    "#!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
    "#!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-24_H-1024_A-16.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# with zipfile.ZipFile(\"uncased_L-12_H-768_A-12.zip\",\"r\") as zip_ref:\n",
    "#     zip_ref.extractall(repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# with zipfile.ZipFile(\"uncased_L-24_H-1024_A-16.zip\",\"r\") as zip_ref:\n",
    "#     zip_ref.extractall(repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 422M\r\n",
      "-rw-rw-r-- 1 anmehra anmehra 884K Apr 30 01:28 bert_model.ckpt.meta\r\n",
      "-rw-rw-r-- 1 anmehra anmehra 227K Apr 30 01:28 vocab.txt\r\n",
      "-rw-rw-r-- 1 anmehra anmehra 8.4K Apr 30 01:28 bert_model.ckpt.index\r\n",
      "-rw-rw-r-- 1 anmehra anmehra 421M Apr 30 01:28 bert_model.ckpt.data-00000-of-00001\r\n",
      "-rw-rw-r-- 1 anmehra anmehra  313 Apr 30 01:28 bert_config.json\r\n"
     ]
    }
   ],
   "source": [
    "#check listings\n",
    "!ls -lhrt '{repo}/uncased_L-12_H-768_A-12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1.3G\r\n",
      "-rw-rw-r-- 1 anmehra anmehra 1.8M Apr 30 01:28 bert_model.ckpt.meta\r\n",
      "-rw-rw-r-- 1 anmehra anmehra 227K Apr 30 01:28 vocab.txt\r\n",
      "-rw-rw-r-- 1 anmehra anmehra  17K Apr 30 01:28 bert_model.ckpt.index\r\n",
      "-rw-rw-r-- 1 anmehra anmehra 1.3G Apr 30 01:28 bert_model.ckpt.data-00000-of-00001\r\n",
      "-rw-rw-r-- 1 anmehra anmehra  314 Apr 30 01:28 bert_config.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lhrt '{repo}/uncased_L-24_H-1024_A-16'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:navy\"> Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### <span style=\"color:navy\"> Step 1 - Define & Initilaize Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ! python run_squad.py \\\n",
    "#   --vocab_file=models/model_repo/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "#   --bert_config_file=models/model_repo/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "#   --init_checkpoint=models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt \\\n",
    "#   --do_train=True \\\n",
    "#   --train_file=squad/train-v2.0.json \\\n",
    "#   --do_predict=True \\\n",
    "#   --predict_file=squad/dev-v2.0.json \\\n",
    "#   --train_batch_size=12 \\\n",
    "#   --learning_rate=3e-5 \\\n",
    "#   --num_train_epochs=2.0 \\\n",
    "#   --max_seq_length=384 \\\n",
    "#   --doc_stride=128 \\\n",
    "#   --output_dir=squad/output \\\n",
    "#   --use_tpu=False \\\n",
    "#   --tpu_name=None \\\n",
    "#   --version_2_with_negative=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"exact\": 72.87964288722311,\r\n",
      "  \"f1\": 76.19652536434309,\r\n",
      "  \"total\": 11873,\r\n",
      "  \"HasAns_exact\": 73.22874493927125,\r\n",
      "  \"HasAns_f1\": 79.87202187092528,\r\n",
      "  \"HasAns_total\": 5928,\r\n",
      "  \"NoAns_exact\": 72.53153910849453,\r\n",
      "  \"NoAns_f1\": 72.53153910849453,\r\n",
      "  \"NoAns_total\": 5945,\r\n",
      "  \"best_exact\": 74.09247873326034,\r\n",
      "  \"best_exact_thresh\": -2.9248909950256348,\r\n",
      "  \"best_f1\": 76.98832933205624,\r\n",
      "  \"best_f1_thresh\": -2.9248909950256348\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "! python squad/evaluate-v2.0.py squad/dev-v2.0.json squad/output/predictions.json --na-prob-file squad/output/null_odds.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Predit Step - Fails all the time, with \n",
    "\n",
    "Traceback (most recent call last):\n",
    "  File \"run_squad.py\", line 1283, in <module>\n",
    "    tf.app.run()\n",
    "  File \"/home/anmehra/anaconda3/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 125, in run\n",
    "    _sys.exit(main(argv))\n",
    "  File \"run_squad.py\", line 1276, in main\n",
    "    output_nbest_file, output_null_log_odds_file)\n",
    "  File \"run_squad.py\", line 906, in write_predictions\n",
    "    score_diff = score_null - best_non_null_entry.start_logit - (\n",
    "AttributeError: 'NoneType' object has no attribute 'start_logit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ! python run_squad.py \\\n",
    "#   --vocab_file=models/model_repo/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "#   --bert_config_file=models/model_repo/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "#   --init_checkpoint=models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt \\\n",
    "#   --do_train=False \\\n",
    "#   --train_file=squad/train-v2.0.json \\\n",
    "#   --do_predict=True \\\n",
    "#   --predict_file=squad/dev-v2.0.json \\\n",
    "#   --train_batch_size=12 \\\n",
    "#   --learning_rate=3e-5 \\\n",
    "#   --num_train_epochs=2.0 \\\n",
    "#   --max_seq_length=384 \\\n",
    "#   --doc_stride=128 \\\n",
    "#   --output_dir=squad/output/best \\\n",
    "#   --use_tpu=False \\\n",
    "#   --tpu_name=None \\\n",
    "#   --version_2_with_negative=True \\\n",
    "#   --null_score_diff_threshold=-2.9248909950256348"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### OPTMIZED FOR GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_vocab_file =  f'{repo}/uncased_L-12_H-768_A-12/vocab.txt'\n",
    "_bert_config_file = f'{repo}/uncased_L-12_H-768_A-12/bert_config.json'\n",
    "_init_checkpoint = f'{repo}/uncased_L-12_H-768_A-12/bert_model.ckpt'\n",
    "_do_train = True\n",
    "_train_file = f'{squad_dir}/train-v2.0.json'\n",
    "_do_predict = True\n",
    "_predict_file = f'{squad_dir}/dev-v2.0.json'\n",
    "_train_batch_size = 12 #24 -- TPU\n",
    "_predict_batch_size = 8\n",
    "_learning_rate = 3e-5 #5e-5\n",
    "_num_train_epochs = 2.0 #3.0\n",
    "_max_seq_length = 384\n",
    "_doc_stride = 128\n",
    "_output_dir = f'{squad_dir}/output/jupyter'\n",
    "_use_tpu = False\n",
    "_tpu_name = f'{tpu_name}'\n",
    "_tpu_zone = None\n",
    "_version_2_with_negative = True #False\n",
    "_do_lower_case = True\n",
    "_max_query_length = 64\n",
    "_warmup_proportion = 0.1\n",
    "_save_checkpoints_steps = 1000\n",
    "_iterations_per_loop = 1000\n",
    "_n_best_size = 20\n",
    "_max_answer_length = 30\n",
    "_gcp_project = None\n",
    "_num_tpu_cores = 8\n",
    "_null_score_diff_threshold = 0.0\n",
    "_master = None\n",
    "_verbose_logging = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "####Delete all flags before declare#####\n",
    "\n",
    "# def del_all_flags(FLAGS):\n",
    "#     flags_dict = FLAGS._flags()    \n",
    "#     keys_list = [keys for keys in flags_dict]    \n",
    "#     for keys in keys_list:\n",
    "#         FLAGS.__delattr__(keys)\n",
    "\n",
    "# del_all_flags(tf.flags.FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "flags = tf.flags\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "# Required parameters\n",
    "flags.DEFINE_string(\n",
    "    \"bert_config_file\", _bert_config_file,\n",
    "    \"The config json file corresponding to the pre-trained BERT model. \"\n",
    "    \"This specifies the model architecture.\")\n",
    "\n",
    "flags.DEFINE_string(\"vocab_file\", _vocab_file,\n",
    "                    \"The vocabulary file that the BERT model was trained on.\")\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"output_dir\", _output_dir,\n",
    "    \"The output directory where the model checkpoints will be written.\")\n",
    "\n",
    "## Other parameters\n",
    "flags.DEFINE_string(\"train_file\", _train_file,\n",
    "                    \"SQuAD json for training. E.g., train-v1.1.json\")\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"predict_file\", _predict_file,\n",
    "    \"SQuAD json for predictions. E.g., dev-v1.1.json or test-v1.1.json\")\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"init_checkpoint\", _init_checkpoint,\n",
    "    \"Initial checkpoint (usually from a pre-trained BERT model).\")\n",
    "\n",
    "flags.DEFINE_bool(\n",
    "    \"do_lower_case\", _do_lower_case,\n",
    "    \"Whether to lower case the input text. Should be True for uncased \"\n",
    "    \"models and False for cased models.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"max_seq_length\", _max_seq_length,\n",
    "    \"The maximum total input sequence length after WordPiece tokenization. \"\n",
    "    \"Sequences longer than this will be truncated, and sequences shorter \"\n",
    "    \"than this will be padded.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"doc_stride\", _doc_stride,\n",
    "    \"When splitting up a long document into chunks, how much stride to \"\n",
    "    \"take between chunks.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"max_query_length\", _max_query_length,\n",
    "    \"The maximum number of tokens for the question. Questions longer than \"\n",
    "    \"this will be truncated to this length.\")\n",
    "\n",
    "flags.DEFINE_bool(\"do_train\", _do_train, \"Whether to run training.\")\n",
    "\n",
    "flags.DEFINE_bool(\"do_predict\", _do_predict, \"Whether to run eval on the dev set.\")\n",
    "\n",
    "flags.DEFINE_integer(\"train_batch_size\", _train_batch_size, \"Total batch size for training.\")\n",
    "\n",
    "flags.DEFINE_integer(\"predict_batch_size\", _predict_batch_size,\n",
    "                     \"Total batch size for predictions.\")\n",
    "\n",
    "flags.DEFINE_float(\"learning_rate\", _learning_rate, \"The initial learning rate for Adam.\")\n",
    "\n",
    "flags.DEFINE_float(\"num_train_epochs\", _num_train_epochs,\n",
    "                   \"Total number of training epochs to perform.\")\n",
    "\n",
    "flags.DEFINE_float(\n",
    "    \"warmup_proportion\", _warmup_proportion,\n",
    "    \"Proportion of training to perform linear learning rate warmup for. \"\n",
    "    \"E.g., 0.1 = 10% of training.\")\n",
    "\n",
    "flags.DEFINE_integer(\"save_checkpoints_steps\", _save_checkpoints_steps,\n",
    "                     \"How often to save the model checkpoint.\")\n",
    "\n",
    "flags.DEFINE_integer(\"iterations_per_loop\", _iterations_per_loop,\n",
    "                     \"How many steps to make in each estimator call.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"n_best_size\", _n_best_size,\n",
    "    \"The total number of n-best predictions to generate in the \"\n",
    "    \"nbest_predictions.json output file.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"max_answer_length\", _max_answer_length,\n",
    "    \"The maximum length of an answer that can be generated. This is needed \"\n",
    "    \"because the start and end predictions are not conditioned on one another.\")\n",
    "\n",
    "flags.DEFINE_bool(\"use_tpu\", _use_tpu, \"Whether to use TPU or GPU/CPU.\")\n",
    "\n",
    "tf.flags.DEFINE_string(\n",
    "    \"tpu_name\", _tpu_name,\n",
    "    \"The Cloud TPU to use for training. This should be either the name \"\n",
    "    \"used when creating the Cloud TPU, or a grpc://ip.address.of.tpu:8470 \"\n",
    "    \"url.\")\n",
    "\n",
    "tf.flags.DEFINE_string(\n",
    "    \"tpu_zone\", _tpu_zone,\n",
    "    \"[Optional] GCE zone where the Cloud TPU is located in. If not \"\n",
    "    \"specified, we will attempt to automatically detect the GCE project from \"\n",
    "    \"metadata.\")\n",
    "\n",
    "tf.flags.DEFINE_string(\n",
    "    \"gcp_project\", _gcp_project,\n",
    "    \"[Optional] Project name for the Cloud TPU-enabled project. If not \"\n",
    "    \"specified, we will attempt to automatically detect the GCE project from \"\n",
    "    \"metadata.\")\n",
    "\n",
    "tf.flags.DEFINE_string(\"master\", _master, \"[Optional] TensorFlow master URL.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"num_tpu_cores\", _num_tpu_cores,\n",
    "    \"Only used if `use_tpu` is True. Total number of TPU cores to use.\")\n",
    "\n",
    "flags.DEFINE_bool(\n",
    "    \"verbose_logging\", _verbose_logging,\n",
    "    \"If true, all of the warnings related to data processing will be printed. \"\n",
    "    \"A number of warnings are expected for a normal SQuAD evaluation.\")\n",
    "\n",
    "flags.DEFINE_bool(\n",
    "    \"version_2_with_negative\", _version_2_with_negative,\n",
    "    \"If true, the SQuAD examples contain some that do not have an answer.\")\n",
    "\n",
    "flags.DEFINE_float(\n",
    "    \"null_score_diff_threshold\", _null_score_diff_threshold,\n",
    "    \"If null_score - best_non_null is greater than the threshold predict null.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logtostderr  ->  False\n",
      "alsologtostderr  ->  False\n",
      "log_dir  ->  \n",
      "v  ->  -1\n",
      "verbosity  ->  -1\n",
      "stderrthreshold  ->  fatal\n",
      "showprefixforinfo  ->  True\n",
      "tfhub_cache_dir  ->  None\n",
      "bert_config_file  ->  models/model_repo/uncased_L-12_H-768_A-12/bert_config.json\n",
      "vocab_file  ->  models/model_repo/uncased_L-12_H-768_A-12/vocab.txt\n",
      "output_dir  ->  squad/output/jupyter\n",
      "train_file  ->  squad/train-v2.0.json\n",
      "predict_file  ->  squad/dev-v2.0.json\n",
      "init_checkpoint  ->  models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt\n",
      "do_lower_case  ->  True\n",
      "max_seq_length  ->  384\n",
      "doc_stride  ->  128\n",
      "max_query_length  ->  64\n",
      "do_train  ->  True\n",
      "do_predict  ->  True\n",
      "train_batch_size  ->  12\n",
      "predict_batch_size  ->  8\n",
      "learning_rate  ->  3e-05\n",
      "num_train_epochs  ->  2.0\n",
      "warmup_proportion  ->  0.1\n",
      "save_checkpoints_steps  ->  1000\n",
      "iterations_per_loop  ->  1000\n",
      "n_best_size  ->  20\n",
      "max_answer_length  ->  30\n",
      "use_tpu  ->  False\n",
      "tpu_name  ->  None\n",
      "tpu_zone  ->  None\n",
      "gcp_project  ->  None\n",
      "master  ->  None\n",
      "num_tpu_cores  ->  8\n",
      "verbose_logging  ->  False\n",
      "version_2_with_negative  ->  True\n",
      "null_score_diff_threshold  ->  0.0\n"
     ]
    }
   ],
   "source": [
    "for key, value in FLAGS.__flags.items():\n",
    "    print (key, ' -> ', value.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### <span style=\"color:navy\"> Step 2 - Define Base Classes & Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class SquadExample(object):\n",
    "  \"\"\"A single training/test example for simple sequence classification.\n",
    "\n",
    "     For examples without an answer, the start and end position are -1.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               qas_id,\n",
    "               question_text,\n",
    "               doc_tokens,\n",
    "               orig_answer_text=None,\n",
    "               start_position=None,\n",
    "               end_position=None,\n",
    "               is_impossible=False):\n",
    "    self.qas_id = qas_id\n",
    "    self.question_text = question_text\n",
    "    self.doc_tokens = doc_tokens\n",
    "    self.orig_answer_text = orig_answer_text\n",
    "    self.start_position = start_position\n",
    "    self.end_position = end_position\n",
    "    self.is_impossible = is_impossible\n",
    "\n",
    "  def __str__(self):\n",
    "    return self.__repr__()\n",
    "\n",
    "  def __repr__(self):\n",
    "    s = \"\"\n",
    "    s += \"qas_id: %s\" % (tokenization.printable_text(self.qas_id))\n",
    "    s += \", question_text: %s\" % (\n",
    "        tokenization.printable_text(self.question_text))\n",
    "    s += \", doc_tokens: [%s]\" % (\" \".join(self.doc_tokens))\n",
    "    if self.start_position:\n",
    "      s += \", start_position: %d\" % (self.start_position)\n",
    "    if self.start_position:\n",
    "      s += \", end_position: %d\" % (self.end_position)\n",
    "    if self.start_position:\n",
    "      s += \", is_impossible: %r\" % (self.is_impossible)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class InputFeatures(object):\n",
    "  \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               unique_id,\n",
    "               example_index,\n",
    "               doc_span_index,\n",
    "               tokens,\n",
    "               token_to_orig_map,\n",
    "               token_is_max_context,\n",
    "               input_ids,\n",
    "               input_mask,\n",
    "               segment_ids,\n",
    "               start_position=None,\n",
    "               end_position=None,\n",
    "               is_impossible=None):\n",
    "    self.unique_id = unique_id\n",
    "    self.example_index = example_index\n",
    "    self.doc_span_index = doc_span_index\n",
    "    self.tokens = tokens\n",
    "    self.token_to_orig_map = token_to_orig_map\n",
    "    self.token_is_max_context = token_is_max_context\n",
    "    self.input_ids = input_ids\n",
    "    self.input_mask = input_mask\n",
    "    self.segment_ids = segment_ids\n",
    "    self.start_position = start_position\n",
    "    self.end_position = end_position\n",
    "    self.is_impossible = is_impossible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def read_squad_examples(input_file, is_training):\n",
    "  \"\"\"Read a SQuAD json file into a list of SquadExample.\"\"\"\n",
    "  with tf.gfile.Open(input_file, \"r\") as reader:\n",
    "    input_data = json.load(reader)[\"data\"]\n",
    "\n",
    "  def is_whitespace(c):\n",
    "    if c == \" \" or c == \"\\t\" or c == \"\\r\" or c == \"\\n\" or ord(c) == 0x202F:\n",
    "      return True\n",
    "    return False\n",
    "\n",
    "  examples = []\n",
    "  for entry in input_data:\n",
    "    for paragraph in entry[\"paragraphs\"]:\n",
    "      paragraph_text = paragraph[\"context\"]\n",
    "      doc_tokens = []\n",
    "      char_to_word_offset = []\n",
    "      prev_is_whitespace = True\n",
    "      for c in paragraph_text:\n",
    "        if is_whitespace(c):\n",
    "          prev_is_whitespace = True\n",
    "        else:\n",
    "          if prev_is_whitespace:\n",
    "            doc_tokens.append(c)\n",
    "          else:\n",
    "            doc_tokens[-1] += c\n",
    "          prev_is_whitespace = False\n",
    "        char_to_word_offset.append(len(doc_tokens) - 1)\n",
    "\n",
    "      for qa in paragraph[\"qas\"]:\n",
    "        qas_id = qa[\"id\"]\n",
    "        question_text = qa[\"question\"]\n",
    "        start_position = None\n",
    "        end_position = None\n",
    "        orig_answer_text = None\n",
    "        is_impossible = False\n",
    "        if is_training:\n",
    "\n",
    "          if FLAGS.version_2_with_negative:\n",
    "            is_impossible = qa[\"is_impossible\"]\n",
    "          if (len(qa[\"answers\"]) != 1) and (not is_impossible):\n",
    "            raise ValueError(\n",
    "                \"For training, each question should have exactly 1 answer.\")\n",
    "          if not is_impossible:\n",
    "            answer = qa[\"answers\"][0]\n",
    "            orig_answer_text = answer[\"text\"]\n",
    "            answer_offset = answer[\"answer_start\"]\n",
    "            answer_length = len(orig_answer_text)\n",
    "            start_position = char_to_word_offset[answer_offset]\n",
    "            end_position = char_to_word_offset[answer_offset + answer_length -\n",
    "                                               1]\n",
    "            # Only add answers where the text can be exactly recovered from the\n",
    "            # document. If this CAN'T happen it's likely due to weird Unicode\n",
    "            # stuff so we will just skip the example.\n",
    "            #\n",
    "            # Note that this means for training mode, every example is NOT\n",
    "            # guaranteed to be preserved.\n",
    "            actual_text = \" \".join(\n",
    "                doc_tokens[start_position:(end_position + 1)])\n",
    "            cleaned_answer_text = \" \".join(\n",
    "                tokenization.whitespace_tokenize(orig_answer_text))\n",
    "            if actual_text.find(cleaned_answer_text) == -1:\n",
    "              tf.logging.warning(\"Could not find answer: '%s' vs. '%s'\",\n",
    "                                 actual_text, cleaned_answer_text)\n",
    "              continue\n",
    "          else:\n",
    "            start_position = -1\n",
    "            end_position = -1\n",
    "            orig_answer_text = \"\"\n",
    "\n",
    "        example = SquadExample(\n",
    "            qas_id=qas_id,\n",
    "            question_text=question_text,\n",
    "            doc_tokens=doc_tokens,\n",
    "            orig_answer_text=orig_answer_text,\n",
    "            start_position=start_position,\n",
    "            end_position=end_position,\n",
    "            is_impossible=is_impossible)\n",
    "        examples.append(example)\n",
    "\n",
    "  return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples, tokenizer, max_seq_length,\n",
    "                                 doc_stride, max_query_length, is_training,\n",
    "                                 output_fn):\n",
    "  \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "\n",
    "  unique_id = 1000000000\n",
    "\n",
    "  for (example_index, example) in enumerate(examples):\n",
    "    query_tokens = tokenizer.tokenize(example.question_text)\n",
    "\n",
    "    if len(query_tokens) > max_query_length:\n",
    "      query_tokens = query_tokens[0:max_query_length]\n",
    "\n",
    "    tok_to_orig_index = []\n",
    "    orig_to_tok_index = []\n",
    "    all_doc_tokens = []\n",
    "    for (i, token) in enumerate(example.doc_tokens):\n",
    "      orig_to_tok_index.append(len(all_doc_tokens))\n",
    "      sub_tokens = tokenizer.tokenize(token)\n",
    "      for sub_token in sub_tokens:\n",
    "        tok_to_orig_index.append(i)\n",
    "        all_doc_tokens.append(sub_token)\n",
    "\n",
    "    tok_start_position = None\n",
    "    tok_end_position = None\n",
    "    if is_training and example.is_impossible:\n",
    "      tok_start_position = -1\n",
    "      tok_end_position = -1\n",
    "    if is_training and not example.is_impossible:\n",
    "      tok_start_position = orig_to_tok_index[example.start_position]\n",
    "      if example.end_position < len(example.doc_tokens) - 1:\n",
    "        tok_end_position = orig_to_tok_index[example.end_position + 1] - 1\n",
    "      else:\n",
    "        tok_end_position = len(all_doc_tokens) - 1\n",
    "      (tok_start_position, tok_end_position) = _improve_answer_span(\n",
    "          all_doc_tokens, tok_start_position, tok_end_position, tokenizer,\n",
    "          example.orig_answer_text)\n",
    "\n",
    "    # The -3 accounts for [CLS], [SEP] and [SEP]\n",
    "    max_tokens_for_doc = max_seq_length - len(query_tokens) - 3\n",
    "\n",
    "    # We can have documents that are longer than the maximum sequence length.\n",
    "    # To deal with this we do a sliding window approach, where we take chunks\n",
    "    # of the up to our max length with a stride of `doc_stride`.\n",
    "    _DocSpan = collections.namedtuple(  # pylint: disable=invalid-name\n",
    "        \"DocSpan\", [\"start\", \"length\"])\n",
    "    doc_spans = []\n",
    "    start_offset = 0\n",
    "    while start_offset < len(all_doc_tokens):\n",
    "      length = len(all_doc_tokens) - start_offset\n",
    "      if length > max_tokens_for_doc:\n",
    "        length = max_tokens_for_doc\n",
    "      doc_spans.append(_DocSpan(start=start_offset, length=length))\n",
    "      if start_offset + length == len(all_doc_tokens):\n",
    "        break\n",
    "      start_offset += min(length, doc_stride)\n",
    "\n",
    "    for (doc_span_index, doc_span) in enumerate(doc_spans):\n",
    "      tokens = []\n",
    "      token_to_orig_map = {}\n",
    "      token_is_max_context = {}\n",
    "      segment_ids = []\n",
    "      tokens.append(\"[CLS]\")\n",
    "      segment_ids.append(0)\n",
    "      for token in query_tokens:\n",
    "        tokens.append(token)\n",
    "        segment_ids.append(0)\n",
    "      tokens.append(\"[SEP]\")\n",
    "      segment_ids.append(0)\n",
    "\n",
    "      for i in range(doc_span.length):\n",
    "        split_token_index = doc_span.start + i\n",
    "        token_to_orig_map[len(tokens)] = tok_to_orig_index[split_token_index]\n",
    "\n",
    "        is_max_context = _check_is_max_context(doc_spans, doc_span_index,\n",
    "                                               split_token_index)\n",
    "        token_is_max_context[len(tokens)] = is_max_context\n",
    "        tokens.append(all_doc_tokens[split_token_index])\n",
    "        segment_ids.append(1)\n",
    "      tokens.append(\"[SEP]\")\n",
    "      segment_ids.append(1)\n",
    "\n",
    "      input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "      # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "      # tokens are attended to.\n",
    "      input_mask = [1] * len(input_ids)\n",
    "\n",
    "      # Zero-pad up to the sequence length.\n",
    "      while len(input_ids) < max_seq_length:\n",
    "        input_ids.append(0)\n",
    "        input_mask.append(0)\n",
    "        segment_ids.append(0)\n",
    "\n",
    "      assert len(input_ids) == max_seq_length\n",
    "      assert len(input_mask) == max_seq_length\n",
    "      assert len(segment_ids) == max_seq_length\n",
    "\n",
    "      start_position = None\n",
    "      end_position = None\n",
    "      if is_training and not example.is_impossible:\n",
    "        # For training, if our document chunk does not contain an annotation\n",
    "        # we throw it out, since there is nothing to predict.\n",
    "        doc_start = doc_span.start\n",
    "        doc_end = doc_span.start + doc_span.length - 1\n",
    "        out_of_span = False\n",
    "        if not (tok_start_position >= doc_start and\n",
    "                tok_end_position <= doc_end):\n",
    "          out_of_span = True\n",
    "        if out_of_span:\n",
    "          start_position = 0\n",
    "          end_position = 0\n",
    "        else:\n",
    "          doc_offset = len(query_tokens) + 2\n",
    "          start_position = tok_start_position - doc_start + doc_offset\n",
    "          end_position = tok_end_position - doc_start + doc_offset\n",
    "\n",
    "      if is_training and example.is_impossible:\n",
    "        start_position = 0\n",
    "        end_position = 0\n",
    "\n",
    "      if example_index < 20:\n",
    "        tf.logging.info(\"*** Example ***\")\n",
    "        tf.logging.info(\"unique_id: %s\" % (unique_id))\n",
    "        tf.logging.info(\"example_index: %s\" % (example_index))\n",
    "        tf.logging.info(\"doc_span_index: %s\" % (doc_span_index))\n",
    "        tf.logging.info(\"tokens: %s\" % \" \".join(\n",
    "            [tokenization.printable_text(x) for x in tokens]))\n",
    "        tf.logging.info(\"token_to_orig_map: %s\" % \" \".join(\n",
    "            [\"%d:%d\" % (x, y) for (x, y) in six.iteritems(token_to_orig_map)]))\n",
    "        tf.logging.info(\"token_is_max_context: %s\" % \" \".join([\n",
    "            \"%d:%s\" % (x, y) for (x, y) in six.iteritems(token_is_max_context)\n",
    "        ]))\n",
    "        tf.logging.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
    "        tf.logging.info(\n",
    "            \"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
    "        tf.logging.info(\n",
    "            \"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
    "        if is_training and example.is_impossible:\n",
    "          tf.logging.info(\"impossible example\")\n",
    "        if is_training and not example.is_impossible:\n",
    "          answer_text = \" \".join(tokens[start_position:(end_position + 1)])\n",
    "          tf.logging.info(\"start_position: %d\" % (start_position))\n",
    "          tf.logging.info(\"end_position: %d\" % (end_position))\n",
    "          tf.logging.info(\n",
    "              \"answer: %s\" % (tokenization.printable_text(answer_text)))\n",
    "\n",
    "      feature = InputFeatures(\n",
    "          unique_id=unique_id,\n",
    "          example_index=example_index,\n",
    "          doc_span_index=doc_span_index,\n",
    "          tokens=tokens,\n",
    "          token_to_orig_map=token_to_orig_map,\n",
    "          token_is_max_context=token_is_max_context,\n",
    "          input_ids=input_ids,\n",
    "          input_mask=input_mask,\n",
    "          segment_ids=segment_ids,\n",
    "          start_position=start_position,\n",
    "          end_position=end_position,\n",
    "          is_impossible=example.is_impossible)\n",
    "\n",
    "      # Run callback\n",
    "      output_fn(feature)\n",
    "\n",
    "      unique_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _improve_answer_span(doc_tokens, input_start, input_end, tokenizer,\n",
    "                         orig_answer_text):\n",
    "  \"\"\"Returns tokenized answer spans that better match the annotated answer.\"\"\"\n",
    "\n",
    "  # The SQuAD annotations are character based. We first project them to\n",
    "  # whitespace-tokenized words. But then after WordPiece tokenization, we can\n",
    "  # often find a \"better match\". For example:\n",
    "  #\n",
    "  #   Question: What year was John Smith born?\n",
    "  #   Context: The leader was John Smith (1895-1943).\n",
    "  #   Answer: 1895\n",
    "  #\n",
    "  # The original whitespace-tokenized answer will be \"(1895-1943).\". However\n",
    "  # after tokenization, our tokens will be \"( 1895 - 1943 ) .\". So we can match\n",
    "  # the exact answer, 1895.\n",
    "  #\n",
    "  # However, this is not always possible. Consider the following:\n",
    "  #\n",
    "  #   Question: What country is the top exporter of electornics?\n",
    "  #   Context: The Japanese electronics industry is the lagest in the world.\n",
    "  #   Answer: Japan\n",
    "  #\n",
    "  # In this case, the annotator chose \"Japan\" as a character sub-span of\n",
    "  # the word \"Japanese\". Since our WordPiece tokenizer does not split\n",
    "  # \"Japanese\", we just use \"Japanese\" as the annotation. This is fairly rare\n",
    "  # in SQuAD, but does happen.\n",
    "  tok_answer_text = \" \".join(tokenizer.tokenize(orig_answer_text))\n",
    "\n",
    "  for new_start in range(input_start, input_end + 1):\n",
    "    for new_end in range(input_end, new_start - 1, -1):\n",
    "      text_span = \" \".join(doc_tokens[new_start:(new_end + 1)])\n",
    "      if text_span == tok_answer_text:\n",
    "        return (new_start, new_end)\n",
    "\n",
    "  return (input_start, input_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _check_is_max_context(doc_spans, cur_span_index, position):\n",
    "  \"\"\"Check if this is the 'max context' doc span for the token.\"\"\"\n",
    "\n",
    "  # Because of the sliding window approach taken to scoring documents, a single\n",
    "  # token can appear in multiple documents. E.g.\n",
    "  #  Doc: the man went to the store and bought a gallon of milk\n",
    "  #  Span A: the man went to the\n",
    "  #  Span B: to the store and bought\n",
    "  #  Span C: and bought a gallon of\n",
    "  #  ...\n",
    "  #\n",
    "  # Now the word 'bought' will have two scores from spans B and C. We only\n",
    "  # want to consider the score with \"maximum context\", which we define as\n",
    "  # the *minimum* of its left and right context (the *sum* of left and\n",
    "  # right context will always be the same, of course).\n",
    "  #\n",
    "  # In the example the maximum context for 'bought' would be span C since\n",
    "  # it has 1 left context and 3 right context, while span B has 4 left context\n",
    "  # and 0 right context.\n",
    "  best_score = None\n",
    "  best_span_index = None\n",
    "  for (span_index, doc_span) in enumerate(doc_spans):\n",
    "    end = doc_span.start + doc_span.length - 1\n",
    "    if position < doc_span.start:\n",
    "      continue\n",
    "    if position > end:\n",
    "      continue\n",
    "    num_left_context = position - doc_span.start\n",
    "    num_right_context = end - position\n",
    "    score = min(num_left_context, num_right_context) + 0.01 * doc_span.length\n",
    "    if best_score is None or score > best_score:\n",
    "      best_score = score\n",
    "      best_span_index = span_index\n",
    "\n",
    "  return cur_span_index == best_span_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_model(bert_config, is_training, input_ids, input_mask, segment_ids,\n",
    "                 use_one_hot_embeddings):\n",
    "  \"\"\"Creates a classification model.\"\"\"\n",
    "  model = modeling.BertModel(\n",
    "      config=bert_config,\n",
    "      is_training=is_training,\n",
    "      input_ids=input_ids,\n",
    "      input_mask=input_mask,\n",
    "      token_type_ids=segment_ids,\n",
    "      use_one_hot_embeddings=use_one_hot_embeddings)\n",
    "\n",
    "  final_hidden = model.get_sequence_output()\n",
    "\n",
    "  final_hidden_shape = modeling.get_shape_list(final_hidden, expected_rank=3)\n",
    "  batch_size = final_hidden_shape[0]\n",
    "  seq_length = final_hidden_shape[1]\n",
    "  hidden_size = final_hidden_shape[2]\n",
    "\n",
    "  output_weights = tf.get_variable(\n",
    "      \"cls/squad/output_weights\", [2, hidden_size],\n",
    "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "  output_bias = tf.get_variable(\n",
    "      \"cls/squad/output_bias\", [2], initializer=tf.zeros_initializer())\n",
    "\n",
    "  final_hidden_matrix = tf.reshape(final_hidden,\n",
    "                                   [batch_size * seq_length, hidden_size])\n",
    "  logits = tf.matmul(final_hidden_matrix, output_weights, transpose_b=True)\n",
    "  logits = tf.nn.bias_add(logits, output_bias)\n",
    "\n",
    "  logits = tf.reshape(logits, [batch_size, seq_length, 2])\n",
    "  logits = tf.transpose(logits, [2, 0, 1])\n",
    "\n",
    "  unstacked_logits = tf.unstack(logits, axis=0)\n",
    "\n",
    "  (start_logits, end_logits) = (unstacked_logits[0], unstacked_logits[1])\n",
    "\n",
    "  return (start_logits, end_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def model_fn_builder(bert_config, init_checkpoint, learning_rate,\n",
    "                     num_train_steps, num_warmup_steps, use_tpu,\n",
    "                     use_one_hot_embeddings):\n",
    "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
    "\n",
    "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
    "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
    "\n",
    "    tf.logging.info(\"*** Features ***\")\n",
    "    for name in sorted(features.keys()):\n",
    "      tf.logging.info(\"  name = %s, shape = %s\" % (name, features[name].shape))\n",
    "\n",
    "    unique_ids = features[\"unique_ids\"]\n",
    "    input_ids = features[\"input_ids\"]\n",
    "    input_mask = features[\"input_mask\"]\n",
    "    segment_ids = features[\"segment_ids\"]\n",
    "\n",
    "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    (start_logits, end_logits) = create_model(\n",
    "        bert_config=bert_config,\n",
    "        is_training=is_training,\n",
    "        input_ids=input_ids,\n",
    "        input_mask=input_mask,\n",
    "        segment_ids=segment_ids,\n",
    "        use_one_hot_embeddings=use_one_hot_embeddings)\n",
    "\n",
    "    tvars = tf.trainable_variables()\n",
    "\n",
    "    initialized_variable_names = {}\n",
    "    scaffold_fn = None\n",
    "    if init_checkpoint:\n",
    "      (assignment_map, initialized_variable_names\n",
    "      ) = modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n",
    "      if use_tpu:\n",
    "\n",
    "        def tpu_scaffold():\n",
    "          tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
    "          return tf.train.Scaffold()\n",
    "\n",
    "        scaffold_fn = tpu_scaffold\n",
    "      else:\n",
    "        tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
    "\n",
    "    tf.logging.info(\"**** Trainable Variables ****\")\n",
    "    for var in tvars:\n",
    "      init_string = \"\"\n",
    "      if var.name in initialized_variable_names:\n",
    "        init_string = \", *INIT_FROM_CKPT*\"\n",
    "      tf.logging.info(\"  name = %s, shape = %s%s\", var.name, var.shape,\n",
    "                      init_string)\n",
    "\n",
    "    output_spec = None\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "      seq_length = modeling.get_shape_list(input_ids)[1]\n",
    "\n",
    "      def compute_loss(logits, positions):\n",
    "        one_hot_positions = tf.one_hot(\n",
    "            positions, depth=seq_length, dtype=tf.float32)\n",
    "        log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "        loss = -tf.reduce_mean(\n",
    "            tf.reduce_sum(one_hot_positions * log_probs, axis=-1))\n",
    "        return loss\n",
    "\n",
    "      start_positions = features[\"start_positions\"]\n",
    "      end_positions = features[\"end_positions\"]\n",
    "\n",
    "      start_loss = compute_loss(start_logits, start_positions)\n",
    "      end_loss = compute_loss(end_logits, end_positions)\n",
    "\n",
    "      total_loss = (start_loss + end_loss) / 2.0\n",
    "\n",
    "      train_op = optimization.create_optimizer(\n",
    "          total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)\n",
    "\n",
    "      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
    "          mode=mode,\n",
    "          loss=total_loss,\n",
    "          train_op=train_op,\n",
    "          scaffold_fn=scaffold_fn)\n",
    "    elif mode == tf.estimator.ModeKeys.PREDICT:\n",
    "      predictions = {\n",
    "          \"unique_ids\": unique_ids,\n",
    "          \"start_logits\": start_logits,\n",
    "          \"end_logits\": end_logits,\n",
    "      }\n",
    "      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
    "          mode=mode, predictions=predictions, scaffold_fn=scaffold_fn)\n",
    "    else:\n",
    "      raise ValueError(\n",
    "          \"Only TRAIN and PREDICT modes are supported: %s\" % (mode))\n",
    "\n",
    "    return output_spec\n",
    "\n",
    "  return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def input_fn_builder(input_file, seq_length, is_training, drop_remainder):\n",
    "  \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n",
    "\n",
    "  name_to_features = {\n",
    "      \"unique_ids\": tf.FixedLenFeature([], tf.int64),\n",
    "      \"input_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "      \"input_mask\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "      \"segment_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "  }\n",
    "\n",
    "  if is_training:\n",
    "    name_to_features[\"start_positions\"] = tf.FixedLenFeature([], tf.int64)\n",
    "    name_to_features[\"end_positions\"] = tf.FixedLenFeature([], tf.int64)\n",
    "\n",
    "  def _decode_record(record, name_to_features):\n",
    "    \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
    "    example = tf.parse_single_example(record, name_to_features)\n",
    "\n",
    "    # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n",
    "    # So cast all int64 to int32.\n",
    "    for name in list(example.keys()):\n",
    "      t = example[name]\n",
    "      if t.dtype == tf.int64:\n",
    "        t = tf.to_int32(t)\n",
    "      example[name] = t\n",
    "\n",
    "    return example\n",
    "\n",
    "  def input_fn(params):\n",
    "    \"\"\"The actual input function.\"\"\"\n",
    "    batch_size = params[\"batch_size\"]\n",
    "\n",
    "    # For training, we want a lot of parallel reading and shuffling.\n",
    "    # For eval, we want no shuffling and parallel reading doesn't matter.\n",
    "    d = tf.data.TFRecordDataset(input_file)\n",
    "    if is_training:\n",
    "      d = d.repeat()\n",
    "      d = d.shuffle(buffer_size=100)\n",
    "\n",
    "    d = d.apply(\n",
    "        tf.contrib.data.map_and_batch(\n",
    "            lambda record: _decode_record(record, name_to_features),\n",
    "            batch_size=batch_size,\n",
    "            drop_remainder=drop_remainder))\n",
    "\n",
    "    return d\n",
    "\n",
    "  return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "RawResult = collections.namedtuple(\"RawResult\",\n",
    "                                   [\"unique_id\", \"start_logits\", \"end_logits\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def write_predictions(all_examples, all_features, all_results, n_best_size,\n",
    "                      max_answer_length, do_lower_case, output_prediction_file,\n",
    "                      output_nbest_file, output_null_log_odds_file):\n",
    "  \"\"\"Write final predictions to the json file and log-odds of null if needed.\"\"\"\n",
    "  tf.logging.info(\"Writing predictions to: %s\" % (output_prediction_file))\n",
    "  tf.logging.info(\"Writing nbest to: %s\" % (output_nbest_file))\n",
    "\n",
    "  example_index_to_features = collections.defaultdict(list)\n",
    "  for feature in all_features:\n",
    "    example_index_to_features[feature.example_index].append(feature)\n",
    "\n",
    "  unique_id_to_result = {}\n",
    "  for result in all_results:\n",
    "    unique_id_to_result[result.unique_id] = result\n",
    "\n",
    "  _PrelimPrediction = collections.namedtuple(  # pylint: disable=invalid-name\n",
    "      \"PrelimPrediction\",\n",
    "      [\"feature_index\", \"start_index\", \"end_index\", \"start_logit\", \"end_logit\"])\n",
    "\n",
    "  all_predictions = collections.OrderedDict()\n",
    "  all_nbest_json = collections.OrderedDict()\n",
    "  scores_diff_json = collections.OrderedDict()\n",
    "\n",
    "  for (example_index, example) in enumerate(all_examples):\n",
    "    features = example_index_to_features[example_index]\n",
    "\n",
    "    prelim_predictions = []\n",
    "    # keep track of the minimum score of null start+end of position 0\n",
    "    score_null = 1000000  # large and positive\n",
    "    min_null_feature_index = 0  # the paragraph slice with min mull score\n",
    "    null_start_logit = 0  # the start logit at the slice with min null score\n",
    "    null_end_logit = 0  # the end logit at the slice with min null score\n",
    "    for (feature_index, feature) in enumerate(features):\n",
    "      result = unique_id_to_result[feature.unique_id]\n",
    "      start_indexes = _get_best_indexes(result.start_logits, n_best_size)\n",
    "      end_indexes = _get_best_indexes(result.end_logits, n_best_size)\n",
    "      # if we could have irrelevant answers, get the min score of irrelevant\n",
    "      if FLAGS.version_2_with_negative:\n",
    "        feature_null_score = result.start_logits[0] + result.end_logits[0]\n",
    "        if feature_null_score < score_null:\n",
    "          score_null = feature_null_score\n",
    "          min_null_feature_index = feature_index\n",
    "          null_start_logit = result.start_logits[0]\n",
    "          null_end_logit = result.end_logits[0]\n",
    "      for start_index in start_indexes:\n",
    "        for end_index in end_indexes:\n",
    "          # We could hypothetically create invalid predictions, e.g., predict\n",
    "          # that the start of the span is in the question. We throw out all\n",
    "          # invalid predictions.\n",
    "          if start_index >= len(feature.tokens):\n",
    "            continue\n",
    "          if end_index >= len(feature.tokens):\n",
    "            continue\n",
    "          if start_index not in feature.token_to_orig_map:\n",
    "            continue\n",
    "          if end_index not in feature.token_to_orig_map:\n",
    "            continue\n",
    "          if not feature.token_is_max_context.get(start_index, False):\n",
    "            continue\n",
    "          if end_index < start_index:\n",
    "            continue\n",
    "          length = end_index - start_index + 1\n",
    "          if length > max_answer_length:\n",
    "            continue\n",
    "          prelim_predictions.append(\n",
    "              _PrelimPrediction(\n",
    "                  feature_index=feature_index,\n",
    "                  start_index=start_index,\n",
    "                  end_index=end_index,\n",
    "                  start_logit=result.start_logits[start_index],\n",
    "                  end_logit=result.end_logits[end_index]))\n",
    "\n",
    "    if FLAGS.version_2_with_negative:\n",
    "      prelim_predictions.append(\n",
    "          _PrelimPrediction(\n",
    "              feature_index=min_null_feature_index,\n",
    "              start_index=0,\n",
    "              end_index=0,\n",
    "              start_logit=null_start_logit,\n",
    "              end_logit=null_end_logit))\n",
    "    prelim_predictions = sorted(\n",
    "        prelim_predictions,\n",
    "        key=lambda x: (x.start_logit + x.end_logit),\n",
    "        reverse=True)\n",
    "\n",
    "    _NbestPrediction = collections.namedtuple(  # pylint: disable=invalid-name\n",
    "        \"NbestPrediction\", [\"text\", \"start_logit\", \"end_logit\"])\n",
    "\n",
    "    seen_predictions = {}\n",
    "    nbest = []\n",
    "    for pred in prelim_predictions:\n",
    "      if len(nbest) >= n_best_size:\n",
    "        break\n",
    "      feature = features[pred.feature_index]\n",
    "      if pred.start_index > 0:  # this is a non-null prediction\n",
    "        tok_tokens = feature.tokens[pred.start_index:(pred.end_index + 1)]\n",
    "        orig_doc_start = feature.token_to_orig_map[pred.start_index]\n",
    "        orig_doc_end = feature.token_to_orig_map[pred.end_index]\n",
    "        orig_tokens = example.doc_tokens[orig_doc_start:(orig_doc_end + 1)]\n",
    "        tok_text = \" \".join(tok_tokens)\n",
    "\n",
    "        # De-tokenize WordPieces that have been split off.\n",
    "        tok_text = tok_text.replace(\" ##\", \"\")\n",
    "        tok_text = tok_text.replace(\"##\", \"\")\n",
    "\n",
    "        # Clean whitespace\n",
    "        tok_text = tok_text.strip()\n",
    "        tok_text = \" \".join(tok_text.split())\n",
    "        orig_text = \" \".join(orig_tokens)\n",
    "\n",
    "        final_text = get_final_text(tok_text, orig_text, do_lower_case)\n",
    "        if final_text in seen_predictions:\n",
    "          continue\n",
    "\n",
    "        seen_predictions[final_text] = True\n",
    "      else:\n",
    "        final_text = \"\"\n",
    "        seen_predictions[final_text] = True\n",
    "\n",
    "      nbest.append(\n",
    "          _NbestPrediction(\n",
    "              text=final_text,\n",
    "              start_logit=pred.start_logit,\n",
    "              end_logit=pred.end_logit))\n",
    "\n",
    "    # if we didn't inlude the empty option in the n-best, inlcude it\n",
    "    if FLAGS.version_2_with_negative:\n",
    "      if \"\" not in seen_predictions:\n",
    "        nbest.append(\n",
    "            _NbestPrediction(\n",
    "                text=\"\", start_logit=null_start_logit,\n",
    "                end_logit=null_end_logit))\n",
    "    # In very rare edge cases we could have no valid predictions. So we\n",
    "    # just create a nonce prediction in this case to avoid failure.\n",
    "    if not nbest:\n",
    "      nbest.append(\n",
    "          _NbestPrediction(text=\"empty\", start_logit=0.0, end_logit=0.0))\n",
    "\n",
    "    assert len(nbest) >= 1\n",
    "\n",
    "    total_scores = []\n",
    "    best_non_null_entry = None\n",
    "    for entry in nbest:\n",
    "      total_scores.append(entry.start_logit + entry.end_logit)\n",
    "      if not best_non_null_entry:\n",
    "        if entry.text:\n",
    "          best_non_null_entry = entry\n",
    "\n",
    "    probs = _compute_softmax(total_scores)\n",
    "\n",
    "    nbest_json = []\n",
    "    for (i, entry) in enumerate(nbest):\n",
    "      output = collections.OrderedDict()\n",
    "      output[\"text\"] = entry.text\n",
    "      output[\"probability\"] = probs[i]\n",
    "      output[\"start_logit\"] = entry.start_logit\n",
    "      output[\"end_logit\"] = entry.end_logit\n",
    "      nbest_json.append(output)\n",
    "\n",
    "    assert len(nbest_json) >= 1\n",
    "\n",
    "    if not FLAGS.version_2_with_negative:\n",
    "      all_predictions[example.qas_id] = nbest_json[0][\"text\"]\n",
    "    else:\n",
    "      # predict \"\" iff the null score - the score of best non-null > threshold\n",
    "      score_diff = score_null - best_non_null_entry.start_logit - (\n",
    "          best_non_null_entry.end_logit)\n",
    "      scores_diff_json[example.qas_id] = score_diff\n",
    "      if score_diff > FLAGS.null_score_diff_threshold:\n",
    "        all_predictions[example.qas_id] = \"\"\n",
    "      else:\n",
    "        all_predictions[example.qas_id] = best_non_null_entry.text\n",
    "\n",
    "    all_nbest_json[example.qas_id] = nbest_json\n",
    "\n",
    "  with tf.gfile.GFile(output_prediction_file, \"w\") as writer:\n",
    "    writer.write(json.dumps(all_predictions, indent=4) + \"\\n\")\n",
    "\n",
    "  with tf.gfile.GFile(output_nbest_file, \"w\") as writer:\n",
    "    writer.write(json.dumps(all_nbest_json, indent=4) + \"\\n\")\n",
    "\n",
    "  if FLAGS.version_2_with_negative:\n",
    "    with tf.gfile.GFile(output_null_log_odds_file, \"w\") as writer:\n",
    "      writer.write(json.dumps(scores_diff_json, indent=4) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_final_text(pred_text, orig_text, do_lower_case):\n",
    "  \"\"\"Project the tokenized prediction back to the original text.\"\"\"\n",
    "\n",
    "  # When we created the data, we kept track of the alignment between original\n",
    "  # (whitespace tokenized) tokens and our WordPiece tokenized tokens. So\n",
    "  # now `orig_text` contains the span of our original text corresponding to the\n",
    "  # span that we predicted.\n",
    "  #\n",
    "  # However, `orig_text` may contain extra characters that we don't want in\n",
    "  # our prediction.\n",
    "  #\n",
    "  # For example, let's say:\n",
    "  #   pred_text = steve smith\n",
    "  #   orig_text = Steve Smith's\n",
    "  #\n",
    "  # We don't want to return `orig_text` because it contains the extra \"'s\".\n",
    "  #\n",
    "  # We don't want to return `pred_text` because it's already been normalized\n",
    "  # (the SQuAD eval script also does punctuation stripping/lower casing but\n",
    "  # our tokenizer does additional normalization like stripping accent\n",
    "  # characters).\n",
    "  #\n",
    "  # What we really want to return is \"Steve Smith\".\n",
    "  #\n",
    "  # Therefore, we have to apply a semi-complicated alignment heruistic between\n",
    "  # `pred_text` and `orig_text` to get a character-to-charcter alignment. This\n",
    "  # can fail in certain cases in which case we just return `orig_text`.\n",
    "\n",
    "  def _strip_spaces(text):\n",
    "    ns_chars = []\n",
    "    ns_to_s_map = collections.OrderedDict()\n",
    "    for (i, c) in enumerate(text):\n",
    "      if c == \" \":\n",
    "        continue\n",
    "      ns_to_s_map[len(ns_chars)] = i\n",
    "      ns_chars.append(c)\n",
    "    ns_text = \"\".join(ns_chars)\n",
    "    return (ns_text, ns_to_s_map)\n",
    "\n",
    "  # We first tokenize `orig_text`, strip whitespace from the result\n",
    "  # and `pred_text`, and check if they are the same length. If they are\n",
    "  # NOT the same length, the heuristic has failed. If they are the same\n",
    "  # length, we assume the characters are one-to-one aligned.\n",
    "  tokenizer = tokenization.BasicTokenizer(do_lower_case=do_lower_case)\n",
    "\n",
    "  tok_text = \" \".join(tokenizer.tokenize(orig_text))\n",
    "\n",
    "  start_position = tok_text.find(pred_text)\n",
    "  if start_position == -1:\n",
    "    if FLAGS.verbose_logging:\n",
    "      tf.logging.info(\n",
    "          \"Unable to find text: '%s' in '%s'\" % (pred_text, orig_text))\n",
    "    return orig_text\n",
    "  end_position = start_position + len(pred_text) - 1\n",
    "\n",
    "  (orig_ns_text, orig_ns_to_s_map) = _strip_spaces(orig_text)\n",
    "  (tok_ns_text, tok_ns_to_s_map) = _strip_spaces(tok_text)\n",
    "\n",
    "  if len(orig_ns_text) != len(tok_ns_text):\n",
    "    if FLAGS.verbose_logging:\n",
    "      tf.logging.info(\"Length not equal after stripping spaces: '%s' vs '%s'\",\n",
    "                      orig_ns_text, tok_ns_text)\n",
    "    return orig_text\n",
    "\n",
    "  # We then project the characters in `pred_text` back to `orig_text` using\n",
    "  # the character-to-character alignment.\n",
    "  tok_s_to_ns_map = {}\n",
    "  for (i, tok_index) in six.iteritems(tok_ns_to_s_map):\n",
    "    tok_s_to_ns_map[tok_index] = i\n",
    "\n",
    "  orig_start_position = None\n",
    "  if start_position in tok_s_to_ns_map:\n",
    "    ns_start_position = tok_s_to_ns_map[start_position]\n",
    "    if ns_start_position in orig_ns_to_s_map:\n",
    "      orig_start_position = orig_ns_to_s_map[ns_start_position]\n",
    "\n",
    "  if orig_start_position is None:\n",
    "    if FLAGS.verbose_logging:\n",
    "      tf.logging.info(\"Couldn't map start position\")\n",
    "    return orig_text\n",
    "\n",
    "  orig_end_position = None\n",
    "  if end_position in tok_s_to_ns_map:\n",
    "    ns_end_position = tok_s_to_ns_map[end_position]\n",
    "    if ns_end_position in orig_ns_to_s_map:\n",
    "      orig_end_position = orig_ns_to_s_map[ns_end_position]\n",
    "\n",
    "  if orig_end_position is None:\n",
    "    if FLAGS.verbose_logging:\n",
    "      tf.logging.info(\"Couldn't map end position\")\n",
    "    return orig_text\n",
    "\n",
    "  output_text = orig_text[orig_start_position:(orig_end_position + 1)]\n",
    "  return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _get_best_indexes(logits, n_best_size):\n",
    "  \"\"\"Get the n-best logits from a list.\"\"\"\n",
    "  index_and_score = sorted(enumerate(logits), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "  best_indexes = []\n",
    "  for i in range(len(index_and_score)):\n",
    "    if i >= n_best_size:\n",
    "      break\n",
    "    best_indexes.append(index_and_score[i][0])\n",
    "  return best_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _compute_softmax(scores):\n",
    "  \"\"\"Compute softmax probability over raw logits.\"\"\"\n",
    "  if not scores:\n",
    "    return []\n",
    "\n",
    "  max_score = None\n",
    "  for score in scores:\n",
    "    if max_score is None or score > max_score:\n",
    "      max_score = score\n",
    "\n",
    "  exp_scores = []\n",
    "  total_sum = 0.0\n",
    "  for score in scores:\n",
    "    x = math.exp(score - max_score)\n",
    "    exp_scores.append(x)\n",
    "    total_sum += x\n",
    "\n",
    "  probs = []\n",
    "  for score in exp_scores:\n",
    "    probs.append(score / total_sum)\n",
    "  return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class FeatureWriter(object):\n",
    "  \"\"\"Writes InputFeature to TF example file.\"\"\"\n",
    "\n",
    "  def __init__(self, filename, is_training):\n",
    "    self.filename = filename\n",
    "    self.is_training = is_training\n",
    "    self.num_features = 0\n",
    "    self._writer = tf.python_io.TFRecordWriter(filename)\n",
    "\n",
    "  def process_feature(self, feature):\n",
    "    \"\"\"Write a InputFeature to the TFRecordWriter as a tf.train.Example.\"\"\"\n",
    "    self.num_features += 1\n",
    "\n",
    "    def create_int_feature(values):\n",
    "      feature = tf.train.Feature(\n",
    "          int64_list=tf.train.Int64List(value=list(values)))\n",
    "      return feature\n",
    "\n",
    "    features = collections.OrderedDict()\n",
    "    features[\"unique_ids\"] = create_int_feature([feature.unique_id])\n",
    "    features[\"input_ids\"] = create_int_feature(feature.input_ids)\n",
    "    features[\"input_mask\"] = create_int_feature(feature.input_mask)\n",
    "    features[\"segment_ids\"] = create_int_feature(feature.segment_ids)\n",
    "\n",
    "    if self.is_training:\n",
    "      features[\"start_positions\"] = create_int_feature([feature.start_position])\n",
    "      features[\"end_positions\"] = create_int_feature([feature.end_position])\n",
    "      impossible = 0\n",
    "      if feature.is_impossible:\n",
    "        impossible = 1\n",
    "      features[\"is_impossible\"] = create_int_feature([impossible])\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature=features))\n",
    "    self._writer.write(tf_example.SerializeToString())\n",
    "\n",
    "  def close(self):\n",
    "    self._writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def validate_flags_or_throw(bert_config):\n",
    "  \"\"\"Validate the input FLAGS or throw an exception.\"\"\"\n",
    "  tokenization.validate_case_matches_checkpoint(FLAGS.do_lower_case,\n",
    "                                                FLAGS.init_checkpoint)\n",
    "\n",
    "  if not FLAGS.do_train and not FLAGS.do_predict:\n",
    "    raise ValueError(\"At least one of `do_train` or `do_predict` must be True.\")\n",
    "\n",
    "  if FLAGS.do_train:\n",
    "    if not FLAGS.train_file:\n",
    "      raise ValueError(\n",
    "          \"If `do_train` is True, then `train_file` must be specified.\")\n",
    "  if FLAGS.do_predict:\n",
    "    if not FLAGS.predict_file:\n",
    "      raise ValueError(\n",
    "          \"If `do_predict` is True, then `predict_file` must be specified.\")\n",
    "\n",
    "  if FLAGS.max_seq_length > bert_config.max_position_embeddings:\n",
    "    raise ValueError(\n",
    "        \"Cannot use sequence length %d because the BERT model \"\n",
    "        \"was only trained up to sequence length %d\" %\n",
    "        (FLAGS.max_seq_length, bert_config.max_position_embeddings))\n",
    "\n",
    "  if FLAGS.max_seq_length <= FLAGS.max_query_length + 3:\n",
    "    raise ValueError(\n",
    "        \"The max_seq_length (%d) must be greater than max_query_length \"\n",
    "        \"(%d) + 3\" % (FLAGS.max_seq_length, FLAGS.max_query_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### <span style=\"color:navy\"> Step 3 - Define Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def main(_):\n",
    "  tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "  bert_config = modeling.BertConfig.from_json_file(FLAGS.bert_config_file)\n",
    "\n",
    "  validate_flags_or_throw(bert_config)\n",
    "\n",
    "  tf.gfile.MakeDirs(FLAGS.output_dir)\n",
    "\n",
    "  tokenizer = tokenization.FullTokenizer(\n",
    "      vocab_file=FLAGS.vocab_file, do_lower_case=FLAGS.do_lower_case)\n",
    "\n",
    "  tpu_cluster_resolver = None\n",
    "  if FLAGS.use_tpu and FLAGS.tpu_name:\n",
    "    tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(\n",
    "        FLAGS.tpu_name, zone=FLAGS.tpu_zone, project=FLAGS.gcp_project)\n",
    "\n",
    "  is_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n",
    "  run_config = tf.contrib.tpu.RunConfig(\n",
    "      cluster=tpu_cluster_resolver,\n",
    "      master=FLAGS.master,\n",
    "      model_dir=FLAGS.output_dir,\n",
    "      save_checkpoints_steps=FLAGS.save_checkpoints_steps,\n",
    "      tpu_config=tf.contrib.tpu.TPUConfig(\n",
    "          iterations_per_loop=FLAGS.iterations_per_loop,\n",
    "          num_shards=FLAGS.num_tpu_cores,\n",
    "          per_host_input_for_training=is_per_host))\n",
    "\n",
    "  train_examples = None\n",
    "  num_train_steps = None\n",
    "  num_warmup_steps = None\n",
    "  if FLAGS.do_train:\n",
    "    train_examples = read_squad_examples(\n",
    "        input_file=FLAGS.train_file, is_training=True)\n",
    "    \n",
    "    #print (\"Anshoo - \", len(train_examples))\n",
    "    \n",
    "    num_train_steps = int(\n",
    "        len(train_examples) / FLAGS.train_batch_size * FLAGS.num_train_epochs)\n",
    "    num_warmup_steps = int(num_train_steps * FLAGS.warmup_proportion)\n",
    "\n",
    "    # Pre-shuffle the input to avoid having to make a very large shuffle\n",
    "    # buffer in in the `input_fn`.\n",
    "    rng = random.Random(12345)\n",
    "    rng.shuffle(train_examples)\n",
    "\n",
    "  model_fn = model_fn_builder(\n",
    "      bert_config=bert_config,\n",
    "      init_checkpoint=FLAGS.init_checkpoint,\n",
    "      learning_rate=FLAGS.learning_rate,\n",
    "      num_train_steps=num_train_steps,\n",
    "      num_warmup_steps=num_warmup_steps,\n",
    "      use_tpu=FLAGS.use_tpu,\n",
    "      use_one_hot_embeddings=FLAGS.use_tpu)\n",
    "\n",
    "  # If TPU is not available, this will fall back to normal Estimator on CPU\n",
    "  # or GPU.\n",
    "  estimator = tf.contrib.tpu.TPUEstimator(\n",
    "      use_tpu=FLAGS.use_tpu,\n",
    "      model_fn=model_fn,\n",
    "      config=run_config,\n",
    "      train_batch_size=FLAGS.train_batch_size,\n",
    "      predict_batch_size=FLAGS.predict_batch_size)\n",
    "\n",
    "  if FLAGS.do_train:\n",
    "    # We write to a temporary file to avoid storing very large constant tensors\n",
    "    # in memory.\n",
    "    train_writer = FeatureWriter(\n",
    "        filename=os.path.join(FLAGS.output_dir, \"train.tf_record\"),\n",
    "        is_training=True)\n",
    "    convert_examples_to_features(\n",
    "        examples=train_examples,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=FLAGS.max_seq_length,\n",
    "        doc_stride=FLAGS.doc_stride,\n",
    "        max_query_length=FLAGS.max_query_length,\n",
    "        is_training=True,\n",
    "        output_fn=train_writer.process_feature)\n",
    "    train_writer.close()\n",
    "\n",
    "    tf.logging.info(\"***** Running training *****\")\n",
    "    tf.logging.info(\"  Num orig examples = %d\", len(train_examples))\n",
    "    tf.logging.info(\"  Num split examples = %d\", train_writer.num_features)\n",
    "    tf.logging.info(\"  Batch size = %d\", FLAGS.train_batch_size)\n",
    "    tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
    "    del train_examples\n",
    "\n",
    "    train_input_fn = input_fn_builder(\n",
    "        input_file=train_writer.filename,\n",
    "        seq_length=FLAGS.max_seq_length,\n",
    "        is_training=True,\n",
    "        drop_remainder=True)\n",
    "    estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "\n",
    "  if FLAGS.do_predict:\n",
    "    eval_examples = read_squad_examples(\n",
    "        input_file=FLAGS.predict_file, is_training=False)\n",
    "\n",
    "    eval_writer = FeatureWriter(\n",
    "        filename=os.path.join(FLAGS.output_dir, \"eval.tf_record\"),\n",
    "        is_training=False)\n",
    "    eval_features = []\n",
    "\n",
    "    def append_feature(feature):\n",
    "      eval_features.append(feature)\n",
    "      eval_writer.process_feature(feature)\n",
    "\n",
    "    convert_examples_to_features(\n",
    "        examples=eval_examples,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=FLAGS.max_seq_length,\n",
    "        doc_stride=FLAGS.doc_stride,\n",
    "        max_query_length=FLAGS.max_query_length,\n",
    "        is_training=False,\n",
    "        output_fn=append_feature)\n",
    "    eval_writer.close()\n",
    "\n",
    "    tf.logging.info(\"***** Running predictions *****\")\n",
    "    tf.logging.info(\"  Num orig examples = %d\", len(eval_examples))\n",
    "    tf.logging.info(\"  Num split examples = %d\", len(eval_features))\n",
    "    tf.logging.info(\"  Batch size = %d\", FLAGS.predict_batch_size)\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    predict_input_fn = input_fn_builder(\n",
    "        input_file=eval_writer.filename,\n",
    "        seq_length=FLAGS.max_seq_length,\n",
    "        is_training=False,\n",
    "        drop_remainder=False)\n",
    "\n",
    "    # If running eval on the TPU, you will need to specify the number of\n",
    "    # steps.\n",
    "    all_results = []\n",
    "    for result in estimator.predict(\n",
    "        predict_input_fn, yield_single_examples=True):\n",
    "      if len(all_results) % 1000 == 0:\n",
    "        tf.logging.info(\"Processing example: %d\" % (len(all_results)))\n",
    "      unique_id = int(result[\"unique_ids\"])\n",
    "      start_logits = [float(x) for x in result[\"start_logits\"].flat]\n",
    "      end_logits = [float(x) for x in result[\"end_logits\"].flat]\n",
    "      all_results.append(\n",
    "          RawResult(\n",
    "              unique_id=unique_id,\n",
    "              start_logits=start_logits,\n",
    "              end_logits=end_logits))\n",
    "\n",
    "    output_prediction_file = os.path.join(FLAGS.output_dir, \"predictions.json\")\n",
    "    output_nbest_file = os.path.join(FLAGS.output_dir, \"nbest_predictions.json\")\n",
    "    output_null_log_odds_file = os.path.join(FLAGS.output_dir, \"null_odds.json\")\n",
    "\n",
    "    write_predictions(eval_examples, eval_features, all_results,\n",
    "                      FLAGS.n_best_size, FLAGS.max_answer_length,\n",
    "                      FLAGS.do_lower_case, output_prediction_file,\n",
    "                      output_nbest_file, output_null_log_odds_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### <span style=\"color:navy\"> Step x - RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anmehra/anaconda3/lib/python3.6/site-packages/absl/flags/_validators.py:359: UserWarning: Flag --vocab_file has a non-None default value; therefore, mark_flag_as_required will pass even if flag is not specified in the command line!\n",
      "  'command line!' % flag_name)\n",
      "/home/anmehra/anaconda3/lib/python3.6/site-packages/absl/flags/_validators.py:359: UserWarning: Flag --bert_config_file has a non-None default value; therefore, mark_flag_as_required will pass even if flag is not specified in the command line!\n",
      "  'command line!' % flag_name)\n",
      "/home/anmehra/anaconda3/lib/python3.6/site-packages/absl/flags/_validators.py:359: UserWarning: Flag --output_dir has a non-None default value; therefore, mark_flag_as_required will pass even if flag is not specified in the command line!\n",
      "  'command line!' % flag_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anshoo -  130319\n",
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f64c635c620>) includes params argument, but params are not passed to Estimator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0501 18:19:36.870299 140073664845568 tf_logging.py:125] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f64c635c620>) includes params argument, but params are not passed to Estimator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'squad/output/jupyter', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f64c68ef748>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, computation_shape=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None), '_cluster': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.872109 140073664845568 tf_logging.py:115] Using config: {'_model_dir': 'squad/output/jupyter', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f64c68ef748>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, computation_shape=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None), '_cluster': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.873542 140073664845568 tf_logging.py:115] _TPUContext: eval_on_tpu True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0501 18:19:36.874851 140073664845568 tf_logging.py:125] eval_on_tpu ignored because use_tpu is False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.879113 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.879891 140073664845568 tf_logging.py:115] unique_id: 1000000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.880894 140073664845568 tf_logging.py:115] example_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.881757 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] what is the name of the act that was a success in creating boundaries for the crown and the e ##ic for being subjective ? [SEP] pitt ' s act was deemed a failure because it quickly became apparent that the boundaries between government control and the company ' s powers were ne ##bu ##lous and highly subjective . the government felt obliged to respond to humanitarian calls for better treatment of local peoples in british - occupied territories . edmund burke , a former east india company shareholder and diplomat , was moved to address the situation and introduced a new regulating bill in 1783 . the bill was defeated amid lobbying by company loyalists and accusations of ne ##pot ##ism in the bill ' s recommendations for the appointment of councillors . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.882690 140073664845568 tf_logging.py:115] tokens: [CLS] what is the name of the act that was a success in creating boundaries for the crown and the e ##ic for being subjective ? [SEP] pitt ' s act was deemed a failure because it quickly became apparent that the boundaries between government control and the company ' s powers were ne ##bu ##lous and highly subjective . the government felt obliged to respond to humanitarian calls for better treatment of local peoples in british - occupied territories . edmund burke , a former east india company shareholder and diplomat , was moved to address the situation and introduced a new regulating bill in 1783 . the bill was defeated amid lobbying by company loyalists and accusations of ne ##pot ##ism in the bill ' s recommendations for the appointment of councillors . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 27:0 28:0 29:0 30:1 31:2 32:3 33:4 34:5 35:6 36:7 37:8 38:9 39:10 40:11 41:12 42:13 43:14 44:15 45:16 46:17 47:18 48:19 49:19 50:19 51:20 52:21 53:22 54:22 55:22 56:23 57:24 58:25 59:25 60:26 61:27 62:28 63:29 64:30 65:31 66:32 67:33 68:34 69:35 70:36 71:37 72:38 73:39 74:40 75:41 76:42 77:42 78:42 79:43 80:43 81:44 82:45 83:45 84:46 85:47 86:48 87:49 88:50 89:51 90:52 91:53 92:53 93:54 94:55 95:56 96:57 97:58 98:59 99:60 100:61 101:62 102:63 103:64 104:65 105:66 106:67 107:67 108:68 109:69 110:70 111:71 112:72 113:73 114:74 115:75 116:76 117:77 118:78 119:79 120:80 121:80 122:80 123:81 124:82 125:83 126:83 127:83 128:84 129:85 130:86 131:87 132:88 133:89 134:89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.883575 140073664845568 tf_logging.py:115] token_to_orig_map: 27:0 28:0 29:0 30:1 31:2 32:3 33:4 34:5 35:6 36:7 37:8 38:9 39:10 40:11 41:12 42:13 43:14 44:15 45:16 46:17 47:18 48:19 49:19 50:19 51:20 52:21 53:22 54:22 55:22 56:23 57:24 58:25 59:25 60:26 61:27 62:28 63:29 64:30 65:31 66:32 67:33 68:34 69:35 70:36 71:37 72:38 73:39 74:40 75:41 76:42 77:42 78:42 79:43 80:43 81:44 82:45 83:45 84:46 85:47 86:48 87:49 88:50 89:51 90:52 91:53 92:53 93:54 94:55 95:56 96:57 97:58 98:59 99:60 100:61 101:62 102:63 103:64 104:65 105:66 106:67 107:67 108:68 109:69 110:70 111:71 112:72 113:73 114:74 115:75 116:76 117:77 118:78 119:79 120:80 121:80 122:80 123:81 124:82 125:83 126:83 127:83 128:84 129:85 130:86 131:87 132:88 133:89 134:89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.884583 140073664845568 tf_logging.py:115] token_is_max_context: 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2054 2003 1996 2171 1997 1996 2552 2008 2001 1037 3112 1999 4526 7372 2005 1996 4410 1998 1996 1041 2594 2005 2108 20714 1029 102 15091 1005 1055 2552 2001 8357 1037 4945 2138 2009 2855 2150 6835 2008 1996 7372 2090 2231 2491 1998 1996 2194 1005 1055 4204 2020 11265 8569 15534 1998 3811 20714 1012 1996 2231 2371 14723 2000 6869 2000 11470 4455 2005 2488 3949 1997 2334 7243 1999 2329 1011 4548 6500 1012 9493 9894 1010 1037 2280 2264 2634 2194 18668 1998 11125 1010 2001 2333 2000 4769 1996 3663 1998 3107 1037 2047 21575 3021 1999 15331 1012 1996 3021 2001 3249 13463 19670 2011 2194 26590 1998 13519 1997 11265 11008 2964 1999 1996 3021 1005 1055 11433 2005 1996 6098 1997 13189 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.885515 140073664845568 tf_logging.py:115] input_ids: 101 2054 2003 1996 2171 1997 1996 2552 2008 2001 1037 3112 1999 4526 7372 2005 1996 4410 1998 1996 1041 2594 2005 2108 20714 1029 102 15091 1005 1055 2552 2001 8357 1037 4945 2138 2009 2855 2150 6835 2008 1996 7372 2090 2231 2491 1998 1996 2194 1005 1055 4204 2020 11265 8569 15534 1998 3811 20714 1012 1996 2231 2371 14723 2000 6869 2000 11470 4455 2005 2488 3949 1997 2334 7243 1999 2329 1011 4548 6500 1012 9493 9894 1010 1037 2280 2264 2634 2194 18668 1998 11125 1010 2001 2333 2000 4769 1996 3663 1998 3107 1037 2047 21575 3021 1999 15331 1012 1996 3021 2001 3249 13463 19670 2011 2194 26590 1998 13519 1997 11265 11008 2964 1999 1996 3021 1005 1055 11433 2005 1996 6098 1997 13189 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.886508 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.887350 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:impossible example\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.888164 140073664845568 tf_logging.py:115] impossible example\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.893978 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.895034 140073664845568 tf_logging.py:115] unique_id: 1000000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.895861 140073664845568 tf_logging.py:115] example_index: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.896852 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] what do winners of the continental competition get to do ? [SEP] after the world cup , the most important international football competitions are the continental championships , which are organised by each continental confederation and contested between national teams . these are the european championship ( uefa ) , the copa america ( con ##me ##bol ) , african cup of nations ( caf ) , the asian cup ( afc ) , the concacaf gold cup ( concacaf ) and the of ##c nations cup ( of ##c ) . the fifa confederation ##s cup is contested by the winners of all six continental championships , the current fifa world cup champions and the country which is hosting the confederation ##s cup . this is generally regarded as a warm - up tournament for the upcoming fifa world cup and does not carry the same prestige as the world cup itself . the most prestigious competitions in club football are the respective continental championships , which are generally contested between national champions , for example the uefa champions league in europe and the copa libertadores in south america . the winners of each continental competition contest the fifa club world cup . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.897835 140073664845568 tf_logging.py:115] tokens: [CLS] what do winners of the continental competition get to do ? [SEP] after the world cup , the most important international football competitions are the continental championships , which are organised by each continental confederation and contested between national teams . these are the european championship ( uefa ) , the copa america ( con ##me ##bol ) , african cup of nations ( caf ) , the asian cup ( afc ) , the concacaf gold cup ( concacaf ) and the of ##c nations cup ( of ##c ) . the fifa confederation ##s cup is contested by the winners of all six continental championships , the current fifa world cup champions and the country which is hosting the confederation ##s cup . this is generally regarded as a warm - up tournament for the upcoming fifa world cup and does not carry the same prestige as the world cup itself . the most prestigious competitions in club football are the respective continental championships , which are generally contested between national champions , for example the uefa champions league in europe and the copa libertadores in south america . the winners of each continental competition contest the fifa club world cup . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 13:0 14:1 15:2 16:3 17:3 18:4 19:5 20:6 21:7 22:8 23:9 24:10 25:11 26:12 27:13 28:13 29:14 30:15 31:16 32:17 33:18 34:19 35:20 36:21 37:22 38:23 39:24 40:25 41:25 42:26 43:27 44:28 45:29 46:30 47:31 48:31 49:31 50:31 51:32 52:33 53:34 54:35 55:35 56:35 57:35 58:35 59:35 60:36 61:37 62:38 63:39 64:40 65:40 66:40 67:40 68:41 69:42 70:43 71:44 72:44 73:44 74:44 75:45 76:46 77:47 78:48 79:49 80:49 81:49 82:50 83:51 84:52 85:52 86:53 87:54 88:55 89:55 90:55 91:55 92:55 93:56 94:57 95:58 96:58 97:59 98:60 99:61 100:62 101:63 102:64 103:65 104:66 105:67 106:68 107:69 108:69 109:70 110:71 111:72 112:73 113:74 114:75 115:76 116:77 117:78 118:79 119:80 120:81 121:82 122:83 123:83 124:84 125:84 126:85 127:86 128:87 129:88 130:89 131:90 132:91 133:91 134:91 135:92 136:93 137:94 138:95 139:96 140:97 141:98 142:99 143:100 144:101 145:102 146:103 147:104 148:105 149:106 150:107 151:108 152:109 153:110 154:110 155:111 156:112 157:113 158:114 159:115 160:116 161:117 162:118 163:119 164:120 165:121 166:122 167:122 168:123 169:124 170:125 171:126 172:127 173:128 174:129 175:129 176:130 177:131 178:132 179:133 180:134 181:135 182:136 183:137 184:138 185:139 186:140 187:141 188:142 189:143 190:144 191:144 192:145 193:146 194:147 195:148 196:149 197:150 198:151 199:152 200:153 201:154 202:155 203:156 204:156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.898892 140073664845568 tf_logging.py:115] token_to_orig_map: 13:0 14:1 15:2 16:3 17:3 18:4 19:5 20:6 21:7 22:8 23:9 24:10 25:11 26:12 27:13 28:13 29:14 30:15 31:16 32:17 33:18 34:19 35:20 36:21 37:22 38:23 39:24 40:25 41:25 42:26 43:27 44:28 45:29 46:30 47:31 48:31 49:31 50:31 51:32 52:33 53:34 54:35 55:35 56:35 57:35 58:35 59:35 60:36 61:37 62:38 63:39 64:40 65:40 66:40 67:40 68:41 69:42 70:43 71:44 72:44 73:44 74:44 75:45 76:46 77:47 78:48 79:49 80:49 81:49 82:50 83:51 84:52 85:52 86:53 87:54 88:55 89:55 90:55 91:55 92:55 93:56 94:57 95:58 96:58 97:59 98:60 99:61 100:62 101:63 102:64 103:65 104:66 105:67 106:68 107:69 108:69 109:70 110:71 111:72 112:73 113:74 114:75 115:76 116:77 117:78 118:79 119:80 120:81 121:82 122:83 123:83 124:84 125:84 126:85 127:86 128:87 129:88 130:89 131:90 132:91 133:91 134:91 135:92 136:93 137:94 138:95 139:96 140:97 141:98 142:99 143:100 144:101 145:102 146:103 147:104 148:105 149:106 150:107 151:108 152:109 153:110 154:110 155:111 156:112 157:113 158:114 159:115 160:116 161:117 162:118 163:119 164:120 165:121 166:122 167:122 168:123 169:124 170:125 171:126 172:127 173:128 174:129 175:129 176:130 177:131 178:132 179:133 180:134 181:135 182:136 183:137 184:138 185:139 186:140 187:141 188:142 189:143 190:144 191:144 192:145 193:146 194:147 195:148 196:149 197:150 198:151 199:152 200:153 201:154 202:155 203:156 204:156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.899732 140073664845568 tf_logging.py:115] token_is_max_context: 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2054 2079 4791 1997 1996 6803 2971 2131 2000 2079 1029 102 2044 1996 2088 2452 1010 1996 2087 2590 2248 2374 6479 2024 1996 6803 3219 1010 2029 2024 7362 2011 2169 6803 11078 1998 7259 2090 2120 2780 1012 2122 2024 1996 2647 2528 1006 6663 1007 1010 1996 10613 2637 1006 9530 4168 14956 1007 1010 3060 2452 1997 3741 1006 24689 1007 1010 1996 4004 2452 1006 10511 1007 1010 1996 22169 2751 2452 1006 22169 1007 1998 1996 1997 2278 3741 2452 1006 1997 2278 1007 1012 1996 5713 11078 2015 2452 2003 7259 2011 1996 4791 1997 2035 2416 6803 3219 1010 1996 2783 5713 2088 2452 3966 1998 1996 2406 2029 2003 9936 1996 11078 2015 2452 1012 2023 2003 3227 5240 2004 1037 4010 1011 2039 2977 2005 1996 9046 5713 2088 2452 1998 2515 2025 4287 1996 2168 14653 2004 1996 2088 2452 2993 1012 1996 2087 8919 6479 1999 2252 2374 2024 1996 7972 6803 3219 1010 2029 2024 3227 7259 2090 2120 3966 1010 2005 2742 1996 6663 3966 2223 1999 2885 1998 1996 10613 27968 1999 2148 2637 1012 1996 4791 1997 2169 6803 2971 5049 1996 5713 2252 2088 2452 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.900712 140073664845568 tf_logging.py:115] input_ids: 101 2054 2079 4791 1997 1996 6803 2971 2131 2000 2079 1029 102 2044 1996 2088 2452 1010 1996 2087 2590 2248 2374 6479 2024 1996 6803 3219 1010 2029 2024 7362 2011 2169 6803 11078 1998 7259 2090 2120 2780 1012 2122 2024 1996 2647 2528 1006 6663 1007 1010 1996 10613 2637 1006 9530 4168 14956 1007 1010 3060 2452 1997 3741 1006 24689 1007 1010 1996 4004 2452 1006 10511 1007 1010 1996 22169 2751 2452 1006 22169 1007 1998 1996 1997 2278 3741 2452 1006 1997 2278 1007 1012 1996 5713 11078 2015 2452 2003 7259 2011 1996 4791 1997 2035 2416 6803 3219 1010 1996 2783 5713 2088 2452 3966 1998 1996 2406 2029 2003 9936 1996 11078 2015 2452 1012 2023 2003 3227 5240 2004 1037 4010 1011 2039 2977 2005 1996 9046 5713 2088 2452 1998 2515 2025 4287 1996 2168 14653 2004 1996 2088 2452 2993 1012 1996 2087 8919 6479 1999 2252 2374 2024 1996 7972 6803 3219 1010 2029 2024 3227 7259 2090 2120 3966 1010 2005 2742 1996 6663 3966 2223 1999 2885 1998 1996 10613 27968 1999 2148 2637 1012 1996 4791 1997 2169 6803 2971 5049 1996 5713 2252 2088 2452 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.901573 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.902595 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:start_position: 198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.903522 140073664845568 tf_logging.py:115] start_position: 198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:end_position: 203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.904320 140073664845568 tf_logging.py:115] end_position: 203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:answer: contest the fifa club world cup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.904986 140073664845568 tf_logging.py:115] answer: contest the fifa club world cup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.908978 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.909927 140073664845568 tf_logging.py:115] unique_id: 1000000002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.910944 140073664845568 tf_logging.py:115] example_index: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.911780 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] what did frederick zu ##gi ##be study in detail for this book ? [SEP] in his book the cr ##uc ##if ##ix ##ion of jesus , physician and forensic path ##ologist frederick zu ##gi ##be studied the likely circumstances of the death of jesus in great detail . zu ##gi ##be carried out a number of experiments over several years to test his theories while he was a medical examiner . these studies included experiments in which volunteers with specific weights were hanging at specific angles and the amount of pull on each hand was measured , in cases where the feet were also secured or not . in these cases the amount of pull and the corresponding pain was found to be significant . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.912670 140073664845568 tf_logging.py:115] tokens: [CLS] what did frederick zu ##gi ##be study in detail for this book ? [SEP] in his book the cr ##uc ##if ##ix ##ion of jesus , physician and forensic path ##ologist frederick zu ##gi ##be studied the likely circumstances of the death of jesus in great detail . zu ##gi ##be carried out a number of experiments over several years to test his theories while he was a medical examiner . these studies included experiments in which volunteers with specific weights were hanging at specific angles and the amount of pull on each hand was measured , in cases where the feet were also secured or not . in these cases the amount of pull and the corresponding pain was found to be significant . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 15:0 16:1 17:2 18:3 19:4 20:4 21:4 22:4 23:4 24:5 25:6 26:6 27:7 28:8 29:9 30:10 31:10 32:11 33:12 34:12 35:12 36:13 37:14 38:15 39:16 40:17 41:18 42:19 43:20 44:21 45:22 46:23 47:24 48:24 49:25 50:25 51:25 52:26 53:27 54:28 55:29 56:30 57:31 58:32 59:33 60:34 61:35 62:36 63:37 64:38 65:39 66:40 67:41 68:42 69:43 70:44 71:44 72:45 73:46 74:47 75:48 76:49 77:50 78:51 79:52 80:53 81:54 82:55 83:56 84:57 85:58 86:59 87:60 88:61 89:62 90:63 91:64 92:65 93:66 94:67 95:68 96:69 97:69 98:70 99:71 100:72 101:73 102:74 103:75 104:76 105:77 106:78 107:79 108:79 109:80 110:81 111:82 112:83 113:84 114:85 115:86 116:87 117:88 118:89 119:90 120:91 121:92 122:93 123:94 124:95 125:95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.913397 140073664845568 tf_logging.py:115] token_to_orig_map: 15:0 16:1 17:2 18:3 19:4 20:4 21:4 22:4 23:4 24:5 25:6 26:6 27:7 28:8 29:9 30:10 31:10 32:11 33:12 34:12 35:12 36:13 37:14 38:15 39:16 40:17 41:18 42:19 43:20 44:21 45:22 46:23 47:24 48:24 49:25 50:25 51:25 52:26 53:27 54:28 55:29 56:30 57:31 58:32 59:33 60:34 61:35 62:36 63:37 64:38 65:39 66:40 67:41 68:42 69:43 70:44 71:44 72:45 73:46 74:47 75:48 76:49 77:50 78:51 79:52 80:53 81:54 82:55 83:56 84:57 85:58 86:59 87:60 88:61 89:62 90:63 91:64 92:65 93:66 94:67 95:68 96:69 97:69 98:70 99:71 100:72 101:73 102:74 103:75 104:76 105:77 106:78 107:79 108:79 109:80 110:81 111:82 112:83 113:84 114:85 115:86 116:87 117:88 118:89 119:90 120:91 121:92 122:93 123:94 124:95 125:95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.914316 140073664845568 tf_logging.py:115] token_is_max_context: 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2054 2106 5406 16950 5856 4783 2817 1999 6987 2005 2023 2338 1029 102 1999 2010 2338 1996 13675 14194 10128 7646 3258 1997 4441 1010 7522 1998 15359 4130 8662 5406 16950 5856 4783 3273 1996 3497 6214 1997 1996 2331 1997 4441 1999 2307 6987 1012 16950 5856 4783 3344 2041 1037 2193 1997 7885 2058 2195 2086 2000 3231 2010 8106 2096 2002 2001 1037 2966 19684 1012 2122 2913 2443 7885 1999 2029 7314 2007 3563 15871 2020 5689 2012 3563 12113 1998 1996 3815 1997 4139 2006 2169 2192 2001 7594 1010 1999 3572 2073 1996 2519 2020 2036 7119 2030 2025 1012 1999 2122 3572 1996 3815 1997 4139 1998 1996 7978 3255 2001 2179 2000 2022 3278 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.915083 140073664845568 tf_logging.py:115] input_ids: 101 2054 2106 5406 16950 5856 4783 2817 1999 6987 2005 2023 2338 1029 102 1999 2010 2338 1996 13675 14194 10128 7646 3258 1997 4441 1010 7522 1998 15359 4130 8662 5406 16950 5856 4783 3273 1996 3497 6214 1997 1996 2331 1997 4441 1999 2307 6987 1012 16950 5856 4783 3344 2041 1037 2193 1997 7885 2058 2195 2086 2000 3231 2010 8106 2096 2002 2001 1037 2966 19684 1012 2122 2913 2443 7885 1999 2029 7314 2007 3563 15871 2020 5689 2012 3563 12113 1998 1996 3815 1997 4139 2006 2169 2192 2001 7594 1010 1999 3572 2073 1996 2519 2020 2036 7119 2030 2025 1012 1999 2122 3572 1996 3815 1997 4139 1998 1996 7978 3255 2001 2179 2000 2022 3278 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.915891 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.916611 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:start_position: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.917375 140073664845568 tf_logging.py:115] start_position: 37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:end_position: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.918128 140073664845568 tf_logging.py:115] end_position: 44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:answer: the likely circumstances of the death of jesus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.918844 140073664845568 tf_logging.py:115] answer: the likely circumstances of the death of jesus\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.922643 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.923492 140073664845568 tf_logging.py:115] unique_id: 1000000003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.924257 140073664845568 tf_logging.py:115] example_index: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.925034 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] how many millions of tourists does greece ban each year ? [SEP] greece attracts more than 16 million tourists each year , thus contributing 18 . 2 % to the nation ' s gdp in 2008 according to an o ##ec ##d report . the same survey showed that the average tourist expenditure while in greece was $ 1 , 07 ##3 , ranking greece 10th in the world . the number of jobs directly or indirectly related to the tourism sector were 840 , 000 in 2008 and represented 19 % of the country ' s total labor force . in 2009 , greece welcomed over 19 . 3 million tourists , a major increase from the 17 . 7 million tourists the country welcomed in 2008 . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.925982 140073664845568 tf_logging.py:115] tokens: [CLS] how many millions of tourists does greece ban each year ? [SEP] greece attracts more than 16 million tourists each year , thus contributing 18 . 2 % to the nation ' s gdp in 2008 according to an o ##ec ##d report . the same survey showed that the average tourist expenditure while in greece was $ 1 , 07 ##3 , ranking greece 10th in the world . the number of jobs directly or indirectly related to the tourism sector were 840 , 000 in 2008 and represented 19 % of the country ' s total labor force . in 2009 , greece welcomed over 19 . 3 million tourists , a major increase from the 17 . 7 million tourists the country welcomed in 2008 . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 13:0 14:1 15:2 16:3 17:4 18:5 19:6 20:7 21:8 22:8 23:9 24:10 25:11 26:11 27:11 28:11 29:12 30:13 31:14 32:14 33:14 34:15 35:16 36:17 37:18 38:19 39:20 40:21 41:21 42:21 43:22 44:22 45:23 46:24 47:25 48:26 49:27 50:28 51:29 52:30 53:31 54:32 55:33 56:34 57:35 58:36 59:36 60:36 61:36 62:36 63:36 64:37 65:38 66:39 67:40 68:41 69:42 70:42 71:43 72:44 73:45 74:46 75:47 76:48 77:49 78:50 79:51 80:52 81:53 82:54 83:55 84:56 85:56 86:56 87:57 88:58 89:59 90:60 91:61 92:61 93:62 94:63 95:64 96:64 97:64 98:65 99:66 100:67 101:67 102:68 103:69 104:69 105:70 106:71 107:72 108:73 109:73 110:73 111:74 112:75 113:75 114:76 115:77 116:78 117:79 118:80 119:81 120:81 121:81 122:82 123:83 124:84 125:85 126:86 127:87 128:88 129:88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.926915 140073664845568 tf_logging.py:115] token_to_orig_map: 13:0 14:1 15:2 16:3 17:4 18:5 19:6 20:7 21:8 22:8 23:9 24:10 25:11 26:11 27:11 28:11 29:12 30:13 31:14 32:14 33:14 34:15 35:16 36:17 37:18 38:19 39:20 40:21 41:21 42:21 43:22 44:22 45:23 46:24 47:25 48:26 49:27 50:28 51:29 52:30 53:31 54:32 55:33 56:34 57:35 58:36 59:36 60:36 61:36 62:36 63:36 64:37 65:38 66:39 67:40 68:41 69:42 70:42 71:43 72:44 73:45 74:46 75:47 76:48 77:49 78:50 79:51 80:52 81:53 82:54 83:55 84:56 85:56 86:56 87:57 88:58 89:59 90:60 91:61 92:61 93:62 94:63 95:64 96:64 97:64 98:65 99:66 100:67 101:67 102:68 103:69 104:69 105:70 106:71 107:72 108:73 109:73 110:73 111:74 112:75 113:75 114:76 115:77 116:78 117:79 118:80 119:81 120:81 121:81 122:82 123:83 124:84 125:85 126:86 127:87 128:88 129:88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.927656 140073664845568 tf_logging.py:115] token_is_max_context: 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2129 2116 8817 1997 9045 2515 5483 7221 2169 2095 1029 102 5483 17771 2062 2084 2385 2454 9045 2169 2095 1010 2947 8020 2324 1012 1016 1003 2000 1996 3842 1005 1055 14230 1999 2263 2429 2000 2019 1051 8586 2094 3189 1012 1996 2168 5002 3662 2008 1996 2779 7538 20700 2096 1999 5483 2001 1002 1015 1010 5718 2509 1010 5464 5483 6049 1999 1996 2088 1012 1996 2193 1997 5841 3495 2030 17351 3141 2000 1996 6813 4753 2020 28122 1010 2199 1999 2263 1998 3421 2539 1003 1997 1996 2406 1005 1055 2561 4450 2486 1012 1999 2268 1010 5483 10979 2058 2539 1012 1017 2454 9045 1010 1037 2350 3623 2013 1996 2459 1012 1021 2454 9045 1996 2406 10979 1999 2263 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.928481 140073664845568 tf_logging.py:115] input_ids: 101 2129 2116 8817 1997 9045 2515 5483 7221 2169 2095 1029 102 5483 17771 2062 2084 2385 2454 9045 2169 2095 1010 2947 8020 2324 1012 1016 1003 2000 1996 3842 1005 1055 14230 1999 2263 2429 2000 2019 1051 8586 2094 3189 1012 1996 2168 5002 3662 2008 1996 2779 7538 20700 2096 1999 5483 2001 1002 1015 1010 5718 2509 1010 5464 5483 6049 1999 1996 2088 1012 1996 2193 1997 5841 3495 2030 17351 3141 2000 1996 6813 4753 2020 28122 1010 2199 1999 2263 1998 3421 2539 1003 1997 1996 2406 1005 1055 2561 4450 2486 1012 1999 2268 1010 5483 10979 2058 2539 1012 1017 2454 9045 1010 1037 2350 3623 2013 1996 2459 1012 1021 2454 9045 1996 2406 10979 1999 2263 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.929358 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.930362 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:impossible example\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.931119 140073664845568 tf_logging.py:115] impossible example\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.935496 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.936435 140073664845568 tf_logging.py:115] unique_id: 1000000004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.937275 140073664845568 tf_logging.py:115] example_index: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.938168 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] what is the main role of the cabinet of government ministers ? [SEP] when the party is represented by members in the lower house of parliament , the party leader simultaneously serves as the leader of the parliamentary group of that full party representation ; depending on a minimum number of seats held , westminster - based parties typically allow for leaders to form front ##ben ##ch teams of senior fellow members of the parliamentary group to serve as critics of aspects of government policy . when a party becomes the largest party not part of the government , the party ' s parliamentary group forms the official opposition , with official opposition front ##ben ##ch team members often forming the official opposition shadow cabinet . when a party achieve ##s enough seats in an election to form a majority , the party ' s front ##ben ##ch becomes the cabinet of government ministers . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.939057 140073664845568 tf_logging.py:115] tokens: [CLS] what is the main role of the cabinet of government ministers ? [SEP] when the party is represented by members in the lower house of parliament , the party leader simultaneously serves as the leader of the parliamentary group of that full party representation ; depending on a minimum number of seats held , westminster - based parties typically allow for leaders to form front ##ben ##ch teams of senior fellow members of the parliamentary group to serve as critics of aspects of government policy . when a party becomes the largest party not part of the government , the party ' s parliamentary group forms the official opposition , with official opposition front ##ben ##ch team members often forming the official opposition shadow cabinet . when a party achieve ##s enough seats in an election to form a majority , the party ' s front ##ben ##ch becomes the cabinet of government ministers . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 14:0 15:1 16:2 17:3 18:4 19:5 20:6 21:7 22:8 23:9 24:10 25:11 26:12 27:12 28:13 29:14 30:15 31:16 32:17 33:18 34:19 35:20 36:21 37:22 38:23 39:24 40:25 41:26 42:27 43:28 44:29 45:29 46:30 47:31 48:32 49:33 50:34 51:35 52:36 53:37 54:37 55:38 56:38 57:38 58:39 59:40 60:41 61:42 62:43 63:44 64:45 65:46 66:46 67:46 68:47 69:48 70:49 71:50 72:51 73:52 74:53 75:54 76:55 77:56 78:57 79:58 80:59 81:60 82:61 83:62 84:63 85:64 86:64 87:65 88:66 89:67 90:68 91:69 92:70 93:71 94:72 95:73 96:74 97:75 98:76 99:76 100:77 101:78 102:78 103:78 104:79 105:80 106:81 107:82 108:83 109:84 110:84 111:85 112:86 113:87 114:88 115:88 116:88 117:89 118:90 119:91 120:92 121:93 122:94 123:95 124:96 125:97 126:97 127:98 128:99 129:100 130:101 131:101 132:102 133:103 134:104 135:105 136:106 137:107 138:108 139:109 140:110 141:110 142:111 143:112 144:112 145:112 146:113 147:113 148:113 149:114 150:115 151:116 152:117 153:118 154:119 155:119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.940012 140073664845568 tf_logging.py:115] token_to_orig_map: 14:0 15:1 16:2 17:3 18:4 19:5 20:6 21:7 22:8 23:9 24:10 25:11 26:12 27:12 28:13 29:14 30:15 31:16 32:17 33:18 34:19 35:20 36:21 37:22 38:23 39:24 40:25 41:26 42:27 43:28 44:29 45:29 46:30 47:31 48:32 49:33 50:34 51:35 52:36 53:37 54:37 55:38 56:38 57:38 58:39 59:40 60:41 61:42 62:43 63:44 64:45 65:46 66:46 67:46 68:47 69:48 70:49 71:50 72:51 73:52 74:53 75:54 76:55 77:56 78:57 79:58 80:59 81:60 82:61 83:62 84:63 85:64 86:64 87:65 88:66 89:67 90:68 91:69 92:70 93:71 94:72 95:73 96:74 97:75 98:76 99:76 100:77 101:78 102:78 103:78 104:79 105:80 106:81 107:82 108:83 109:84 110:84 111:85 112:86 113:87 114:88 115:88 116:88 117:89 118:90 119:91 120:92 121:93 122:94 123:95 124:96 125:97 126:97 127:98 128:99 129:100 130:101 131:101 132:102 133:103 134:104 135:105 136:106 137:107 138:108 139:109 140:110 141:110 142:111 143:112 144:112 145:112 146:113 147:113 148:113 149:114 150:115 151:116 152:117 153:118 154:119 155:119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.940871 140073664845568 tf_logging.py:115] token_is_max_context: 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2054 2003 1996 2364 2535 1997 1996 5239 1997 2231 7767 1029 102 2043 1996 2283 2003 3421 2011 2372 1999 1996 2896 2160 1997 3323 1010 1996 2283 3003 7453 4240 2004 1996 3003 1997 1996 5768 2177 1997 2008 2440 2283 6630 1025 5834 2006 1037 6263 2193 1997 4272 2218 1010 9434 1011 2241 4243 4050 3499 2005 4177 2000 2433 2392 10609 2818 2780 1997 3026 3507 2372 1997 1996 5768 2177 2000 3710 2004 4401 1997 5919 1997 2231 3343 1012 2043 1037 2283 4150 1996 2922 2283 2025 2112 1997 1996 2231 1010 1996 2283 1005 1055 5768 2177 3596 1996 2880 4559 1010 2007 2880 4559 2392 10609 2818 2136 2372 2411 5716 1996 2880 4559 5192 5239 1012 2043 1037 2283 6162 2015 2438 4272 1999 2019 2602 2000 2433 1037 3484 1010 1996 2283 1005 1055 2392 10609 2818 4150 1996 5239 1997 2231 7767 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.941782 140073664845568 tf_logging.py:115] input_ids: 101 2054 2003 1996 2364 2535 1997 1996 5239 1997 2231 7767 1029 102 2043 1996 2283 2003 3421 2011 2372 1999 1996 2896 2160 1997 3323 1010 1996 2283 3003 7453 4240 2004 1996 3003 1997 1996 5768 2177 1997 2008 2440 2283 6630 1025 5834 2006 1037 6263 2193 1997 4272 2218 1010 9434 1011 2241 4243 4050 3499 2005 4177 2000 2433 2392 10609 2818 2780 1997 3026 3507 2372 1997 1996 5768 2177 2000 3710 2004 4401 1997 5919 1997 2231 3343 1012 2043 1037 2283 4150 1996 2922 2283 2025 2112 1997 1996 2231 1010 1996 2283 1005 1055 5768 2177 3596 1996 2880 4559 1010 2007 2880 4559 2392 10609 2818 2136 2372 2411 5716 1996 2880 4559 5192 5239 1012 2043 1037 2283 6162 2015 2438 4272 1999 2019 2602 2000 2433 1037 3484 1010 1996 2283 1005 1055 2392 10609 2818 4150 1996 5239 1997 2231 7767 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.942651 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.943531 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:impossible example\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.944224 140073664845568 tf_logging.py:115] impossible example\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.949440 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.950428 140073664845568 tf_logging.py:115] unique_id: 1000000005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.951427 140073664845568 tf_logging.py:115] example_index: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.952343 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] what does the fe ##pc stand for ? [SEP] f ##dr ' s new deal programs often contained equal opportunity clauses stating \" no discrimination shall be made on account of race , color or creed \" , : 11 but the true forerunner to affirmative action was the interior secretary of the time , harold l . ic ##kes . ic ##kes prohibited discrimination in hiring for public works administration funded projects and oversaw not only the institution of a quota system , where contractors were required to employ a fixed percentage of black workers , by robert c . weaver and clark foreman , : 12 but also the equal pay of women proposed by harry hopkins . : 14 ##f ##dr ' s largest contribution to affirmative action , however , lay in his executive order 880 ##2 which prohibited discrimination in the defense industry or government . : 22 the executive order promoted the idea that if taxpayer funds were accepted through a government contract , then all taxpayers should have an equal opportunity to work through the contractor . : 23  4 to enforce this idea , roosevelt created the fair employment practices committee ( fe ##pc ) with the power to investigate hiring practices by government contractors . : 22 [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.953321 140073664845568 tf_logging.py:115] tokens: [CLS] what does the fe ##pc stand for ? [SEP] f ##dr ' s new deal programs often contained equal opportunity clauses stating \" no discrimination shall be made on account of race , color or creed \" , : 11 but the true forerunner to affirmative action was the interior secretary of the time , harold l . ic ##kes . ic ##kes prohibited discrimination in hiring for public works administration funded projects and oversaw not only the institution of a quota system , where contractors were required to employ a fixed percentage of black workers , by robert c . weaver and clark foreman , : 12 but also the equal pay of women proposed by harry hopkins . : 14 ##f ##dr ' s largest contribution to affirmative action , however , lay in his executive order 880 ##2 which prohibited discrimination in the defense industry or government . : 22 the executive order promoted the idea that if taxpayer funds were accepted through a government contract , then all taxpayers should have an equal opportunity to work through the contractor . : 23  4 to enforce this idea , roosevelt created the fair employment practices committee ( fe ##pc ) with the power to investigate hiring practices by government contractors . : 22 [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 10:0 11:0 12:0 13:0 14:1 15:2 16:3 17:4 18:5 19:6 20:7 21:8 22:9 23:10 24:10 25:11 26:12 27:13 28:14 29:15 30:16 31:17 32:18 33:18 34:19 35:20 36:21 37:21 38:21 39:21 40:21 41:22 42:23 43:24 44:25 45:26 46:27 47:28 48:29 49:30 50:31 51:32 52:33 53:34 54:35 55:35 56:36 57:37 58:37 59:38 60:38 61:38 62:39 63:39 64:40 65:41 66:42 67:43 68:44 69:45 70:46 71:47 72:48 73:49 74:50 75:51 76:52 77:53 78:54 79:55 80:56 81:57 82:58 83:59 84:59 85:60 86:61 87:62 88:63 89:64 90:65 91:66 92:67 93:68 94:69 95:70 96:71 97:71 98:72 99:73 100:74 101:74 102:75 103:76 104:77 105:78 106:78 107:78 108:78 109:79 110:80 111:81 112:82 113:83 114:84 115:85 116:86 117:87 118:88 119:89 120:89 121:89 122:89 123:89 124:89 125:89 126:89 127:90 128:91 129:92 130:93 131:94 132:94 133:95 134:95 135:96 136:97 137:98 138:99 139:100 140:101 141:101 142:102 143:103 144:104 145:105 146:106 147:107 148:108 149:109 150:110 151:110 152:110 153:110 154:111 155:112 156:113 157:114 158:115 159:116 160:117 161:118 162:119 163:120 164:121 165:122 166:123 167:124 168:125 169:126 170:126 171:127 172:128 173:129 174:130 175:131 176:132 177:133 178:134 179:135 180:136 181:137 182:138 183:139 184:139 185:139 186:139 187:139 188:139 189:140 190:141 191:142 192:143 193:143 194:144 195:145 196:146 197:147 198:148 199:149 200:150 201:151 202:151 203:151 204:151 205:152 206:153 207:154 208:155 209:156 210:157 211:158 212:159 213:160 214:161 215:161 216:161 217:161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.954356 140073664845568 tf_logging.py:115] token_to_orig_map: 10:0 11:0 12:0 13:0 14:1 15:2 16:3 17:4 18:5 19:6 20:7 21:8 22:9 23:10 24:10 25:11 26:12 27:13 28:14 29:15 30:16 31:17 32:18 33:18 34:19 35:20 36:21 37:21 38:21 39:21 40:21 41:22 42:23 43:24 44:25 45:26 46:27 47:28 48:29 49:30 50:31 51:32 52:33 53:34 54:35 55:35 56:36 57:37 58:37 59:38 60:38 61:38 62:39 63:39 64:40 65:41 66:42 67:43 68:44 69:45 70:46 71:47 72:48 73:49 74:50 75:51 76:52 77:53 78:54 79:55 80:56 81:57 82:58 83:59 84:59 85:60 86:61 87:62 88:63 89:64 90:65 91:66 92:67 93:68 94:69 95:70 96:71 97:71 98:72 99:73 100:74 101:74 102:75 103:76 104:77 105:78 106:78 107:78 108:78 109:79 110:80 111:81 112:82 113:83 114:84 115:85 116:86 117:87 118:88 119:89 120:89 121:89 122:89 123:89 124:89 125:89 126:89 127:90 128:91 129:92 130:93 131:94 132:94 133:95 134:95 135:96 136:97 137:98 138:99 139:100 140:101 141:101 142:102 143:103 144:104 145:105 146:106 147:107 148:108 149:109 150:110 151:110 152:110 153:110 154:111 155:112 156:113 157:114 158:115 159:116 160:117 161:118 162:119 163:120 164:121 165:122 166:123 167:124 168:125 169:126 170:126 171:127 172:128 173:129 174:130 175:131 176:132 177:133 178:134 179:135 180:136 181:137 182:138 183:139 184:139 185:139 186:139 187:139 188:139 189:140 190:141 191:142 192:143 193:143 194:144 195:145 196:146 197:147 198:148 199:149 200:150 201:151 202:151 203:151 204:151 205:152 206:153 207:154 208:155 209:156 210:157 211:158 212:159 213:160 214:161 215:161 216:161 217:161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.955236 140073664845568 tf_logging.py:115] token_is_max_context: 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2054 2515 1996 10768 15042 3233 2005 1029 102 1042 13626 1005 1055 2047 3066 3454 2411 4838 5020 4495 24059 5517 1000 2053 9147 4618 2022 2081 2006 4070 1997 2679 1010 3609 2030 16438 1000 1010 1024 2340 2021 1996 2995 23993 2000 27352 2895 2001 1996 4592 3187 1997 1996 2051 1010 7157 1048 1012 24582 9681 1012 24582 9681 10890 9147 1999 14763 2005 2270 2573 3447 6787 3934 1998 14105 2025 2069 1996 5145 1997 1037 20563 2291 1010 2073 16728 2020 3223 2000 12666 1037 4964 7017 1997 2304 3667 1010 2011 2728 1039 1012 14077 1998 5215 18031 1010 1024 2260 2021 2036 1996 5020 3477 1997 2308 3818 2011 4302 10239 1012 1024 2403 2546 13626 1005 1055 2922 6691 2000 27352 2895 1010 2174 1010 3913 1999 2010 3237 2344 26839 2475 2029 10890 9147 1999 1996 3639 3068 2030 2231 1012 1024 2570 1996 3237 2344 3755 1996 2801 2008 2065 26980 5029 2020 3970 2083 1037 2231 3206 1010 2059 2035 26457 2323 2031 2019 5020 4495 2000 2147 2083 1996 13666 1012 1024 2603 1516 1018 2000 16306 2023 2801 1010 8573 2580 1996 4189 6107 6078 2837 1006 10768 15042 1007 2007 1996 2373 2000 8556 14763 6078 2011 2231 16728 1012 1024 2570 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.956197 140073664845568 tf_logging.py:115] input_ids: 101 2054 2515 1996 10768 15042 3233 2005 1029 102 1042 13626 1005 1055 2047 3066 3454 2411 4838 5020 4495 24059 5517 1000 2053 9147 4618 2022 2081 2006 4070 1997 2679 1010 3609 2030 16438 1000 1010 1024 2340 2021 1996 2995 23993 2000 27352 2895 2001 1996 4592 3187 1997 1996 2051 1010 7157 1048 1012 24582 9681 1012 24582 9681 10890 9147 1999 14763 2005 2270 2573 3447 6787 3934 1998 14105 2025 2069 1996 5145 1997 1037 20563 2291 1010 2073 16728 2020 3223 2000 12666 1037 4964 7017 1997 2304 3667 1010 2011 2728 1039 1012 14077 1998 5215 18031 1010 1024 2260 2021 2036 1996 5020 3477 1997 2308 3818 2011 4302 10239 1012 1024 2403 2546 13626 1005 1055 2922 6691 2000 27352 2895 1010 2174 1010 3913 1999 2010 3237 2344 26839 2475 2029 10890 9147 1999 1996 3639 3068 2030 2231 1012 1024 2570 1996 3237 2344 3755 1996 2801 2008 2065 26980 5029 2020 3970 2083 1037 2231 3206 1010 2059 2035 26457 2323 2031 2019 5020 4495 2000 2147 2083 1996 13666 1012 1024 2603 1516 1018 2000 16306 2023 2801 1010 8573 2580 1996 4189 6107 6078 2837 1006 10768 15042 1007 2007 1996 2373 2000 8556 14763 6078 2011 2231 16728 1012 1024 2570 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.957075 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.958130 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:start_position: 197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.958913 140073664845568 tf_logging.py:115] start_position: 197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:end_position: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.959582 140073664845568 tf_logging.py:115] end_position: 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:answer: fair employment practices committee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.960343 140073664845568 tf_logging.py:115] answer: fair employment practices committee\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.962637 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.963517 140073664845568 tf_logging.py:115] unique_id: 1000000006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.964255 140073664845568 tf_logging.py:115] example_index: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.965060 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] the structures that still remain are open to whom ? [SEP] because it was designated as the national capital , many structures were built around that time . even today , some of them still remain which are open to tourists . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.965783 140073664845568 tf_logging.py:115] tokens: [CLS] the structures that still remain are open to whom ? [SEP] because it was designated as the national capital , many structures were built around that time . even today , some of them still remain which are open to tourists . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 12:0 13:1 14:2 15:3 16:4 17:5 18:6 19:7 20:7 21:8 22:9 23:10 24:11 25:12 26:13 27:14 28:14 29:15 30:16 31:16 32:17 33:18 34:19 35:20 36:21 37:22 38:23 39:24 40:25 41:26 42:26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.966569 140073664845568 tf_logging.py:115] token_to_orig_map: 12:0 13:1 14:2 15:3 16:4 17:5 18:6 19:7 20:7 21:8 22:9 23:10 24:11 25:12 26:13 27:14 28:14 29:15 30:16 31:16 32:17 33:18 34:19 35:20 36:21 37:22 38:23 39:24 40:25 41:26 42:26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.967243 140073664845568 tf_logging.py:115] token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1996 5090 2008 2145 3961 2024 2330 2000 3183 1029 102 2138 2009 2001 4351 2004 1996 2120 3007 1010 2116 5090 2020 2328 2105 2008 2051 1012 2130 2651 1010 2070 1997 2068 2145 3961 2029 2024 2330 2000 9045 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.968016 140073664845568 tf_logging.py:115] input_ids: 101 1996 5090 2008 2145 3961 2024 2330 2000 3183 1029 102 2138 2009 2001 4351 2004 1996 2120 3007 1010 2116 5090 2020 2328 2105 2008 2051 1012 2130 2651 1010 2070 1997 2068 2145 3961 2029 2024 2330 2000 9045 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.968796 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.969665 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:start_position: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.970455 140073664845568 tf_logging.py:115] start_position: 41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:end_position: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.971211 140073664845568 tf_logging.py:115] end_position: 41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:answer: tourists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.971987 140073664845568 tf_logging.py:115] answer: tourists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.975591 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.976497 140073664845568 tf_logging.py:115] unique_id: 1000000007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.977302 140073664845568 tf_logging.py:115] example_index: 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.978197 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] when was the mann act passed ? [SEP] the bureau ' s first official task was visiting and making surveys of the houses of prostitution in preparation for enforcing the \" white slave traffic act , \" or mann act , passed on june 25 , 1910 . in 1932 , it was renamed the united states bureau of investigation . the following year it was linked to the bureau of prohibition and rec ##hri ##sten ##ed the division of investigation ( doi ) before finally becoming an independent service within the department of justice in 1935 . in the same year , its name was officially changed from the division of investigation to the present - day federal bureau of investigation , or fbi . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.979026 140073664845568 tf_logging.py:115] tokens: [CLS] when was the mann act passed ? [SEP] the bureau ' s first official task was visiting and making surveys of the houses of prostitution in preparation for enforcing the \" white slave traffic act , \" or mann act , passed on june 25 , 1910 . in 1932 , it was renamed the united states bureau of investigation . the following year it was linked to the bureau of prohibition and rec ##hri ##sten ##ed the division of investigation ( doi ) before finally becoming an independent service within the department of justice in 1935 . in the same year , its name was officially changed from the division of investigation to the present - day federal bureau of investigation , or fbi . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 9:0 10:1 11:1 12:1 13:2 14:3 15:4 16:5 17:6 18:7 19:8 20:9 21:10 22:11 23:12 24:13 25:14 26:15 27:16 28:17 29:18 30:19 31:20 32:20 33:21 34:22 35:23 36:23 37:23 38:24 39:25 40:26 41:26 42:27 43:28 44:29 45:30 46:30 47:31 48:31 49:32 50:33 51:33 52:34 53:35 54:36 55:37 56:38 57:39 58:40 59:41 60:42 61:42 62:43 63:44 64:45 65:46 66:47 67:48 68:49 69:50 70:51 71:52 72:53 73:54 74:55 75:55 76:55 77:55 78:56 79:57 80:58 81:59 82:60 83:60 84:60 85:61 86:62 87:63 88:64 89:65 90:66 91:67 92:68 93:69 94:70 95:71 96:72 97:73 98:73 99:74 100:75 101:76 102:77 103:77 104:78 105:79 106:80 107:81 108:82 109:83 110:84 111:85 112:86 113:87 114:88 115:89 116:90 117:90 118:90 119:91 120:92 121:93 122:94 123:94 124:95 125:96 126:96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.979862 140073664845568 tf_logging.py:115] token_to_orig_map: 9:0 10:1 11:1 12:1 13:2 14:3 15:4 16:5 17:6 18:7 19:8 20:9 21:10 22:11 23:12 24:13 25:14 26:15 27:16 28:17 29:18 30:19 31:20 32:20 33:21 34:22 35:23 36:23 37:23 38:24 39:25 40:26 41:26 42:27 43:28 44:29 45:30 46:30 47:31 48:31 49:32 50:33 51:33 52:34 53:35 54:36 55:37 56:38 57:39 58:40 59:41 60:42 61:42 62:43 63:44 64:45 65:46 66:47 67:48 68:49 69:50 70:51 71:52 72:53 73:54 74:55 75:55 76:55 77:55 78:56 79:57 80:58 81:59 82:60 83:60 84:60 85:61 86:62 87:63 88:64 89:65 90:66 91:67 92:68 93:69 94:70 95:71 96:72 97:73 98:73 99:74 100:75 101:76 102:77 103:77 104:78 105:79 106:80 107:81 108:82 109:83 110:84 111:85 112:86 113:87 114:88 115:89 116:90 117:90 118:90 119:91 120:92 121:93 122:94 123:94 124:95 125:96 126:96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.980666 140073664845568 tf_logging.py:115] token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2043 2001 1996 10856 2552 2979 1029 102 1996 4879 1005 1055 2034 2880 4708 2001 5873 1998 2437 12265 1997 1996 3506 1997 15016 1999 7547 2005 27455 1996 1000 2317 6658 4026 2552 1010 1000 2030 10856 2552 1010 2979 2006 2238 2423 1010 4976 1012 1999 4673 1010 2009 2001 4096 1996 2142 2163 4879 1997 4812 1012 1996 2206 2095 2009 2001 5799 2000 1996 4879 1997 13574 1998 28667 26378 16173 2098 1996 2407 1997 4812 1006 9193 1007 2077 2633 3352 2019 2981 2326 2306 1996 2533 1997 3425 1999 4437 1012 1999 1996 2168 2095 1010 2049 2171 2001 3985 2904 2013 1996 2407 1997 4812 2000 1996 2556 1011 2154 2976 4879 1997 4812 1010 2030 8495 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.981472 140073664845568 tf_logging.py:115] input_ids: 101 2043 2001 1996 10856 2552 2979 1029 102 1996 4879 1005 1055 2034 2880 4708 2001 5873 1998 2437 12265 1997 1996 3506 1997 15016 1999 7547 2005 27455 1996 1000 2317 6658 4026 2552 1010 1000 2030 10856 2552 1010 2979 2006 2238 2423 1010 4976 1012 1999 4673 1010 2009 2001 4096 1996 2142 2163 4879 1997 4812 1012 1996 2206 2095 2009 2001 5799 2000 1996 4879 1997 13574 1998 28667 26378 16173 2098 1996 2407 1997 4812 1006 9193 1007 2077 2633 3352 2019 2981 2326 2306 1996 2533 1997 3425 1999 4437 1012 1999 1996 2168 2095 1010 2049 2171 2001 3985 2904 2013 1996 2407 1997 4812 2000 1996 2556 1011 2154 2976 4879 1997 4812 1010 2030 8495 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.982373 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.983143 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:start_position: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.983852 140073664845568 tf_logging.py:115] start_position: 44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:end_position: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.984553 140073664845568 tf_logging.py:115] end_position: 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:answer: june 25 , 1910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.985343 140073664845568 tf_logging.py:115] answer: june 25 , 1910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.988487 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.989371 140073664845568 tf_logging.py:115] unique_id: 1000000008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.990219 140073664845568 tf_logging.py:115] example_index: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.991009 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] what is the result of / e / being the same in central , western and bel ##ear ##ic ? [SEP] central , western , and bal ##ear ##ic differ in the lexi ##cal incidence of stressed / e / and /  / . usually , words with /  / in central catalan correspond to /  / in bal ##ear ##ic and / e / in western catalan . words with / e / in bal ##ear ##ic almost always have / e / in central and western catalan as well . [ vague ] as a result , central catalan has a much higher incidence of / e / . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.991834 140073664845568 tf_logging.py:115] tokens: [CLS] what is the result of / e / being the same in central , western and bel ##ear ##ic ? [SEP] central , western , and bal ##ear ##ic differ in the lexi ##cal incidence of stressed / e / and /  / . usually , words with /  / in central catalan correspond to /  / in bal ##ear ##ic and / e / in western catalan . words with / e / in bal ##ear ##ic almost always have / e / in central and western catalan as well . [ vague ] as a result , central catalan has a much higher incidence of / e / . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 22:0 23:0 24:1 25:1 26:2 27:3 28:3 29:3 30:4 31:5 32:6 33:7 34:7 35:8 36:9 37:10 38:11 39:11 40:11 41:12 42:13 43:13 44:13 45:13 46:14 47:14 48:15 49:16 50:17 51:17 52:17 53:18 54:19 55:20 56:21 57:22 58:23 59:23 60:23 61:24 62:25 63:25 64:25 65:26 66:27 67:27 68:27 69:28 70:29 71:30 72:30 73:31 74:32 75:33 76:33 77:33 78:34 79:35 80:35 81:35 82:36 83:37 84:38 85:39 86:39 87:39 88:40 89:41 90:42 91:43 92:44 93:45 94:46 95:46 96:46 97:46 98:46 99:47 100:48 101:49 102:49 103:50 104:51 105:52 106:53 107:54 108:55 109:56 110:57 111:58 112:58 113:58 114:58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.992645 140073664845568 tf_logging.py:115] token_to_orig_map: 22:0 23:0 24:1 25:1 26:2 27:3 28:3 29:3 30:4 31:5 32:6 33:7 34:7 35:8 36:9 37:10 38:11 39:11 40:11 41:12 42:13 43:13 44:13 45:13 46:14 47:14 48:15 49:16 50:17 51:17 52:17 53:18 54:19 55:20 56:21 57:22 58:23 59:23 60:23 61:24 62:25 63:25 64:25 65:26 66:27 67:27 68:27 69:28 70:29 71:30 72:30 73:31 74:32 75:33 76:33 77:33 78:34 79:35 80:35 81:35 82:36 83:37 84:38 85:39 86:39 87:39 88:40 89:41 90:42 91:43 92:44 93:45 94:46 95:46 96:46 97:46 98:46 99:47 100:48 101:49 102:49 103:50 104:51 105:52 106:53 107:54 108:55 109:56 110:57 111:58 112:58 113:58 114:58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.993384 140073664845568 tf_logging.py:115] token_is_max_context: 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2054 2003 1996 2765 1997 1013 1041 1013 2108 1996 2168 1999 2430 1010 2530 1998 19337 14644 2594 1029 102 2430 1010 2530 1010 1998 28352 14644 2594 11234 1999 1996 16105 9289 18949 1997 13233 1013 1041 1013 1998 1013 1115 1013 1012 2788 1010 2616 2007 1013 1115 1013 1999 2430 13973 17254 2000 1013 1114 1013 1999 28352 14644 2594 1998 1013 1041 1013 1999 2530 13973 1012 2616 2007 1013 1041 1013 1999 28352 14644 2594 2471 2467 2031 1013 1041 1013 1999 2430 1998 2530 13973 2004 2092 1012 1031 13727 1033 2004 1037 2765 1010 2430 13973 2038 1037 2172 3020 18949 1997 1013 1041 1013 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.994281 140073664845568 tf_logging.py:115] input_ids: 101 2054 2003 1996 2765 1997 1013 1041 1013 2108 1996 2168 1999 2430 1010 2530 1998 19337 14644 2594 1029 102 2430 1010 2530 1010 1998 28352 14644 2594 11234 1999 1996 16105 9289 18949 1997 13233 1013 1041 1013 1998 1013 1115 1013 1012 2788 1010 2616 2007 1013 1115 1013 1999 2430 13973 17254 2000 1013 1114 1013 1999 28352 14644 2594 1998 1013 1041 1013 1999 2530 13973 1012 2616 2007 1013 1041 1013 1999 28352 14644 2594 2471 2467 2031 1013 1041 1013 1999 2430 1998 2530 13973 2004 2092 1012 1031 13727 1033 2004 1037 2765 1010 2430 13973 2038 1037 2172 3020 18949 1997 1013 1041 1013 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.995019 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.995805 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:start_position: 108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.996515 140073664845568 tf_logging.py:115] start_position: 108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:end_position: 109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.997206 140073664845568 tf_logging.py:115] end_position: 109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:answer: higher incidence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:36.998040 140073664845568 tf_logging.py:115] answer: higher incidence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.001834 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.002759 140073664845568 tf_logging.py:115] unique_id: 1000000009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.003589 140073664845568 tf_logging.py:115] example_index: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.004375 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] what did the old letter  [UNK]  become ? [SEP] older letters of the russian alphabet include  [UNK]  , which merged to    ( / je / or /  ##e / ) ;    and  [UNK]  , which both merged to    ( / i / ) ;  [UNK]  , which merged to    ( / f / ) ;  [UNK]  , which merged to    ( / u / ) ;  [UNK]  , which merged to    ( / ju / or /  ##u / ) ; and  [UNK] /  [UNK]   , which later were graphical ##ly res ##ha ##ped into    and merged phonetic ##ally to / ja / or /  ##a / . while these older letters have been abandoned at one time or another , they may be used in this and related articles . the yer ##s    and    originally indicated the pronunciation of ultra - short or reduced / u / , / i / . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.006652 140073664845568 tf_logging.py:115] tokens: [CLS] what did the old letter  [UNK]  become ? [SEP] older letters of the russian alphabet include  [UNK]  , which merged to    ( / je / or /  ##e / ) ;    and  [UNK]  , which both merged to    ( / i / ) ;  [UNK]  , which merged to    ( / f / ) ;  [UNK]  , which merged to    ( / u / ) ;  [UNK]  , which merged to    ( / ju / or /  ##u / ) ; and  [UNK] /  [UNK]   , which later were graphical ##ly res ##ha ##ped into    and merged phonetic ##ally to / ja / or /  ##a / . while these older letters have been abandoned at one time or another , they may be used in this and related articles . the yer ##s    and    originally indicated the pronunciation of ultra - short or reduced / u / , / i / . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 12:0 13:1 14:2 15:3 16:4 17:5 18:6 19:7 20:7 21:7 22:7 23:8 24:9 25:10 26:11 27:11 28:11 29:12 30:12 31:12 32:12 33:13 34:14 35:14 36:14 37:14 38:14 39:14 40:15 41:15 42:15 43:16 44:17 45:17 46:17 47:17 48:18 49:19 50:20 51:21 52:22 53:22 54:22 55:23 56:23 57:23 58:23 59:23 60:23 61:24 62:24 63:24 64:24 65:25 66:26 67:27 68:28 69:28 70:28 71:29 72:29 73:29 74:29 75:29 76:29 77:30 78:30 79:30 80:30 81:31 82:32 83:33 84:34 85:34 86:34 87:35 88:35 89:35 90:35 91:35 92:35 93:36 94:36 95:36 96:36 97:37 98:38 99:39 100:40 101:40 102:40 103:41 104:41 105:41 106:41 107:42 108:43 109:43 110:43 111:43 112:43 113:43 114:44 115:45 116:45 117:45 118:45 119:45 120:45 121:45 122:45 123:46 124:47 125:48 126:49 127:49 128:50 129:50 130:50 131:51 132:52 133:52 134:52 135:53 136:54 137:55 138:55 139:56 140:57 141:57 142:57 143:58 144:59 145:59 146:59 147:59 148:59 149:60 150:61 151:62 152:63 153:64 154:65 155:66 156:67 157:68 158:69 159:70 160:71 161:71 162:72 163:73 164:74 165:75 166:76 167:77 168:78 169:79 170:80 171:80 172:81 173:82 174:82 175:83 176:83 177:83 178:84 179:85 180:85 181:85 182:86 183:87 184:88 185:89 186:90 187:91 188:91 189:91 190:92 191:93 192:94 193:94 194:94 195:94 196:95 197:95 198:95 199:95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.007564 140073664845568 tf_logging.py:115] token_to_orig_map: 12:0 13:1 14:2 15:3 16:4 17:5 18:6 19:7 20:7 21:7 22:7 23:8 24:9 25:10 26:11 27:11 28:11 29:12 30:12 31:12 32:12 33:13 34:14 35:14 36:14 37:14 38:14 39:14 40:15 41:15 42:15 43:16 44:17 45:17 46:17 47:17 48:18 49:19 50:20 51:21 52:22 53:22 54:22 55:23 56:23 57:23 58:23 59:23 60:23 61:24 62:24 63:24 64:24 65:25 66:26 67:27 68:28 69:28 70:28 71:29 72:29 73:29 74:29 75:29 76:29 77:30 78:30 79:30 80:30 81:31 82:32 83:33 84:34 85:34 86:34 87:35 88:35 89:35 90:35 91:35 92:35 93:36 94:36 95:36 96:36 97:37 98:38 99:39 100:40 101:40 102:40 103:41 104:41 105:41 106:41 107:42 108:43 109:43 110:43 111:43 112:43 113:43 114:44 115:45 116:45 117:45 118:45 119:45 120:45 121:45 122:45 123:46 124:47 125:48 126:49 127:49 128:50 129:50 130:50 131:51 132:52 133:52 134:52 135:53 136:54 137:55 138:55 139:56 140:57 141:57 142:57 143:58 144:59 145:59 146:59 147:59 148:59 149:60 150:61 151:62 152:63 153:64 154:65 155:66 156:67 157:68 158:69 159:70 160:71 161:71 162:72 163:73 164:74 165:75 166:76 167:77 168:78 169:79 170:80 171:80 172:81 173:82 174:82 175:83 176:83 177:83 178:84 179:85 180:85 181:85 182:86 183:87 184:88 185:89 186:90 187:91 188:91 189:91 190:92 191:93 192:94 193:94 194:94 195:94 196:95 197:95 198:95 199:95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.008426 140073664845568 tf_logging.py:115] token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2054 2106 1996 2214 3661 1629 100 1630 2468 1029 102 3080 4144 1997 1996 2845 12440 2421 1629 100 1630 1010 2029 5314 2000 1629 1185 1630 1006 1013 15333 1013 2030 1013 1141 2063 1013 1007 1025 1629 1213 1630 1998 1629 100 1630 1010 2029 2119 5314 2000 1629 1188 1630 1006 1013 1045 1013 1007 1025 1629 100 1630 1010 2029 5314 2000 1629 1199 1630 1006 1013 1042 1013 1007 1025 1629 100 1630 1010 2029 5314 2000 1629 1198 1630 1006 1013 1057 1013 1007 1025 1629 100 1630 1010 2029 5314 2000 1629 1209 1630 1006 1013 18414 1013 2030 1013 1141 2226 1013 1007 1025 1998 1629 100 1013 1629 100 1630 1630 1010 2029 2101 2020 20477 2135 24501 3270 5669 2046 1629 1210 1630 1998 5314 26664 3973 2000 1013 14855 1013 2030 1013 1141 2050 1013 1012 2096 2122 3080 4144 2031 2042 4704 2012 2028 2051 2030 2178 1010 2027 2089 2022 2109 1999 2023 1998 3141 4790 1012 1996 20416 2015 1629 1205 1630 1998 1629 1207 1630 2761 5393 1996 15498 1997 11087 1011 2460 2030 4359 1013 1057 1013 1010 1013 1045 1013 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.009319 140073664845568 tf_logging.py:115] input_ids: 101 2054 2106 1996 2214 3661 1629 100 1630 2468 1029 102 3080 4144 1997 1996 2845 12440 2421 1629 100 1630 1010 2029 5314 2000 1629 1185 1630 1006 1013 15333 1013 2030 1013 1141 2063 1013 1007 1025 1629 1213 1630 1998 1629 100 1630 1010 2029 2119 5314 2000 1629 1188 1630 1006 1013 1045 1013 1007 1025 1629 100 1630 1010 2029 5314 2000 1629 1199 1630 1006 1013 1042 1013 1007 1025 1629 100 1630 1010 2029 5314 2000 1629 1198 1630 1006 1013 1057 1013 1007 1025 1629 100 1630 1010 2029 5314 2000 1629 1209 1630 1006 1013 18414 1013 2030 1013 1141 2226 1013 1007 1025 1998 1629 100 1013 1629 100 1630 1630 1010 2029 2101 2020 20477 2135 24501 3270 5669 2046 1629 1210 1630 1998 5314 26664 3973 2000 1013 14855 1013 2030 1013 1141 2050 1013 1012 2096 2122 3080 4144 2031 2042 4704 2012 2028 2051 2030 2178 1010 2027 2089 2022 2109 1999 2023 1998 3141 4790 1012 1996 20416 2015 1629 1205 1630 1998 1629 1207 1630 2761 5393 1996 15498 1997 11087 1011 2460 2030 4359 1013 1057 1013 1010 1013 1045 1013 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.010215 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.010950 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:start_position: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.011696 140073664845568 tf_logging.py:115] start_position: 26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:end_position: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.012397 140073664845568 tf_logging.py:115] end_position: 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:answer:   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.013127 140073664845568 tf_logging.py:115] answer:   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.018423 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.019269 140073664845568 tf_logging.py:115] unique_id: 1000000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.020064 140073664845568 tf_logging.py:115] example_index: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.020850 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] what was the problem with the palace ' s chimneys ? [SEP] buckingham palace finally became the principal royal residence in 1837 , on the accession of queen victoria , who was the first monarch to reside there ; her predecessor william iv had died before its completion . while the state rooms were a riot of gil ##t and colour , the nec ##ess ##ities of the new palace were somewhat less luxurious . for one thing , it was reported the chimneys smoked so much that the fires had to be allowed to die down , and consequently the court shivered in icy mag ##ni ##fi ##cence . ventilation was so bad that the interior smelled , and when a decision was taken to install gas lamps , there was a serious worry about the build - up of gas on the lower floors . it was also said that staff were lax and lazy and the palace was dirty . following the queen ' s marriage in 1840 , her husband , prince albert , concerned himself with a reorganisation of the household offices and staff , and with the design faults of the palace . the problems were all rec ##ti ##fied by the close of 1840 . however , the builders were to return within the decade . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.021701 140073664845568 tf_logging.py:115] tokens: [CLS] what was the problem with the palace ' s chimneys ? [SEP] buckingham palace finally became the principal royal residence in 1837 , on the accession of queen victoria , who was the first monarch to reside there ; her predecessor william iv had died before its completion . while the state rooms were a riot of gil ##t and colour , the nec ##ess ##ities of the new palace were somewhat less luxurious . for one thing , it was reported the chimneys smoked so much that the fires had to be allowed to die down , and consequently the court shivered in icy mag ##ni ##fi ##cence . ventilation was so bad that the interior smelled , and when a decision was taken to install gas lamps , there was a serious worry about the build - up of gas on the lower floors . it was also said that staff were lax and lazy and the palace was dirty . following the queen ' s marriage in 1840 , her husband , prince albert , concerned himself with a reorganisation of the household offices and staff , and with the design faults of the palace . the problems were all rec ##ti ##fied by the close of 1840 . however , the builders were to return within the decade . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 13:0 14:1 15:2 16:3 17:4 18:5 19:6 20:7 21:8 22:9 23:9 24:10 25:11 26:12 27:13 28:14 29:15 30:15 31:16 32:17 33:18 34:19 35:20 36:21 37:22 38:23 39:23 40:24 41:25 42:26 43:27 44:28 45:29 46:30 47:31 48:32 49:32 50:33 51:34 52:35 53:36 54:37 55:38 56:39 57:40 58:41 59:41 60:42 61:43 62:43 63:44 64:45 65:45 66:45 67:46 68:47 69:48 70:49 71:50 72:51 73:52 74:53 75:53 76:54 77:55 78:56 79:56 80:57 81:58 82:59 83:60 84:61 85:62 86:63 87:64 88:65 89:66 90:67 91:68 92:69 93:70 94:71 95:72 96:73 97:74 98:74 99:75 100:76 101:77 102:78 103:79 104:80 105:81 106:82 107:82 108:82 109:82 110:82 111:83 112:84 113:85 114:86 115:87 116:88 117:89 118:90 119:90 120:91 121:92 122:93 123:94 124:95 125:96 126:97 127:98 128:99 129:100 130:100 131:101 132:102 133:103 134:104 135:105 136:106 137:107 138:108 139:108 140:108 141:109 142:110 143:111 144:112 145:113 146:114 147:114 148:115 149:116 150:117 151:118 152:119 153:120 154:121 155:122 156:123 157:124 158:125 159:126 160:127 161:128 162:129 163:129 164:130 165:131 166:132 167:132 168:132 169:133 170:134 171:135 172:135 173:136 174:137 175:137 176:138 177:139 178:139 179:140 180:141 181:142 182:143 183:144 184:145 185:146 186:147 187:148 188:149 189:150 190:150 191:151 192:152 193:153 194:154 195:155 196:156 197:157 198:158 199:158 200:159 201:160 202:161 203:162 204:163 205:163 206:163 207:164 208:165 209:166 210:167 211:168 212:168 213:169 214:169 215:170 216:171 217:172 218:173 219:174 220:175 221:176 222:177 223:177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.022590 140073664845568 tf_logging.py:115] token_to_orig_map: 13:0 14:1 15:2 16:3 17:4 18:5 19:6 20:7 21:8 22:9 23:9 24:10 25:11 26:12 27:13 28:14 29:15 30:15 31:16 32:17 33:18 34:19 35:20 36:21 37:22 38:23 39:23 40:24 41:25 42:26 43:27 44:28 45:29 46:30 47:31 48:32 49:32 50:33 51:34 52:35 53:36 54:37 55:38 56:39 57:40 58:41 59:41 60:42 61:43 62:43 63:44 64:45 65:45 66:45 67:46 68:47 69:48 70:49 71:50 72:51 73:52 74:53 75:53 76:54 77:55 78:56 79:56 80:57 81:58 82:59 83:60 84:61 85:62 86:63 87:64 88:65 89:66 90:67 91:68 92:69 93:70 94:71 95:72 96:73 97:74 98:74 99:75 100:76 101:77 102:78 103:79 104:80 105:81 106:82 107:82 108:82 109:82 110:82 111:83 112:84 113:85 114:86 115:87 116:88 117:89 118:90 119:90 120:91 121:92 122:93 123:94 124:95 125:96 126:97 127:98 128:99 129:100 130:100 131:101 132:102 133:103 134:104 135:105 136:106 137:107 138:108 139:108 140:108 141:109 142:110 143:111 144:112 145:113 146:114 147:114 148:115 149:116 150:117 151:118 152:119 153:120 154:121 155:122 156:123 157:124 158:125 159:126 160:127 161:128 162:129 163:129 164:130 165:131 166:132 167:132 168:132 169:133 170:134 171:135 172:135 173:136 174:137 175:137 176:138 177:139 178:139 179:140 180:141 181:142 182:143 183:144 184:145 185:146 186:147 187:148 188:149 189:150 190:150 191:151 192:152 193:153 194:154 195:155 196:156 197:157 198:158 199:158 200:159 201:160 202:161 203:162 204:163 205:163 206:163 207:164 208:165 209:166 210:167 211:168 212:168 213:169 214:169 215:170 216:171 217:172 218:173 219:174 220:175 221:176 222:177 223:177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.023453 140073664845568 tf_logging.py:115] token_is_max_context: 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2054 2001 1996 3291 2007 1996 4186 1005 1055 28885 1029 102 17836 4186 2633 2150 1996 4054 2548 5039 1999 9713 1010 2006 1996 16993 1997 3035 3848 1010 2040 2001 1996 2034 11590 2000 13960 2045 1025 2014 8646 2520 4921 2018 2351 2077 2049 6503 1012 2096 1996 2110 4734 2020 1037 11421 1997 13097 2102 1998 6120 1010 1996 26785 7971 6447 1997 1996 2047 4186 2020 5399 2625 20783 1012 2005 2028 2518 1010 2009 2001 2988 1996 28885 20482 2061 2172 2008 1996 8769 2018 2000 2022 3039 2000 3280 2091 1010 1998 8821 1996 2457 13927 1999 13580 23848 3490 8873 29320 1012 19536 2001 2061 2919 2008 1996 4592 9557 1010 1998 2043 1037 3247 2001 2579 2000 16500 3806 14186 1010 2045 2001 1037 3809 4737 2055 1996 3857 1011 2039 1997 3806 2006 1996 2896 8158 1012 2009 2001 2036 2056 2008 3095 2020 27327 1998 13971 1998 1996 4186 2001 6530 1012 2206 1996 3035 1005 1055 3510 1999 8905 1010 2014 3129 1010 3159 4789 1010 4986 2370 2007 1037 24934 1997 1996 4398 4822 1998 3095 1010 1998 2007 1996 2640 19399 1997 1996 4186 1012 1996 3471 2020 2035 28667 3775 10451 2011 1996 2485 1997 8905 1012 2174 1010 1996 16472 2020 2000 2709 2306 1996 5476 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.024383 140073664845568 tf_logging.py:115] input_ids: 101 2054 2001 1996 3291 2007 1996 4186 1005 1055 28885 1029 102 17836 4186 2633 2150 1996 4054 2548 5039 1999 9713 1010 2006 1996 16993 1997 3035 3848 1010 2040 2001 1996 2034 11590 2000 13960 2045 1025 2014 8646 2520 4921 2018 2351 2077 2049 6503 1012 2096 1996 2110 4734 2020 1037 11421 1997 13097 2102 1998 6120 1010 1996 26785 7971 6447 1997 1996 2047 4186 2020 5399 2625 20783 1012 2005 2028 2518 1010 2009 2001 2988 1996 28885 20482 2061 2172 2008 1996 8769 2018 2000 2022 3039 2000 3280 2091 1010 1998 8821 1996 2457 13927 1999 13580 23848 3490 8873 29320 1012 19536 2001 2061 2919 2008 1996 4592 9557 1010 1998 2043 1037 3247 2001 2579 2000 16500 3806 14186 1010 2045 2001 1037 3809 4737 2055 1996 3857 1011 2039 1997 3806 2006 1996 2896 8158 1012 2009 2001 2036 2056 2008 3095 2020 27327 1998 13971 1998 1996 4186 2001 6530 1012 2206 1996 3035 1005 1055 3510 1999 8905 1010 2014 3129 1010 3159 4789 1010 4986 2370 2007 1037 24934 1997 1996 4398 4822 1998 3095 1010 1998 2007 1996 2640 19399 1997 1996 4186 1012 1996 3471 2020 2035 28667 3775 10451 2011 1996 2485 1997 8905 1012 2174 1010 1996 16472 2020 2000 2709 2306 1996 5476 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.025167 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.026078 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:start_position: 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.026791 140073664845568 tf_logging.py:115] start_position: 83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:end_position: 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.027549 140073664845568 tf_logging.py:115] end_position: 85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:answer: the chimneys smoked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.028321 140073664845568 tf_logging.py:115] answer: the chimneys smoked\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.033343 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.046679 140073664845568 tf_logging.py:115] unique_id: 1000000011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.047445 140073664845568 tf_logging.py:115] example_index: 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.048276 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] who has noted that binding precedent did not exist when the constitution was written ? [SEP] as federal judge alex ko ##zin ##ski has pointed out , binding precedent as we know it today simply did not exist at the time the constitution was framed . judicial decisions were not consistently , accurately , and faithful ##ly reported on both sides of the atlantic ( reporters often simply re ##wr ##ote or failed to publish decisions which they disliked ) , and the united kingdom lacked a coherent court hierarchy prior to the end of the 19th century . furthermore , english judges in the eighteenth century sub ##scribe ##d to now - obsolete natural law theories of law , by which law was believed to have an existence independent of what individual judges said . judges saw themselves as merely declaring the law which had always theoretically existed , and not as making the law . therefore , a judge could reject another judge ' s opinion as simply an incorrect statement of the law , in the way that scientists regularly reject each other ' s conclusions as incorrect statements of the laws of science . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.049147 140073664845568 tf_logging.py:115] tokens: [CLS] who has noted that binding precedent did not exist when the constitution was written ? [SEP] as federal judge alex ko ##zin ##ski has pointed out , binding precedent as we know it today simply did not exist at the time the constitution was framed . judicial decisions were not consistently , accurately , and faithful ##ly reported on both sides of the atlantic ( reporters often simply re ##wr ##ote or failed to publish decisions which they disliked ) , and the united kingdom lacked a coherent court hierarchy prior to the end of the 19th century . furthermore , english judges in the eighteenth century sub ##scribe ##d to now - obsolete natural law theories of law , by which law was believed to have an existence independent of what individual judges said . judges saw themselves as merely declaring the law which had always theoretically existed , and not as making the law . therefore , a judge could reject another judge ' s opinion as simply an incorrect statement of the law , in the way that scientists regularly reject each other ' s conclusions as incorrect statements of the laws of science . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 17:0 18:1 19:2 20:3 21:4 22:4 23:4 24:5 25:6 26:7 27:7 28:8 29:9 30:10 31:11 32:12 33:13 34:14 35:15 36:16 37:17 38:18 39:19 40:20 41:21 42:22 43:23 44:24 45:25 46:25 47:26 48:27 49:28 50:29 51:30 52:30 53:31 54:31 55:32 56:33 57:33 58:34 59:35 60:36 61:37 62:38 63:39 64:40 65:41 66:41 67:42 68:43 69:44 70:44 71:44 72:45 73:46 74:47 75:48 76:49 77:50 78:51 79:52 80:52 81:52 82:53 83:54 84:55 85:56 86:57 87:58 88:59 89:60 90:61 91:62 92:63 93:64 94:65 95:66 96:67 97:68 98:69 99:69 100:70 101:70 102:71 103:72 104:73 105:74 106:75 107:76 108:77 109:77 110:77 111:78 112:79 113:79 114:79 115:80 116:81 117:82 118:83 119:84 120:84 121:85 122:86 123:87 124:88 125:89 126:90 127:91 128:92 129:93 130:94 131:95 132:96 133:97 134:98 135:99 136:99 137:100 138:101 139:102 140:103 141:104 142:105 143:106 144:107 145:108 146:109 147:110 148:111 149:112 150:112 151:113 152:114 153:115 154:116 155:117 156:118 157:118 158:119 159:119 160:120 161:121 162:122 163:123 164:124 165:125 166:125 167:125 168:126 169:127 170:128 171:129 172:130 173:131 174:132 175:133 176:134 177:134 178:135 179:136 180:137 181:138 182:139 183:140 184:141 185:142 186:143 187:143 188:143 189:144 190:145 191:146 192:147 193:148 194:149 195:150 196:151 197:152 198:152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.050156 140073664845568 tf_logging.py:115] token_to_orig_map: 17:0 18:1 19:2 20:3 21:4 22:4 23:4 24:5 25:6 26:7 27:7 28:8 29:9 30:10 31:11 32:12 33:13 34:14 35:15 36:16 37:17 38:18 39:19 40:20 41:21 42:22 43:23 44:24 45:25 46:25 47:26 48:27 49:28 50:29 51:30 52:30 53:31 54:31 55:32 56:33 57:33 58:34 59:35 60:36 61:37 62:38 63:39 64:40 65:41 66:41 67:42 68:43 69:44 70:44 71:44 72:45 73:46 74:47 75:48 76:49 77:50 78:51 79:52 80:52 81:52 82:53 83:54 84:55 85:56 86:57 87:58 88:59 89:60 90:61 91:62 92:63 93:64 94:65 95:66 96:67 97:68 98:69 99:69 100:70 101:70 102:71 103:72 104:73 105:74 106:75 107:76 108:77 109:77 110:77 111:78 112:79 113:79 114:79 115:80 116:81 117:82 118:83 119:84 120:84 121:85 122:86 123:87 124:88 125:89 126:90 127:91 128:92 129:93 130:94 131:95 132:96 133:97 134:98 135:99 136:99 137:100 138:101 139:102 140:103 141:104 142:105 143:106 144:107 145:108 146:109 147:110 148:111 149:112 150:112 151:113 152:114 153:115 154:116 155:117 156:118 157:118 158:119 159:119 160:120 161:121 162:122 163:123 164:124 165:125 166:125 167:125 168:126 169:127 170:128 171:129 172:130 173:131 174:132 175:133 176:134 177:134 178:135 179:136 180:137 181:138 182:139 183:140 184:141 185:142 186:143 187:143 188:143 189:144 190:145 191:146 192:147 193:148 194:149 195:150 196:151 197:152 198:152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.051088 140073664845568 tf_logging.py:115] token_is_max_context: 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2040 2038 3264 2008 8031 20056 2106 2025 4839 2043 1996 4552 2001 2517 1029 102 2004 2976 3648 4074 12849 17168 5488 2038 4197 2041 1010 8031 20056 2004 2057 2113 2009 2651 3432 2106 2025 4839 2012 1996 2051 1996 4552 2001 10366 1012 8268 6567 2020 2025 10862 1010 14125 1010 1998 11633 2135 2988 2006 2119 3903 1997 1996 4448 1006 12060 2411 3432 2128 13088 12184 2030 3478 2000 10172 6567 2029 2027 18966 1007 1010 1998 1996 2142 2983 10858 1037 18920 2457 12571 3188 2000 1996 2203 1997 1996 3708 2301 1012 7297 1010 2394 6794 1999 1996 12965 2301 4942 29234 2094 2000 2085 1011 15832 3019 2375 8106 1997 2375 1010 2011 2029 2375 2001 3373 2000 2031 2019 4598 2981 1997 2054 3265 6794 2056 1012 6794 2387 3209 2004 6414 13752 1996 2375 2029 2018 2467 22634 5839 1010 1998 2025 2004 2437 1996 2375 1012 3568 1010 1037 3648 2071 15454 2178 3648 1005 1055 5448 2004 3432 2019 16542 4861 1997 1996 2375 1010 1999 1996 2126 2008 6529 5570 15454 2169 2060 1005 1055 15306 2004 16542 8635 1997 1996 4277 1997 2671 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.052018 140073664845568 tf_logging.py:115] input_ids: 101 2040 2038 3264 2008 8031 20056 2106 2025 4839 2043 1996 4552 2001 2517 1029 102 2004 2976 3648 4074 12849 17168 5488 2038 4197 2041 1010 8031 20056 2004 2057 2113 2009 2651 3432 2106 2025 4839 2012 1996 2051 1996 4552 2001 10366 1012 8268 6567 2020 2025 10862 1010 14125 1010 1998 11633 2135 2988 2006 2119 3903 1997 1996 4448 1006 12060 2411 3432 2128 13088 12184 2030 3478 2000 10172 6567 2029 2027 18966 1007 1010 1998 1996 2142 2983 10858 1037 18920 2457 12571 3188 2000 1996 2203 1997 1996 3708 2301 1012 7297 1010 2394 6794 1999 1996 12965 2301 4942 29234 2094 2000 2085 1011 15832 3019 2375 8106 1997 2375 1010 2011 2029 2375 2001 3373 2000 2031 2019 4598 2981 1997 2054 3265 6794 2056 1012 6794 2387 3209 2004 6414 13752 1996 2375 2029 2018 2467 22634 5839 1010 1998 2025 2004 2437 1996 2375 1012 3568 1010 1037 3648 2071 15454 2178 3648 1005 1055 5448 2004 3432 2019 16542 4861 1997 1996 2375 1010 1999 1996 2126 2008 6529 5570 15454 2169 2060 1005 1055 15306 2004 16542 8635 1997 1996 4277 1997 2671 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.053058 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.054063 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:start_position: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.054998 140073664845568 tf_logging.py:115] start_position: 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:end_position: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.055812 140073664845568 tf_logging.py:115] end_position: 23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:answer: federal judge alex ko ##zin ##ski\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.056568 140073664845568 tf_logging.py:115] answer: federal judge alex ko ##zin ##ski\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.060188 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.061064 140073664845568 tf_logging.py:115] unique_id: 1000000012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.061883 140073664845568 tf_logging.py:115] example_index: 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.062727 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] what short ##coming was noticeable , from the start , for wesley clark ? [SEP] in september 2003 , retired four - star general wesley clark announced his intention to run in the presidential primary election for the democratic party nomination . his campaign focused on themes of leadership and patriot ##ism ; early campaign ads relied heavily on biography . his late start left him with relatively few detailed policy proposals . this weakness was apparent in his first few debates , although he soon presented a range of position papers , including a major tax - relief plan . nevertheless , the democrats did not flock to support his campaign . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.063542 140073664845568 tf_logging.py:115] tokens: [CLS] what short ##coming was noticeable , from the start , for wesley clark ? [SEP] in september 2003 , retired four - star general wesley clark announced his intention to run in the presidential primary election for the democratic party nomination . his campaign focused on themes of leadership and patriot ##ism ; early campaign ads relied heavily on biography . his late start left him with relatively few detailed policy proposals . this weakness was apparent in his first few debates , although he soon presented a range of position papers , including a major tax - relief plan . nevertheless , the democrats did not flock to support his campaign . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 16:0 17:1 18:2 19:2 20:3 21:4 22:4 23:4 24:5 25:6 26:7 27:8 28:9 29:10 30:11 31:12 32:13 33:14 34:15 35:16 36:17 37:18 38:19 39:20 40:21 41:22 42:22 43:23 44:24 45:25 46:26 47:27 48:28 49:29 50:30 51:31 52:31 53:31 54:32 55:33 56:34 57:35 58:36 59:37 60:38 61:38 62:39 63:40 64:41 65:42 66:43 67:44 68:45 69:46 70:47 71:48 72:49 73:49 74:50 75:51 76:52 77:53 78:54 79:55 80:56 81:57 82:58 83:58 84:59 85:60 86:61 87:62 88:63 89:64 90:65 91:66 92:67 93:67 94:68 95:69 96:70 97:71 98:71 99:71 100:72 101:72 102:73 103:73 104:74 105:75 106:76 107:77 108:78 109:79 110:80 111:81 112:82 113:82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.064317 140073664845568 tf_logging.py:115] token_to_orig_map: 16:0 17:1 18:2 19:2 20:3 21:4 22:4 23:4 24:5 25:6 26:7 27:8 28:9 29:10 30:11 31:12 32:13 33:14 34:15 35:16 36:17 37:18 38:19 39:20 40:21 41:22 42:22 43:23 44:24 45:25 46:26 47:27 48:28 49:29 50:30 51:31 52:31 53:31 54:32 55:33 56:34 57:35 58:36 59:37 60:38 61:38 62:39 63:40 64:41 65:42 66:43 67:44 68:45 69:46 70:47 71:48 72:49 73:49 74:50 75:51 76:52 77:53 78:54 79:55 80:56 81:57 82:58 83:58 84:59 85:60 86:61 87:62 88:63 89:64 90:65 91:66 92:67 93:67 94:68 95:69 96:70 97:71 98:71 99:71 100:72 101:72 102:73 103:73 104:74 105:75 106:76 107:77 108:78 109:79 110:80 111:81 112:82 113:82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.065081 140073664845568 tf_logging.py:115] token_is_max_context: 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2054 2460 18935 2001 17725 1010 2013 1996 2707 1010 2005 11482 5215 1029 102 1999 2244 2494 1010 3394 2176 1011 2732 2236 11482 5215 2623 2010 6808 2000 2448 1999 1996 4883 3078 2602 2005 1996 3537 2283 6488 1012 2010 3049 4208 2006 6991 1997 4105 1998 16419 2964 1025 2220 3049 14997 13538 4600 2006 8308 1012 2010 2397 2707 2187 2032 2007 4659 2261 6851 3343 10340 1012 2023 11251 2001 6835 1999 2010 2034 2261 14379 1010 2348 2002 2574 3591 1037 2846 1997 2597 4981 1010 2164 1037 2350 4171 1011 4335 2933 1012 6600 1010 1996 8037 2106 2025 19311 2000 2490 2010 3049 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.065955 140073664845568 tf_logging.py:115] input_ids: 101 2054 2460 18935 2001 17725 1010 2013 1996 2707 1010 2005 11482 5215 1029 102 1999 2244 2494 1010 3394 2176 1011 2732 2236 11482 5215 2623 2010 6808 2000 2448 1999 1996 4883 3078 2602 2005 1996 3537 2283 6488 1012 2010 3049 4208 2006 6991 1997 4105 1998 16419 2964 1025 2220 3049 14997 13538 4600 2006 8308 1012 2010 2397 2707 2187 2032 2007 4659 2261 6851 3343 10340 1012 2023 11251 2001 6835 1999 2010 2034 2261 14379 1010 2348 2002 2574 3591 1037 2846 1997 2597 4981 1010 2164 1037 2350 4171 1011 4335 2933 1012 6600 1010 1996 8037 2106 2025 19311 2000 2490 2010 3049 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.066788 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.067615 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:start_position: 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.068309 140073664845568 tf_logging.py:115] start_position: 69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:end_position: 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.069119 140073664845568 tf_logging.py:115] end_position: 72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:answer: few detailed policy proposals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.069833 140073664845568 tf_logging.py:115] answer: few detailed policy proposals\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.073596 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.074543 140073664845568 tf_logging.py:115] unique_id: 1000000013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.075356 140073664845568 tf_logging.py:115] example_index: 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.076106 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] the digest ##ive chambers of the ct ##eno ##ph ##ora and the cn ##ida ##ria serve as what ? [SEP] among the other ph ##yla , the ct ##eno ##ph ##ora and the cn ##ida ##ria , which includes sea an ##emon ##es , coral ##s , and jelly ##fish , are radial ##ly symmetric and have digest ##ive chambers with a single opening , which serves as both the mouth and the an ##us . both have distinct tissues , but they are not organized into organs . there are only two main ge ##rm layers , the ec ##to ##der ##m and end ##oder ##m , with only scattered cells between them . as such , these animals are sometimes called dip ##lo ##bla ##stic . the tiny pl ##aco ##zo ##ans are similar , but they do not have a permanent digest ##ive chamber . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.076985 140073664845568 tf_logging.py:115] tokens: [CLS] the digest ##ive chambers of the ct ##eno ##ph ##ora and the cn ##ida ##ria serve as what ? [SEP] among the other ph ##yla , the ct ##eno ##ph ##ora and the cn ##ida ##ria , which includes sea an ##emon ##es , coral ##s , and jelly ##fish , are radial ##ly symmetric and have digest ##ive chambers with a single opening , which serves as both the mouth and the an ##us . both have distinct tissues , but they are not organized into organs . there are only two main ge ##rm layers , the ec ##to ##der ##m and end ##oder ##m , with only scattered cells between them . as such , these animals are sometimes called dip ##lo ##bla ##stic . the tiny pl ##aco ##zo ##ans are similar , but they do not have a permanent digest ##ive chamber . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 21:0 22:1 23:2 24:3 25:3 26:3 27:4 28:5 29:5 30:5 31:5 32:6 33:7 34:8 35:8 36:8 37:8 38:9 39:10 40:11 41:12 42:12 43:12 44:12 45:13 46:13 47:13 48:14 49:15 50:15 51:15 52:16 53:17 54:17 55:18 56:19 57:20 58:21 59:21 60:22 61:23 62:24 63:25 64:26 65:26 66:27 67:28 68:29 69:30 70:31 71:32 72:33 73:34 74:35 75:35 76:35 77:36 78:37 79:38 80:39 81:39 82:40 83:41 84:42 85:43 86:44 87:45 88:46 89:46 90:47 91:48 92:49 93:50 94:51 95:52 96:52 97:53 98:53 99:54 100:55 101:55 102:55 103:55 104:56 105:57 106:57 107:57 108:57 109:58 110:59 111:60 112:61 113:62 114:63 115:63 116:64 117:65 118:65 119:66 120:67 121:68 122:69 123:70 124:71 125:71 126:71 127:71 128:71 129:72 130:73 131:74 132:74 133:74 134:74 135:75 136:76 137:76 138:77 139:78 140:79 141:80 142:81 143:82 144:83 145:84 146:84 147:85 148:85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.077788 140073664845568 tf_logging.py:115] token_to_orig_map: 21:0 22:1 23:2 24:3 25:3 26:3 27:4 28:5 29:5 30:5 31:5 32:6 33:7 34:8 35:8 36:8 37:8 38:9 39:10 40:11 41:12 42:12 43:12 44:12 45:13 46:13 47:13 48:14 49:15 50:15 51:15 52:16 53:17 54:17 55:18 56:19 57:20 58:21 59:21 60:22 61:23 62:24 63:25 64:26 65:26 66:27 67:28 68:29 69:30 70:31 71:32 72:33 73:34 74:35 75:35 76:35 77:36 78:37 79:38 80:39 81:39 82:40 83:41 84:42 85:43 86:44 87:45 88:46 89:46 90:47 91:48 92:49 93:50 94:51 95:52 96:52 97:53 98:53 99:54 100:55 101:55 102:55 103:55 104:56 105:57 106:57 107:57 108:57 109:58 110:59 111:60 112:61 113:62 114:63 115:63 116:64 117:65 118:65 119:66 120:67 121:68 122:69 123:70 124:71 125:71 126:71 127:71 128:71 129:72 130:73 131:74 132:74 133:74 134:74 135:75 136:76 137:76 138:77 139:78 140:79 141:80 142:81 143:82 144:83 145:84 146:84 147:85 148:85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.078571 140073664845568 tf_logging.py:115] token_is_max_context: 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1996 17886 3512 8477 1997 1996 14931 16515 8458 6525 1998 1996 27166 8524 4360 3710 2004 2054 1029 102 2426 1996 2060 6887 23943 1010 1996 14931 16515 8458 6525 1998 1996 27166 8524 4360 1010 2029 2950 2712 2019 26941 2229 1010 11034 2015 1010 1998 20919 7529 1010 2024 15255 2135 19490 1998 2031 17886 3512 8477 2007 1037 2309 3098 1010 2029 4240 2004 2119 1996 2677 1998 1996 2019 2271 1012 2119 2031 5664 14095 1010 2021 2027 2024 2025 4114 2046 11595 1012 2045 2024 2069 2048 2364 16216 10867 9014 1010 1996 14925 3406 4063 2213 1998 2203 27381 2213 1010 2007 2069 7932 4442 2090 2068 1012 2004 2107 1010 2122 4176 2024 2823 2170 16510 4135 28522 10074 1012 1996 4714 20228 22684 6844 6962 2024 2714 1010 2021 2027 2079 2025 2031 1037 4568 17886 3512 4574 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.079413 140073664845568 tf_logging.py:115] input_ids: 101 1996 17886 3512 8477 1997 1996 14931 16515 8458 6525 1998 1996 27166 8524 4360 3710 2004 2054 1029 102 2426 1996 2060 6887 23943 1010 1996 14931 16515 8458 6525 1998 1996 27166 8524 4360 1010 2029 2950 2712 2019 26941 2229 1010 11034 2015 1010 1998 20919 7529 1010 2024 15255 2135 19490 1998 2031 17886 3512 8477 2007 1037 2309 3098 1010 2029 4240 2004 2119 1996 2677 1998 1996 2019 2271 1012 2119 2031 5664 14095 1010 2021 2027 2024 2025 4114 2046 11595 1012 2045 2024 2069 2048 2364 16216 10867 9014 1010 1996 14925 3406 4063 2213 1998 2203 27381 2213 1010 2007 2069 7932 4442 2090 2068 1012 2004 2107 1010 2122 4176 2024 2823 2170 16510 4135 28522 10074 1012 1996 4714 20228 22684 6844 6962 2024 2714 1010 2021 2027 2079 2025 2031 1037 4568 17886 3512 4574 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.080262 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.081182 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:start_position: 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.081967 140073664845568 tf_logging.py:115] start_position: 69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:end_position: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.082760 140073664845568 tf_logging.py:115] end_position: 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:answer: both the mouth and the an ##us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.083457 140073664845568 tf_logging.py:115] answer: both the mouth and the an ##us\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.085878 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.086824 140073664845568 tf_logging.py:115] unique_id: 1000000014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.087639 140073664845568 tf_logging.py:115] example_index: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.088475 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] when did buddhism leave zhejiang ? [SEP] in mid - 2015 the government of zhejiang recognised folk religion as \" civil religion \" beginning the registration of more than twenty thousand folk religious associations . buddhism has an important presence since its arrival in zhejiang 1 , 800 years ago . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.089322 140073664845568 tf_logging.py:115] tokens: [CLS] when did buddhism leave zhejiang ? [SEP] in mid - 2015 the government of zhejiang recognised folk religion as \" civil religion \" beginning the registration of more than twenty thousand folk religious associations . buddhism has an important presence since its arrival in zhejiang 1 , 800 years ago . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 8:0 9:1 10:1 11:1 12:2 13:3 14:4 15:5 16:6 17:7 18:8 19:9 20:10 21:10 22:11 23:11 24:12 25:13 26:14 27:15 28:16 29:17 30:18 31:19 32:20 33:21 34:22 35:22 36:23 37:24 38:25 39:26 40:27 41:28 42:29 43:30 44:31 45:32 46:33 47:33 48:33 49:34 50:35 51:35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.090174 140073664845568 tf_logging.py:115] token_to_orig_map: 8:0 9:1 10:1 11:1 12:2 13:3 14:4 15:5 16:6 17:7 18:8 19:9 20:10 21:10 22:11 23:11 24:12 25:13 26:14 27:15 28:16 29:17 30:18 31:19 32:20 33:21 34:22 35:22 36:23 37:24 38:25 39:26 40:27 41:28 42:29 43:30 44:31 45:32 46:33 47:33 48:33 49:34 50:35 51:35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.090938 140073664845568 tf_logging.py:115] token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2043 2106 11388 2681 26805 1029 102 1999 3054 1011 2325 1996 2231 1997 26805 7843 5154 4676 2004 1000 2942 4676 1000 2927 1996 8819 1997 2062 2084 3174 4595 5154 3412 8924 1012 11388 2038 2019 2590 3739 2144 2049 5508 1999 26805 1015 1010 5385 2086 3283 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.091687 140073664845568 tf_logging.py:115] input_ids: 101 2043 2106 11388 2681 26805 1029 102 1999 3054 1011 2325 1996 2231 1997 26805 7843 5154 4676 2004 1000 2942 4676 1000 2927 1996 8819 1997 2062 2084 3174 4595 5154 3412 8924 1012 11388 2038 2019 2590 3739 2144 2049 5508 1999 26805 1015 1010 5385 2086 3283 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.092419 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.093248 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:impossible example\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.094104 140073664845568 tf_logging.py:115] impossible example\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.099008 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.099964 140073664845568 tf_logging.py:115] unique_id: 1000000015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.100783 140073664845568 tf_logging.py:115] example_index: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.101593 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] who embraced his family according to the new testament ? [SEP] the ha ##gio ##graphy of mary and the holy family can be contrasted with other material in the gospels . these references include an incident which can be interpreted as jesus rejecting his family in the new testament : \" and his mother and his brothers arrived , and standing outside , they sent in a message asking for him . . . and looking at those who sat in a circle around him , jesus said , ' these are my mother and my brothers . whoever does the will of god is my brother , and sister , and mother ' . \" [ 3 : 31 - 35 ] other verses suggest a conflict between jesus and his family , including an attempt to have jesus restrained because \" he is out of his mind \" , and the famous quote : \" a prophet is not without honor except in his own town , among his relatives and in his own home . \" a leading biblical scholar commented : \" there are clear signs not only that jesus ' s family rejected his message during his public ministry but that he in turn spur ##ned them publicly \" . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.102547 140073664845568 tf_logging.py:115] tokens: [CLS] who embraced his family according to the new testament ? [SEP] the ha ##gio ##graphy of mary and the holy family can be contrasted with other material in the gospels . these references include an incident which can be interpreted as jesus rejecting his family in the new testament : \" and his mother and his brothers arrived , and standing outside , they sent in a message asking for him . . . and looking at those who sat in a circle around him , jesus said , ' these are my mother and my brothers . whoever does the will of god is my brother , and sister , and mother ' . \" [ 3 : 31 - 35 ] other verses suggest a conflict between jesus and his family , including an attempt to have jesus restrained because \" he is out of his mind \" , and the famous quote : \" a prophet is not without honor except in his own town , among his relatives and in his own home . \" a leading biblical scholar commented : \" there are clear signs not only that jesus ' s family rejected his message during his public ministry but that he in turn spur ##ned them publicly \" . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 12:0 13:1 14:1 15:1 16:2 17:3 18:4 19:5 20:6 21:7 22:8 23:9 24:10 25:11 26:12 27:13 28:14 29:15 30:16 31:16 32:17 33:18 34:19 35:20 36:21 37:22 38:23 39:24 40:25 41:26 42:27 43:28 44:29 45:30 46:31 47:32 48:33 49:34 50:34 51:35 52:35 53:36 54:37 55:38 56:39 57:40 58:41 59:41 60:42 61:43 62:44 63:44 64:45 65:46 66:47 67:48 68:49 69:50 70:51 71:52 72:53 73:53 74:53 75:54 76:55 77:56 78:57 79:58 80:59 81:60 82:61 83:62 84:63 85:64 86:64 87:65 88:66 89:66 90:67 91:67 92:68 93:69 94:70 95:71 96:72 97:73 98:73 99:74 100:75 101:76 102:77 103:78 104:79 105:80 106:81 107:82 108:82 109:83 110:84 111:84 112:85 113:86 114:86 115:86 116:86 117:86 118:86 119:86 120:86 121:86 122:86 123:86 124:87 125:88 126:89 127:90 128:91 129:92 130:93 131:94 132:95 133:96 134:96 135:97 136:98 137:99 138:100 139:101 140:102 141:103 142:104 143:105 144:105 145:106 146:107 147:108 148:109 149:110 150:110 151:110 152:111 153:112 154:113 155:114 156:114 157:115 158:115 159:116 160:117 161:118 162:119 163:120 164:121 165:122 166:123 167:124 168:125 169:125 170:126 171:127 172:128 173:129 174:130 175:131 176:132 177:133 178:133 179:133 180:134 181:135 182:136 183:137 184:138 185:138 186:139 187:139 188:140 189:141 190:142 191:143 192:144 193:145 194:146 195:146 196:146 197:147 198:148 199:149 200:150 201:151 202:152 203:153 204:154 205:155 206:156 207:157 208:158 209:159 210:160 211:160 212:161 213:162 214:162 215:162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.103460 140073664845568 tf_logging.py:115] token_to_orig_map: 12:0 13:1 14:1 15:1 16:2 17:3 18:4 19:5 20:6 21:7 22:8 23:9 24:10 25:11 26:12 27:13 28:14 29:15 30:16 31:16 32:17 33:18 34:19 35:20 36:21 37:22 38:23 39:24 40:25 41:26 42:27 43:28 44:29 45:30 46:31 47:32 48:33 49:34 50:34 51:35 52:35 53:36 54:37 55:38 56:39 57:40 58:41 59:41 60:42 61:43 62:44 63:44 64:45 65:46 66:47 67:48 68:49 69:50 70:51 71:52 72:53 73:53 74:53 75:54 76:55 77:56 78:57 79:58 80:59 81:60 82:61 83:62 84:63 85:64 86:64 87:65 88:66 89:66 90:67 91:67 92:68 93:69 94:70 95:71 96:72 97:73 98:73 99:74 100:75 101:76 102:77 103:78 104:79 105:80 106:81 107:82 108:82 109:83 110:84 111:84 112:85 113:86 114:86 115:86 116:86 117:86 118:86 119:86 120:86 121:86 122:86 123:86 124:87 125:88 126:89 127:90 128:91 129:92 130:93 131:94 132:95 133:96 134:96 135:97 136:98 137:99 138:100 139:101 140:102 141:103 142:104 143:105 144:105 145:106 146:107 147:108 148:109 149:110 150:110 151:110 152:111 153:112 154:113 155:114 156:114 157:115 158:115 159:116 160:117 161:118 162:119 163:120 164:121 165:122 166:123 167:124 168:125 169:125 170:126 171:127 172:128 173:129 174:130 175:131 176:132 177:133 178:133 179:133 180:134 181:135 182:136 183:137 184:138 185:138 186:139 187:139 188:140 189:141 190:142 191:143 192:144 193:145 194:146 195:146 196:146 197:147 198:148 199:149 200:150 201:151 202:152 203:153 204:154 205:155 206:156 207:157 208:158 209:159 210:160 211:160 212:161 213:162 214:162 215:162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.104288 140073664845568 tf_logging.py:115] token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2040 14218 2010 2155 2429 2000 1996 2047 9025 1029 102 1996 5292 11411 12565 1997 2984 1998 1996 4151 2155 2064 2022 22085 2007 2060 3430 1999 1996 24131 1012 2122 7604 2421 2019 5043 2029 2064 2022 10009 2004 4441 21936 2010 2155 1999 1996 2047 9025 1024 1000 1998 2010 2388 1998 2010 3428 3369 1010 1998 3061 2648 1010 2027 2741 1999 1037 4471 4851 2005 2032 1012 1012 1012 1998 2559 2012 2216 2040 2938 1999 1037 4418 2105 2032 1010 4441 2056 1010 1005 2122 2024 2026 2388 1998 2026 3428 1012 9444 2515 1996 2097 1997 2643 2003 2026 2567 1010 1998 2905 1010 1998 2388 1005 1012 1000 1031 1017 1024 2861 1011 3486 1033 2060 11086 6592 1037 4736 2090 4441 1998 2010 2155 1010 2164 2019 3535 2000 2031 4441 19868 2138 1000 2002 2003 2041 1997 2010 2568 1000 1010 1998 1996 3297 14686 1024 1000 1037 12168 2003 2025 2302 3932 3272 1999 2010 2219 2237 1010 2426 2010 9064 1998 1999 2010 2219 2188 1012 1000 1037 2877 10213 6288 7034 1024 1000 2045 2024 3154 5751 2025 2069 2008 4441 1005 1055 2155 5837 2010 4471 2076 2010 2270 3757 2021 2008 2002 1999 2735 12996 7228 2068 7271 1000 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.105151 140073664845568 tf_logging.py:115] input_ids: 101 2040 14218 2010 2155 2429 2000 1996 2047 9025 1029 102 1996 5292 11411 12565 1997 2984 1998 1996 4151 2155 2064 2022 22085 2007 2060 3430 1999 1996 24131 1012 2122 7604 2421 2019 5043 2029 2064 2022 10009 2004 4441 21936 2010 2155 1999 1996 2047 9025 1024 1000 1998 2010 2388 1998 2010 3428 3369 1010 1998 3061 2648 1010 2027 2741 1999 1037 4471 4851 2005 2032 1012 1012 1012 1998 2559 2012 2216 2040 2938 1999 1037 4418 2105 2032 1010 4441 2056 1010 1005 2122 2024 2026 2388 1998 2026 3428 1012 9444 2515 1996 2097 1997 2643 2003 2026 2567 1010 1998 2905 1010 1998 2388 1005 1012 1000 1031 1017 1024 2861 1011 3486 1033 2060 11086 6592 1037 4736 2090 4441 1998 2010 2155 1010 2164 2019 3535 2000 2031 4441 19868 2138 1000 2002 2003 2041 1997 2010 2568 1000 1010 1998 1996 3297 14686 1024 1000 1037 12168 2003 2025 2302 3932 3272 1999 2010 2219 2237 1010 2426 2010 9064 1998 1999 2010 2219 2188 1012 1000 1037 2877 10213 6288 7034 1024 1000 2045 2024 3154 5751 2025 2069 2008 4441 1005 1055 2155 5837 2010 4471 2076 2010 2270 3757 2021 2008 2002 1999 2735 12996 7228 2068 7271 1000 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.106042 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.106884 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:impossible example\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.107622 140073664845568 tf_logging.py:115] impossible example\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.111842 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.112770 140073664845568 tf_logging.py:115] unique_id: 1000000016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.113630 140073664845568 tf_logging.py:115] example_index: 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.114567 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] where does a bill go once the president signs it into effect ? [SEP] after the president signs a bill into law ( or congress en ##act ##s it over his veto ) , it is delivered to the office of the federal register ( of ##r ) of the national archives and records administration ( nara ) where it is assigned a law number , and prepared for publication as a slip law . public laws , but not private laws , are also given legal statutory citation by the of ##r . at the end of each session of congress , the slip laws are compiled into bound volumes called the united states statutes at large , and they are known as session laws . the statutes at large present a chronological arrangement of the laws in the exact order that they have been enacted . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.115467 140073664845568 tf_logging.py:115] tokens: [CLS] where does a bill go once the president signs it into effect ? [SEP] after the president signs a bill into law ( or congress en ##act ##s it over his veto ) , it is delivered to the office of the federal register ( of ##r ) of the national archives and records administration ( nara ) where it is assigned a law number , and prepared for publication as a slip law . public laws , but not private laws , are also given legal statutory citation by the of ##r . at the end of each session of congress , the slip laws are compiled into bound volumes called the united states statutes at large , and they are known as session laws . the statutes at large present a chronological arrangement of the laws in the exact order that they have been enacted . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 15:0 16:1 17:2 18:3 19:4 20:5 21:6 22:7 23:8 24:8 25:9 26:10 27:10 28:10 29:11 30:12 31:13 32:14 33:14 34:14 35:15 36:16 37:17 38:18 39:19 40:20 41:21 42:22 43:23 44:24 45:25 46:25 47:25 48:25 49:26 50:27 51:28 52:29 53:30 54:31 55:32 56:33 57:33 58:33 59:34 60:35 61:36 62:37 63:38 64:39 65:40 66:40 67:41 68:42 69:43 70:44 71:45 72:46 73:47 74:48 75:48 76:49 77:50 78:50 79:51 80:52 81:53 82:54 83:54 84:55 85:56 86:57 87:58 88:59 89:60 90:61 91:62 92:63 93:63 94:63 95:64 96:65 97:66 98:67 99:68 100:69 101:70 102:71 103:71 104:72 105:73 106:74 107:75 108:76 109:77 110:78 111:79 112:80 113:81 114:82 115:83 116:84 117:85 118:86 119:86 120:87 121:88 122:89 123:90 124:91 125:92 126:93 127:93 128:94 129:95 130:96 131:97 132:98 133:99 134:100 135:101 136:102 137:103 138:104 139:105 140:106 141:107 142:108 143:109 144:110 145:111 146:112 147:113 148:113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.116259 140073664845568 tf_logging.py:115] token_to_orig_map: 15:0 16:1 17:2 18:3 19:4 20:5 21:6 22:7 23:8 24:8 25:9 26:10 27:10 28:10 29:11 30:12 31:13 32:14 33:14 34:14 35:15 36:16 37:17 38:18 39:19 40:20 41:21 42:22 43:23 44:24 45:25 46:25 47:25 48:25 49:26 50:27 51:28 52:29 53:30 54:31 55:32 56:33 57:33 58:33 59:34 60:35 61:36 62:37 63:38 64:39 65:40 66:40 67:41 68:42 69:43 70:44 71:45 72:46 73:47 74:48 75:48 76:49 77:50 78:50 79:51 80:52 81:53 82:54 83:54 84:55 85:56 86:57 87:58 88:59 89:60 90:61 91:62 92:63 93:63 94:63 95:64 96:65 97:66 98:67 99:68 100:69 101:70 102:71 103:71 104:72 105:73 106:74 107:75 108:76 109:77 110:78 111:79 112:80 113:81 114:82 115:83 116:84 117:85 118:86 119:86 120:87 121:88 122:89 123:90 124:91 125:92 126:93 127:93 128:94 129:95 130:96 131:97 132:98 133:99 134:100 135:101 136:102 137:103 138:104 139:105 140:106 141:107 142:108 143:109 144:110 145:111 146:112 147:113 148:113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.117066 140073664845568 tf_logging.py:115] token_is_max_context: 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2073 2515 1037 3021 2175 2320 1996 2343 5751 2009 2046 3466 1029 102 2044 1996 2343 5751 1037 3021 2046 2375 1006 2030 3519 4372 18908 2015 2009 2058 2010 22102 1007 1010 2009 2003 5359 2000 1996 2436 1997 1996 2976 4236 1006 1997 2099 1007 1997 1996 2120 8264 1998 2636 3447 1006 27544 1007 2073 2009 2003 4137 1037 2375 2193 1010 1998 4810 2005 4772 2004 1037 7540 2375 1012 2270 4277 1010 2021 2025 2797 4277 1010 2024 2036 2445 3423 15201 11091 2011 1996 1997 2099 1012 2012 1996 2203 1997 2169 5219 1997 3519 1010 1996 7540 4277 2024 9227 2046 5391 6702 2170 1996 2142 2163 18574 2012 2312 1010 1998 2027 2024 2124 2004 5219 4277 1012 1996 18574 2012 2312 2556 1037 23472 6512 1997 1996 4277 1999 1996 6635 2344 2008 2027 2031 2042 11955 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.117897 140073664845568 tf_logging.py:115] input_ids: 101 2073 2515 1037 3021 2175 2320 1996 2343 5751 2009 2046 3466 1029 102 2044 1996 2343 5751 1037 3021 2046 2375 1006 2030 3519 4372 18908 2015 2009 2058 2010 22102 1007 1010 2009 2003 5359 2000 1996 2436 1997 1996 2976 4236 1006 1997 2099 1007 1997 1996 2120 8264 1998 2636 3447 1006 27544 1007 2073 2009 2003 4137 1037 2375 2193 1010 1998 4810 2005 4772 2004 1037 7540 2375 1012 2270 4277 1010 2021 2025 2797 4277 1010 2024 2036 2445 3423 15201 11091 2011 1996 1997 2099 1012 2012 1996 2203 1997 2169 5219 1997 3519 1010 1996 7540 4277 2024 9227 2046 5391 6702 2170 1996 2142 2163 18574 2012 2312 1010 1998 2027 2024 2124 2004 5219 4277 1012 1996 18574 2012 2312 2556 1037 23472 6512 1997 1996 4277 1999 1996 6635 2344 2008 2027 2031 2042 11955 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.118801 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.119604 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:start_position: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.120275 140073664845568 tf_logging.py:115] start_position: 37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:end_position: 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.121035 140073664845568 tf_logging.py:115] end_position: 58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:answer: delivered to the office of the federal register ( of ##r ) of the national archives and records administration ( nara )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.121696 140073664845568 tf_logging.py:115] answer: delivered to the office of the federal register ( of ##r ) of the national archives and records administration ( nara )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.126498 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.127447 140073664845568 tf_logging.py:115] unique_id: 1000000017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.128311 140073664845568 tf_logging.py:115] example_index: 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.129146 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] what other beginnings of origin ##ation do some of the last names of the greeks share ? [SEP] greek surname ##s were widely in use by the 9th century su ##pp ##lan ##ting the ancient tradition of using the father  s name , however greek surname ##s are most commonly patron ##ym ##ics . commonly , greek male surname ##s end in - s , which is the common ending for greek masculine proper nouns in the no ##mina ##tive case . exceptionally , some end in - ou , indicating the gen ##itive case of this proper noun for patron ##ym ##ic reasons . although surname ##s in mainland greece are static today , dynamic and changing patron ##ym ##ic usage survives in middle names where the gen ##itive of father ' s first name is commonly the middle name ( this usage having been passed on to the russians ) . in cyprus , by contrast , surname ##s follow the ancient tradition of being given according to the father  s name . finally , in addition to greek - derived surname ##s many have latin , turkish and italian origin . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.130061 140073664845568 tf_logging.py:115] tokens: [CLS] what other beginnings of origin ##ation do some of the last names of the greeks share ? [SEP] greek surname ##s were widely in use by the 9th century su ##pp ##lan ##ting the ancient tradition of using the father  s name , however greek surname ##s are most commonly patron ##ym ##ics . commonly , greek male surname ##s end in - s , which is the common ending for greek masculine proper nouns in the no ##mina ##tive case . exceptionally , some end in - ou , indicating the gen ##itive case of this proper noun for patron ##ym ##ic reasons . although surname ##s in mainland greece are static today , dynamic and changing patron ##ym ##ic usage survives in middle names where the gen ##itive of father ' s first name is commonly the middle name ( this usage having been passed on to the russians ) . in cyprus , by contrast , surname ##s follow the ancient tradition of being given according to the father  s name . finally , in addition to greek - derived surname ##s many have latin , turkish and italian origin . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 19:0 20:1 21:1 22:2 23:3 24:4 25:5 26:6 27:7 28:8 29:9 30:10 31:10 32:10 33:10 34:11 35:12 36:13 37:14 38:15 39:16 40:17 41:17 42:17 43:18 44:18 45:19 46:20 47:21 48:21 49:22 50:23 51:24 52:25 53:25 54:25 55:25 56:26 57:26 58:27 59:28 60:29 61:29 62:30 63:31 64:32 65:32 66:32 67:33 68:34 69:35 70:36 71:37 72:38 73:39 74:40 75:41 76:42 77:43 78:44 79:45 80:45 81:45 82:46 83:46 84:47 85:47 86:48 87:49 88:50 89:51 90:51 91:51 92:52 93:53 94:54 95:54 96:55 97:56 98:57 99:58 100:59 101:60 102:61 103:61 104:61 105:62 106:62 107:63 108:64 109:64 110:65 111:66 112:67 113:68 114:69 115:70 116:70 117:71 118:72 119:73 120:74 121:74 122:74 123:75 124:76 125:77 126:78 127:79 128:80 129:81 130:82 131:82 132:83 133:84 134:84 135:84 136:85 137:86 138:87 139:88 140:89 141:90 142:91 143:92 144:92 145:93 146:94 147:95 148:96 149:97 150:98 151:99 152:100 153:100 154:100 155:101 156:102 157:102 158:103 159:104 160:104 161:105 162:105 163:106 164:107 165:108 166:109 167:110 168:111 169:112 170:113 171:114 172:115 173:116 174:116 175:116 176:117 177:117 178:118 179:118 180:119 181:120 182:121 183:122 184:122 185:122 186:123 187:123 188:124 189:125 190:126 191:126 192:127 193:128 194:129 195:130 196:130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.130907 140073664845568 tf_logging.py:115] token_to_orig_map: 19:0 20:1 21:1 22:2 23:3 24:4 25:5 26:6 27:7 28:8 29:9 30:10 31:10 32:10 33:10 34:11 35:12 36:13 37:14 38:15 39:16 40:17 41:17 42:17 43:18 44:18 45:19 46:20 47:21 48:21 49:22 50:23 51:24 52:25 53:25 54:25 55:25 56:26 57:26 58:27 59:28 60:29 61:29 62:30 63:31 64:32 65:32 66:32 67:33 68:34 69:35 70:36 71:37 72:38 73:39 74:40 75:41 76:42 77:43 78:44 79:45 80:45 81:45 82:46 83:46 84:47 85:47 86:48 87:49 88:50 89:51 90:51 91:51 92:52 93:53 94:54 95:54 96:55 97:56 98:57 99:58 100:59 101:60 102:61 103:61 104:61 105:62 106:62 107:63 108:64 109:64 110:65 111:66 112:67 113:68 114:69 115:70 116:70 117:71 118:72 119:73 120:74 121:74 122:74 123:75 124:76 125:77 126:78 127:79 128:80 129:81 130:82 131:82 132:83 133:84 134:84 135:84 136:85 137:86 138:87 139:88 140:89 141:90 142:91 143:92 144:92 145:93 146:94 147:95 148:96 149:97 150:98 151:99 152:100 153:100 154:100 155:101 156:102 157:102 158:103 159:104 160:104 161:105 162:105 163:106 164:107 165:108 166:109 167:110 168:111 169:112 170:113 171:114 172:115 173:116 174:116 175:116 176:117 177:117 178:118 179:118 180:119 181:120 182:121 183:122 184:122 185:122 186:123 187:123 188:124 189:125 190:126 191:126 192:127 193:128 194:129 195:130 196:130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.131681 140073664845568 tf_logging.py:115] token_is_max_context: 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2054 2060 16508 1997 4761 3370 2079 2070 1997 1996 2197 3415 1997 1996 13176 3745 1029 102 3306 11988 2015 2020 4235 1999 2224 2011 1996 6280 2301 10514 9397 5802 3436 1996 3418 4535 1997 2478 1996 2269 1521 1055 2171 1010 2174 3306 11988 2015 2024 2087 4141 9161 24335 6558 1012 4141 1010 3306 3287 11988 2015 2203 1999 1011 1055 1010 2029 2003 1996 2691 4566 2005 3306 14818 5372 19211 1999 1996 2053 22311 6024 2553 1012 17077 1010 2070 2203 1999 1011 15068 1010 8131 1996 8991 13043 2553 1997 2023 5372 15156 2005 9161 24335 2594 4436 1012 2348 11988 2015 1999 8240 5483 2024 10763 2651 1010 8790 1998 5278 9161 24335 2594 8192 13655 1999 2690 3415 2073 1996 8991 13043 1997 2269 1005 1055 2034 2171 2003 4141 1996 2690 2171 1006 2023 8192 2383 2042 2979 2006 2000 1996 12513 1007 1012 1999 9719 1010 2011 5688 1010 11988 2015 3582 1996 3418 4535 1997 2108 2445 2429 2000 1996 2269 1521 1055 2171 1012 2633 1010 1999 2804 2000 3306 1011 5173 11988 2015 2116 2031 3763 1010 5037 1998 3059 4761 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.132446 140073664845568 tf_logging.py:115] input_ids: 101 2054 2060 16508 1997 4761 3370 2079 2070 1997 1996 2197 3415 1997 1996 13176 3745 1029 102 3306 11988 2015 2020 4235 1999 2224 2011 1996 6280 2301 10514 9397 5802 3436 1996 3418 4535 1997 2478 1996 2269 1521 1055 2171 1010 2174 3306 11988 2015 2024 2087 4141 9161 24335 6558 1012 4141 1010 3306 3287 11988 2015 2203 1999 1011 1055 1010 2029 2003 1996 2691 4566 2005 3306 14818 5372 19211 1999 1996 2053 22311 6024 2553 1012 17077 1010 2070 2203 1999 1011 15068 1010 8131 1996 8991 13043 2553 1997 2023 5372 15156 2005 9161 24335 2594 4436 1012 2348 11988 2015 1999 8240 5483 2024 10763 2651 1010 8790 1998 5278 9161 24335 2594 8192 13655 1999 2690 3415 2073 1996 8991 13043 1997 2269 1005 1055 2034 2171 2003 4141 1996 2690 2171 1006 2023 8192 2383 2042 2979 2006 2000 1996 12513 1007 1012 1999 9719 1010 2011 5688 1010 11988 2015 3582 1996 3418 4535 1997 2108 2445 2429 2000 1996 2269 1521 1055 2171 1012 2633 1010 1999 2804 2000 3306 1011 5173 11988 2015 2116 2031 3763 1010 5037 1998 3059 4761 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.133289 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.134174 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:start_position: 188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.134902 140073664845568 tf_logging.py:115] start_position: 188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:end_position: 196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.135595 140073664845568 tf_logging.py:115] end_position: 196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:answer: many have latin , turkish and italian origin .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.136321 140073664845568 tf_logging.py:115] answer: many have latin , turkish and italian origin .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.138908 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.139816 140073664845568 tf_logging.py:115] unique_id: 1000000018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.140636 140073664845568 tf_logging.py:115] example_index: 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.141484 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] what is the function of a \" beer engine \" ? [SEP] a \" beer engine \" is a device for pumping beer , originally manually operated and typically used to di ##sp ##ense beer from a cas ##k or container in a pub ' s basement or cellar . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.142365 140073664845568 tf_logging.py:115] tokens: [CLS] what is the function of a \" beer engine \" ? [SEP] a \" beer engine \" is a device for pumping beer , originally manually operated and typically used to di ##sp ##ense beer from a cas ##k or container in a pub ' s basement or cellar . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 13:0 14:1 15:1 16:2 17:2 18:3 19:4 20:5 21:6 22:7 23:8 24:8 25:9 26:10 27:11 28:12 29:13 30:14 31:15 32:16 33:16 34:16 35:17 36:18 37:19 38:20 39:20 40:21 41:22 42:23 43:24 44:25 45:25 46:25 47:26 48:27 49:28 50:28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.143139 140073664845568 tf_logging.py:115] token_to_orig_map: 13:0 14:1 15:1 16:2 17:2 18:3 19:4 20:5 21:6 22:7 23:8 24:8 25:9 26:10 27:11 28:12 29:13 30:14 31:15 32:16 33:16 34:16 35:17 36:18 37:19 38:20 39:20 40:21 41:22 42:23 43:24 44:25 45:25 46:25 47:26 48:27 49:28 50:28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.143842 140073664845568 tf_logging.py:115] token_is_max_context: 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2054 2003 1996 3853 1997 1037 1000 5404 3194 1000 1029 102 1037 1000 5404 3194 1000 2003 1037 5080 2005 14107 5404 1010 2761 21118 3498 1998 4050 2109 2000 4487 13102 16700 5404 2013 1037 25222 2243 2030 11661 1999 1037 9047 1005 1055 8102 2030 15423 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.144576 140073664845568 tf_logging.py:115] input_ids: 101 2054 2003 1996 3853 1997 1037 1000 5404 3194 1000 1029 102 1037 1000 5404 3194 1000 2003 1037 5080 2005 14107 5404 1010 2761 21118 3498 1998 4050 2109 2000 4487 13102 16700 5404 2013 1037 25222 2243 2030 11661 1999 1037 9047 1005 1055 8102 2030 15423 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.145431 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.146331 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:start_position: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.147061 140073664845568 tf_logging.py:115] start_position: 31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:end_position: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.147755 140073664845568 tf_logging.py:115] end_position: 49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:answer: to di ##sp ##ense beer from a cas ##k or container in a pub ' s basement or cellar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.148443 140073664845568 tf_logging.py:115] answer: to di ##sp ##ense beer from a cas ##k or container in a pub ' s basement or cellar\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.151946 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.194121 140073664845568 tf_logging.py:115] unique_id: 1000000019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.195057 140073664845568 tf_logging.py:115] example_index: 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.196111 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] what coats uranium metal in liquid ? [SEP] uranium metal reacts with almost all non - metal elements ( with an exception of the noble gases ) and their compounds , with react ##ivity increasing with temperature . hydro ##ch ##lor ##ic and ni ##tric acids dissolve uranium , but non - ox ##idi ##zing acids other than hydro ##ch ##lor ##ic acid attack the element very slowly . when finely divided , it can react with cold water ; in air , uranium metal becomes coated with a dark layer of uranium oxide . uranium in ore ##s is extracted chemical ##ly and converted into uranium dioxide or other chemical forms usable in industry . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.197055 140073664845568 tf_logging.py:115] tokens: [CLS] what coats uranium metal in liquid ? [SEP] uranium metal reacts with almost all non - metal elements ( with an exception of the noble gases ) and their compounds , with react ##ivity increasing with temperature . hydro ##ch ##lor ##ic and ni ##tric acids dissolve uranium , but non - ox ##idi ##zing acids other than hydro ##ch ##lor ##ic acid attack the element very slowly . when finely divided , it can react with cold water ; in air , uranium metal becomes coated with a dark layer of uranium oxide . uranium in ore ##s is extracted chemical ##ly and converted into uranium dioxide or other chemical forms usable in industry . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 9:0 10:1 11:2 12:3 13:4 14:5 15:6 16:6 17:6 18:7 19:8 20:8 21:9 22:10 23:11 24:12 25:13 26:14 27:14 28:15 29:16 30:17 31:17 32:18 33:19 34:19 35:20 36:21 37:22 38:22 39:23 40:23 41:23 42:23 43:24 44:25 45:25 46:26 47:27 48:28 49:28 50:29 51:30 52:30 53:30 54:30 55:30 56:31 57:32 58:33 59:34 60:34 61:34 62:34 63:35 64:36 65:37 66:38 67:39 68:40 69:40 70:41 71:42 72:43 73:43 74:44 75:45 76:46 77:47 78:48 79:49 80:49 81:50 82:51 83:51 84:52 85:53 86:54 87:55 88:56 89:57 90:58 91:59 92:60 93:61 94:62 95:62 96:63 97:64 98:65 99:65 100:66 101:67 102:68 103:68 104:69 105:70 106:71 107:72 108:73 109:74 110:75 111:76 112:77 113:78 114:79 115:80 116:80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.198110 140073664845568 tf_logging.py:115] token_to_orig_map: 9:0 10:1 11:2 12:3 13:4 14:5 15:6 16:6 17:6 18:7 19:8 20:8 21:9 22:10 23:11 24:12 25:13 26:14 27:14 28:15 29:16 30:17 31:17 32:18 33:19 34:19 35:20 36:21 37:22 38:22 39:23 40:23 41:23 42:23 43:24 44:25 45:25 46:26 47:27 48:28 49:28 50:29 51:30 52:30 53:30 54:30 55:30 56:31 57:32 58:33 59:34 60:34 61:34 62:34 63:35 64:36 65:37 66:38 67:39 68:40 69:40 70:41 71:42 72:43 73:43 74:44 75:45 76:46 77:47 78:48 79:49 80:49 81:50 82:51 83:51 84:52 85:53 86:54 87:55 88:56 89:57 90:58 91:59 92:60 93:61 94:62 95:62 96:63 97:64 98:65 99:65 100:66 101:67 102:68 103:68 104:69 105:70 106:71 107:72 108:73 109:74 110:75 111:76 112:77 113:78 114:79 115:80 116:80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.199302 140073664845568 tf_logging.py:115] token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2054 15695 14247 3384 1999 6381 1029 102 14247 3384 27325 2007 2471 2035 2512 1011 3384 3787 1006 2007 2019 6453 1997 1996 7015 15865 1007 1998 2037 10099 1010 2007 10509 7730 4852 2007 4860 1012 18479 2818 10626 2594 1998 9152 12412 12737 21969 14247 1010 2021 2512 1011 23060 28173 6774 12737 2060 2084 18479 2818 10626 2594 5648 2886 1996 5783 2200 3254 1012 2043 22126 4055 1010 2009 2064 10509 2007 3147 2300 1025 1999 2250 1010 14247 3384 4150 15026 2007 1037 2601 6741 1997 14247 15772 1012 14247 1999 10848 2015 2003 15901 5072 2135 1998 4991 2046 14247 14384 2030 2060 5072 3596 24013 1999 3068 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.200295 140073664845568 tf_logging.py:115] input_ids: 101 2054 15695 14247 3384 1999 6381 1029 102 14247 3384 27325 2007 2471 2035 2512 1011 3384 3787 1006 2007 2019 6453 1997 1996 7015 15865 1007 1998 2037 10099 1010 2007 10509 7730 4852 2007 4860 1012 18479 2818 10626 2594 1998 9152 12412 12737 21969 14247 1010 2021 2512 1011 23060 28173 6774 12737 2060 2084 18479 2818 10626 2594 5648 2886 1996 5783 2200 3254 1012 2043 22126 4055 1010 2009 2064 10509 2007 3147 2300 1025 1999 2250 1010 14247 3384 4150 15026 2007 1037 2601 6741 1997 14247 15772 1012 14247 1999 10848 2015 2003 15901 5072 2135 1998 4991 2046 14247 14384 2030 2060 5072 3596 24013 1999 3068 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.201280 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.202397 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:impossible example\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:19:37.203229 140073664845568 tf_logging.py:115] impossible example\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:***** Running training *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:26:58.999393 140073664845568 tf_logging.py:115] ***** Running training *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  Num orig examples = 130319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:26:59.001095 140073664845568 tf_logging.py:115]   Num orig examples = 130319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  Num split examples = 131944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:26:59.002826 140073664845568 tf_logging.py:115]   Num split examples = 131944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  Batch size = 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:26:59.003886 140073664845568 tf_logging.py:115]   Batch size = 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  Num steps = 21719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:26:59.004727 140073664845568 tf_logging.py:115]   Num steps = 21719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:26:59.221098 140073664845568 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running train on CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:26:59.222347 140073664845568 tf_logging.py:115] Running train on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Features ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:26:59.223398 140073664845568 tf_logging.py:115] *** Features ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = end_positions, shape = (12,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:26:59.226138 140073664845568 tf_logging.py:115]   name = end_positions, shape = (12,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = input_ids, shape = (12, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:26:59.226831 140073664845568 tf_logging.py:115]   name = input_ids, shape = (12, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = input_mask, shape = (12, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:26:59.227732 140073664845568 tf_logging.py:115]   name = input_mask, shape = (12, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = segment_ids, shape = (12, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:26:59.228661 140073664845568 tf_logging.py:115]   name = segment_ids, shape = (12, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = start_positions, shape = (12,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:26:59.229486 140073664845568 tf_logging.py:115]   name = start_positions, shape = (12,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = unique_ids, shape = (12,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:26:59.230414 140073664845568 tf_logging.py:115]   name = unique_ids, shape = (12,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/embeddings/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/embeddings/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.245449 140073664845568 tf_logging.py:115] Initialize variable bert/embeddings/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/embeddings/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/embeddings/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/embeddings/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.250263 140073664845568 tf_logging.py:115] Initialize variable bert/embeddings/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/embeddings/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/embeddings/position_embeddings:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/embeddings/position_embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.255079 140073664845568 tf_logging.py:115] Initialize variable bert/embeddings/position_embeddings:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/embeddings/position_embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/embeddings/token_type_embeddings:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/embeddings/token_type_embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.259368 140073664845568 tf_logging.py:115] Initialize variable bert/embeddings/token_type_embeddings:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/embeddings/token_type_embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/embeddings/word_embeddings:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/embeddings/word_embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.263795 140073664845568 tf_logging.py:115] Initialize variable bert/embeddings/word_embeddings:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/embeddings/word_embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_0/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.268098 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_0/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_0/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.272409 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_0/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_0/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.276679 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_0/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_0/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.280960 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_0/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_0/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.285327 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_0/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_0/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.289584 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_0/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_0/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.293871 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_0/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_0/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.298086 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_0/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_0/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.302359 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_0/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_0/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.306547 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_0/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_0/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.310820 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_0/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_0/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.315041 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_0/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_0/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.319496 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_0/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_0/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.323735 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_0/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_0/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.327980 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_0/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_0/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.332333 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_0/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_1/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.336568 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_1/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_1/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.340868 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_1/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_1/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.345140 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_1/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_1/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.349479 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_1/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_1/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.353696 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_1/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_1/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.358033 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_1/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_1/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.362252 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_1/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_1/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.366606 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_1/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_1/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.371358 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_1/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_1/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.375634 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_1/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_1/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.380063 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_1/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_1/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.384289 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_1/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_1/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.388683 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_1/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_1/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.392920 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_1/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_1/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.397226 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_1/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_1/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.401463 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_1/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_10/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.405728 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_10/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_10/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.409941 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_10/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_10/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.414128 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_10/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_10/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.420924 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_10/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_10/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.425626 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_10/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_10/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.430032 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_10/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_10/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.434280 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_10/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_10/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.438649 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_10/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_10/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.442895 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_10/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_10/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.447316 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_10/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_10/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.451768 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_10/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_10/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.456127 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_10/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_10/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.460530 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_10/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_10/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.464862 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_10/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_10/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.469318 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_10/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_10/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.475254 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_10/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_11/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.479671 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_11/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_11/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.483945 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_11/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_11/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.488226 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_11/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_11/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.493159 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_11/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_11/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.497436 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_11/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_11/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.501733 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_11/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_11/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.505976 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_11/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_11/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.510304 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_11/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_11/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.514541 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_11/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_11/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.518817 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_11/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_11/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.523120 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_11/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_11/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.527410 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_11/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_11/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.531820 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_11/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_11/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.536205 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_11/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_11/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.540588 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_11/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_11/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.544929 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_11/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_2/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.549269 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_2/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_2/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.553671 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_2/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_2/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.557943 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_2/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_2/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.562241 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_2/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_2/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.566528 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_2/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_2/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.570782 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_2/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_2/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.575119 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_2/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_2/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.579475 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_2/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_2/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.583973 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_2/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_2/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.588243 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_2/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_2/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.592613 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_2/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_2/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.596957 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_2/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_2/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.601235 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_2/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_2/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.605566 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_2/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_2/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.609814 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_2/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_2/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.614686 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_2/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_3/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.618975 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_3/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_3/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.623282 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_3/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_3/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.627600 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_3/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_3/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.631909 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_3/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_3/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.636302 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_3/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_3/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.640606 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_3/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_3/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.645049 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_3/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_3/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.649348 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_3/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_3/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.653631 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_3/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_3/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.658002 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_3/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_3/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.662309 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_3/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_3/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.666678 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_3/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_3/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.670988 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_3/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_3/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.675333 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_3/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_3/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.679617 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_3/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_3/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.683912 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_3/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_4/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.688241 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_4/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_4/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.692517 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_4/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_4/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.696899 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_4/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_4/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.701192 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_4/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_4/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.705509 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_4/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_4/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.709744 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_4/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_4/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.714045 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_4/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_4/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.718348 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_4/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_4/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.722608 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_4/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_4/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.726979 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_4/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_4/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.731229 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_4/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_4/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.736101 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_4/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_4/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.740483 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_4/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_4/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.744758 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_4/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_4/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.749100 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_4/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_4/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.753494 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_4/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_5/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.757858 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_5/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_5/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.762141 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_5/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_5/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.766515 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_5/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_5/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.770751 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_5/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_5/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.775142 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_5/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_5/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.779463 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_5/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_5/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.783757 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_5/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_5/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.788089 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_5/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_5/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.792380 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_5/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_5/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.796763 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_5/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_5/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.801107 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_5/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_5/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.805379 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_5/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_5/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.809690 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_5/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_5/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.813915 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_5/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_5/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.818228 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_5/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_5/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.822515 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_5/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_6/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.826873 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_6/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_6/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.831114 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_6/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_6/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.835471 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_6/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_6/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.839826 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_6/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_6/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.844106 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_6/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_6/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.848461 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_6/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_6/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.852787 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_6/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_6/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.857659 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_6/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_6/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.861904 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_6/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_6/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.866153 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_6/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_6/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.870463 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_6/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_6/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.874747 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_6/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_6/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.879078 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_6/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_6/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.883303 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_6/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_6/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.887673 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_6/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_6/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.891977 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_6/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_7/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.896300 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_7/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_7/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.900755 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_7/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_7/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.905024 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_7/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_7/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.909368 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_7/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_7/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.913609 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_7/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_7/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.917890 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_7/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_7/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.922313 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_7/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_7/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.926540 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_7/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_7/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.930837 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_7/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_7/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.935130 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_7/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_7/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.939471 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_7/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_7/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.943829 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_7/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_7/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.948135 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_7/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_7/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.952528 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_7/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_7/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.956799 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_7/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_7/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.961141 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_7/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_8/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.965426 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_8/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_8/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.969791 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_8/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_8/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.974089 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_8/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_8/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.978383 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_8/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_8/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.983328 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_8/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_8/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.987616 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_8/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_8/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.991974 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_8/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_8/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:01.996291 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_8/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_8/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.000774 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_8/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_8/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.005187 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_8/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_8/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.009504 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_8/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_8/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.013886 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_8/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_8/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.018208 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_8/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_8/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.022896 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_8/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_8/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.027129 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_8/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_8/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.031467 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_8/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_9/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.035808 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_9/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_9/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.040086 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_9/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_9/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.044431 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_9/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_9/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.048729 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_9/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_9/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.053110 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_9/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_9/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.057406 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_9/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_9/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.061734 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_9/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_9/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.066023 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_9/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_9/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.070259 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_9/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_9/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.074554 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_9/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_9/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.078818 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_9/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_9/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.083134 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_9/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_9/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.087432 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_9/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_9/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.091852 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_9/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_9/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.096155 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_9/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_9/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.100439 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_9/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/pooler/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/pooler/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.105357 140073664845568 tf_logging.py:115] Initialize variable bert/pooler/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/pooler/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/pooler/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/pooler/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.109746 140073664845568 tf_logging.py:115] Initialize variable bert/pooler/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/pooler/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:**** Trainable Variables ****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.110805 140073664845568 tf_logging.py:115] **** Trainable Variables ****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.111657 140073664845568 tf_logging.py:115]   name = bert/embeddings/word_embeddings:0, shape = (30522, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.112644 140073664845568 tf_logging.py:115]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.113475 140073664845568 tf_logging.py:115]   name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.114452 140073664845568 tf_logging.py:115]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.115401 140073664845568 tf_logging.py:115]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.116259 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.117284 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.118372 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.119179 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.120015 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.120839 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.121612 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.122696 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.123517 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.124403 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.125182 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.125988 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.126843 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.127570 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.128298 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.129093 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.130054 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.132175 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.132886 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.133769 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.134722 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.135536 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.136408 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.137121 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.137951 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.138676 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.139410 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.140321 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.141079 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.142004 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.142896 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.143829 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.144578 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.145447 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.146487 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.147235 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.148035 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.148778 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.149574 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.150418 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.151148 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.151897 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.152556 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.153250 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.154139 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.154824 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.155485 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.156212 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.156879 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.157624 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.158444 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.159165 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.159884 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.160551 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.161269 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.162130 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.162827 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.163489 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.164146 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.164831 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.165639 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.166540 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.167344 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.168058 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.168852 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.169696 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.170708 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.171436 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.172213 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.172945 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.173934 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.174710 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.175575 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.176548 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.177266 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.178331 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.179038 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.179807 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.180532 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.181309 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.182189 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.182936 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.183660 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.184434 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.185217 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.186125 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.186875 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.187689 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.188701 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.189496 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.190386 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.191127 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.191905 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.192700 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.193473 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.194485 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.195313 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.196074 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.196921 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.197725 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.198626 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.199413 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.200232 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.200949 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.202030 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.202778 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.203592 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.204381 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.205101 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.205975 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.206789 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.207504 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.208222 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.208954 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.209852 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.210665 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.211452 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.212211 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.212936 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.213747 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.214550 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.215282 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.215998 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.216718 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.217555 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.218447 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.219182 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.219904 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.220625 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.221343 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.222150 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.222832 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.223558 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.224295 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.225019 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.226009 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.227496 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.228509 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.229331 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.230432 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.231279 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.232237 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.233247 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.234218 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.235448 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.236294 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.237202 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.238169 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.239162 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.240137 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.241176 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.242382 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.243239 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.244047 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.244910 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.246017 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.246849 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.247731 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.248603 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.249499 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.250551 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.251419 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.252350 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.253311 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.254539 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.255307 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.256189 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.257028 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.258173 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.259122 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.259978 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.282292 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.283246 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.284195 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.285054 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.286122 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.286902 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.288186 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.289068 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.289945 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.291039 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.292271 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.293250 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.294482 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.295542 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.296415 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.297469 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.298501 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.299201 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.299897 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.300755 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.301623 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.302454 140073664845568 tf_logging.py:115]   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.303303 140073664845568 tf_logging.py:115]   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = cls/squad/output_weights:0, shape = (2, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.304105 140073664845568 tf_logging.py:115]   name = cls/squad/output_weights:0, shape = (2, 768)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = cls/squad/output_bias:0, shape = (2,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:02.304946 140073664845568 tf_logging.py:115]   name = cls/squad/output_bias:0, shape = (2,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:09.216533 140073664845568 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:09.220262 140073664845568 tf_logging.py:115] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:12.588686 140073664845568 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:24.449715 140073664845568 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:24.543321 140073664845568 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:27:29.449385 140073664845568 tf_logging.py:115] Saving checkpoints for 0 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:33:47.629301 140073664845568 tf_logging.py:115] Saving checkpoints for 1000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:39:59.226989 140073664845568 tf_logging.py:115] Saving checkpoints for 2000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 3000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:46:10.835663 140073664845568 tf_logging.py:115] Saving checkpoints for 3000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 4000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:52:22.243415 140073664845568 tf_logging.py:115] Saving checkpoints for 4000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 5000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 18:58:33.680115 140073664845568 tf_logging.py:115] Saving checkpoints for 5000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 6000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 19:04:45.502356 140073664845568 tf_logging.py:115] Saving checkpoints for 6000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 7000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 19:10:57.163345 140073664845568 tf_logging.py:115] Saving checkpoints for 7000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 8000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 19:17:08.784510 140073664845568 tf_logging.py:115] Saving checkpoints for 8000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 9000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 19:23:20.667026 140073664845568 tf_logging.py:115] Saving checkpoints for 9000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 10000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 19:29:32.144328 140073664845568 tf_logging.py:115] Saving checkpoints for 10000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 11000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 19:35:43.413170 140073664845568 tf_logging.py:115] Saving checkpoints for 11000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 12000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 19:41:55.113839 140073664845568 tf_logging.py:115] Saving checkpoints for 12000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 13000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 19:48:06.827058 140073664845568 tf_logging.py:115] Saving checkpoints for 13000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 14000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 19:54:18.430257 140073664845568 tf_logging.py:115] Saving checkpoints for 14000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 15000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:00:30.028088 140073664845568 tf_logging.py:115] Saving checkpoints for 15000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 16000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:06:41.551046 140073664845568 tf_logging.py:115] Saving checkpoints for 16000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 17000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:12:52.956949 140073664845568 tf_logging.py:115] Saving checkpoints for 17000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 18000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:19:04.536080 140073664845568 tf_logging.py:115] Saving checkpoints for 18000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 19000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:25:15.842884 140073664845568 tf_logging.py:115] Saving checkpoints for 19000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 20000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:31:27.534530 140073664845568 tf_logging.py:115] Saving checkpoints for 20000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 21000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:37:39.016931 140073664845568 tf_logging.py:115] Saving checkpoints for 21000 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 21719 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:08.569354 140073664845568 tf_logging.py:115] Saving checkpoints for 21719 into squad/output/jupyter/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.69175595.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:16.974833 140073664845568 tf_logging.py:115] Loss for final step: 0.69175595.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.458508 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.460136 140073664845568 tf_logging.py:115] unique_id: 1000000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.461046 140073664845568 tf_logging.py:115] example_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.461785 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] in what country is normandy located ? [SEP] the norman ##s ( norman : no ##ur ##man ##ds ; french : norman ##ds ; latin : norman ##ni ) were the people who in the 10th and 11th centuries gave their name to normandy , a region in france . they were descended from norse ( \" norman \" comes from \" norse ##man \" ) raiders and pirates from denmark , iceland and norway who , under their leader roll ##o , agreed to swear fe ##al ##ty to king charles iii of west fran ##cia . through generations of assimilation and mixing with the native frankish and roman - gaul ##ish populations , their descendants would gradually merge with the carol ##ing ##ian - based cultures of west fran ##cia . the distinct cultural and ethnic identity of the norman ##s emerged initially in the first half of the 10th century , and it continued to evolve over the succeeding centuries . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.462570 140073664845568 tf_logging.py:115] tokens: [CLS] in what country is normandy located ? [SEP] the norman ##s ( norman : no ##ur ##man ##ds ; french : norman ##ds ; latin : norman ##ni ) were the people who in the 10th and 11th centuries gave their name to normandy , a region in france . they were descended from norse ( \" norman \" comes from \" norse ##man \" ) raiders and pirates from denmark , iceland and norway who , under their leader roll ##o , agreed to swear fe ##al ##ty to king charles iii of west fran ##cia . through generations of assimilation and mixing with the native frankish and roman - gaul ##ish populations , their descendants would gradually merge with the carol ##ing ##ian - based cultures of west fran ##cia . the distinct cultural and ethnic identity of the norman ##s emerged initially in the first half of the 10th century , and it continued to evolve over the succeeding centuries . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 9:0 10:1 11:1 12:2 13:2 14:2 15:3 16:3 17:3 18:3 19:3 20:4 21:4 22:5 23:5 24:5 25:6 26:6 27:7 28:7 29:7 30:8 31:9 32:10 33:11 34:12 35:13 36:14 37:15 38:16 39:17 40:18 41:19 42:20 43:21 44:22 45:22 46:23 47:24 48:25 49:26 50:26 51:27 52:28 53:29 54:30 55:31 56:32 57:32 58:32 59:32 60:33 61:34 62:35 63:35 64:35 65:35 66:35 67:36 68:37 69:38 70:39 71:40 72:40 73:41 74:42 75:43 76:44 77:44 78:45 79:46 80:47 81:48 82:48 83:48 84:49 85:50 86:51 87:52 88:52 89:52 90:53 91:54 92:55 93:56 94:57 95:58 96:59 97:59 98:59 99:60 100:61 101:62 102:63 103:64 104:65 105:66 106:67 107:68 108:69 109:70 110:71 111:71 112:71 113:71 114:72 115:72 116:73 117:74 118:75 119:76 120:77 121:78 122:79 123:80 124:80 125:80 126:80 127:80 128:81 129:82 130:83 131:84 132:84 133:84 134:85 135:86 136:87 137:88 138:89 139:90 140:91 141:92 142:93 143:93 144:94 145:95 146:96 147:97 148:98 149:99 150:100 151:101 152:102 153:103 154:103 155:104 156:105 157:106 158:107 159:108 160:109 161:110 162:111 163:112 164:112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.463392 140073664845568 tf_logging.py:115] token_to_orig_map: 9:0 10:1 11:1 12:2 13:2 14:2 15:3 16:3 17:3 18:3 19:3 20:4 21:4 22:5 23:5 24:5 25:6 26:6 27:7 28:7 29:7 30:8 31:9 32:10 33:11 34:12 35:13 36:14 37:15 38:16 39:17 40:18 41:19 42:20 43:21 44:22 45:22 46:23 47:24 48:25 49:26 50:26 51:27 52:28 53:29 54:30 55:31 56:32 57:32 58:32 59:32 60:33 61:34 62:35 63:35 64:35 65:35 66:35 67:36 68:37 69:38 70:39 71:40 72:40 73:41 74:42 75:43 76:44 77:44 78:45 79:46 80:47 81:48 82:48 83:48 84:49 85:50 86:51 87:52 88:52 89:52 90:53 91:54 92:55 93:56 94:57 95:58 96:59 97:59 98:59 99:60 100:61 101:62 102:63 103:64 104:65 105:66 106:67 107:68 108:69 109:70 110:71 111:71 112:71 113:71 114:72 115:72 116:73 117:74 118:75 119:76 120:77 121:78 122:79 123:80 124:80 125:80 126:80 127:80 128:81 129:82 130:83 131:84 132:84 133:84 134:85 135:86 136:87 137:88 138:89 139:90 140:91 141:92 142:93 143:93 144:94 145:95 146:96 147:97 148:98 149:99 150:100 151:101 152:102 153:103 154:103 155:104 156:105 157:106 158:107 159:108 160:109 161:110 162:111 163:112 164:112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.464225 140073664845568 tf_logging.py:115] token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1999 2054 2406 2003 13298 2284 1029 102 1996 5879 2015 1006 5879 1024 2053 3126 2386 5104 1025 2413 1024 5879 5104 1025 3763 1024 5879 3490 1007 2020 1996 2111 2040 1999 1996 6049 1998 6252 4693 2435 2037 2171 2000 13298 1010 1037 2555 1999 2605 1012 2027 2020 9287 2013 15342 1006 1000 5879 1000 3310 2013 1000 15342 2386 1000 1007 10642 1998 8350 2013 5842 1010 10399 1998 5120 2040 1010 2104 2037 3003 4897 2080 1010 3530 2000 8415 10768 2389 3723 2000 2332 2798 3523 1997 2225 23151 7405 1012 2083 8213 1997 27574 1998 6809 2007 1996 3128 26165 1998 3142 1011 26522 4509 7080 1010 2037 8481 2052 6360 13590 2007 1996 8594 2075 2937 1011 2241 8578 1997 2225 23151 7405 1012 1996 5664 3451 1998 5636 4767 1997 1996 5879 2015 6003 3322 1999 1996 2034 2431 1997 1996 6049 2301 1010 1998 2009 2506 2000 19852 2058 1996 13034 4693 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.465177 140073664845568 tf_logging.py:115] input_ids: 101 1999 2054 2406 2003 13298 2284 1029 102 1996 5879 2015 1006 5879 1024 2053 3126 2386 5104 1025 2413 1024 5879 5104 1025 3763 1024 5879 3490 1007 2020 1996 2111 2040 1999 1996 6049 1998 6252 4693 2435 2037 2171 2000 13298 1010 1037 2555 1999 2605 1012 2027 2020 9287 2013 15342 1006 1000 5879 1000 3310 2013 1000 15342 2386 1000 1007 10642 1998 8350 2013 5842 1010 10399 1998 5120 2040 1010 2104 2037 3003 4897 2080 1010 3530 2000 8415 10768 2389 3723 2000 2332 2798 3523 1997 2225 23151 7405 1012 2083 8213 1997 27574 1998 6809 2007 1996 3128 26165 1998 3142 1011 26522 4509 7080 1010 2037 8481 2052 6360 13590 2007 1996 8594 2075 2937 1011 2241 8578 1997 2225 23151 7405 1012 1996 5664 3451 1998 5636 4767 1997 1996 5879 2015 6003 3322 1999 1996 2034 2431 1997 1996 6049 2301 1010 1998 2009 2506 2000 19852 2058 1996 13034 4693 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.465999 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.466831 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.471053 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.471892 140073664845568 tf_logging.py:115] unique_id: 1000000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.472628 140073664845568 tf_logging.py:115] example_index: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.473351 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] when were the norman ##s in normandy ? [SEP] the norman ##s ( norman : no ##ur ##man ##ds ; french : norman ##ds ; latin : norman ##ni ) were the people who in the 10th and 11th centuries gave their name to normandy , a region in france . they were descended from norse ( \" norman \" comes from \" norse ##man \" ) raiders and pirates from denmark , iceland and norway who , under their leader roll ##o , agreed to swear fe ##al ##ty to king charles iii of west fran ##cia . through generations of assimilation and mixing with the native frankish and roman - gaul ##ish populations , their descendants would gradually merge with the carol ##ing ##ian - based cultures of west fran ##cia . the distinct cultural and ethnic identity of the norman ##s emerged initially in the first half of the 10th century , and it continued to evolve over the succeeding centuries . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.474141 140073664845568 tf_logging.py:115] tokens: [CLS] when were the norman ##s in normandy ? [SEP] the norman ##s ( norman : no ##ur ##man ##ds ; french : norman ##ds ; latin : norman ##ni ) were the people who in the 10th and 11th centuries gave their name to normandy , a region in france . they were descended from norse ( \" norman \" comes from \" norse ##man \" ) raiders and pirates from denmark , iceland and norway who , under their leader roll ##o , agreed to swear fe ##al ##ty to king charles iii of west fran ##cia . through generations of assimilation and mixing with the native frankish and roman - gaul ##ish populations , their descendants would gradually merge with the carol ##ing ##ian - based cultures of west fran ##cia . the distinct cultural and ethnic identity of the norman ##s emerged initially in the first half of the 10th century , and it continued to evolve over the succeeding centuries . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 10:0 11:1 12:1 13:2 14:2 15:2 16:3 17:3 18:3 19:3 20:3 21:4 22:4 23:5 24:5 25:5 26:6 27:6 28:7 29:7 30:7 31:8 32:9 33:10 34:11 35:12 36:13 37:14 38:15 39:16 40:17 41:18 42:19 43:20 44:21 45:22 46:22 47:23 48:24 49:25 50:26 51:26 52:27 53:28 54:29 55:30 56:31 57:32 58:32 59:32 60:32 61:33 62:34 63:35 64:35 65:35 66:35 67:35 68:36 69:37 70:38 71:39 72:40 73:40 74:41 75:42 76:43 77:44 78:44 79:45 80:46 81:47 82:48 83:48 84:48 85:49 86:50 87:51 88:52 89:52 90:52 91:53 92:54 93:55 94:56 95:57 96:58 97:59 98:59 99:59 100:60 101:61 102:62 103:63 104:64 105:65 106:66 107:67 108:68 109:69 110:70 111:71 112:71 113:71 114:71 115:72 116:72 117:73 118:74 119:75 120:76 121:77 122:78 123:79 124:80 125:80 126:80 127:80 128:80 129:81 130:82 131:83 132:84 133:84 134:84 135:85 136:86 137:87 138:88 139:89 140:90 141:91 142:92 143:93 144:93 145:94 146:95 147:96 148:97 149:98 150:99 151:100 152:101 153:102 154:103 155:103 156:104 157:105 158:106 159:107 160:108 161:109 162:110 163:111 164:112 165:112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.474924 140073664845568 tf_logging.py:115] token_to_orig_map: 10:0 11:1 12:1 13:2 14:2 15:2 16:3 17:3 18:3 19:3 20:3 21:4 22:4 23:5 24:5 25:5 26:6 27:6 28:7 29:7 30:7 31:8 32:9 33:10 34:11 35:12 36:13 37:14 38:15 39:16 40:17 41:18 42:19 43:20 44:21 45:22 46:22 47:23 48:24 49:25 50:26 51:26 52:27 53:28 54:29 55:30 56:31 57:32 58:32 59:32 60:32 61:33 62:34 63:35 64:35 65:35 66:35 67:35 68:36 69:37 70:38 71:39 72:40 73:40 74:41 75:42 76:43 77:44 78:44 79:45 80:46 81:47 82:48 83:48 84:48 85:49 86:50 87:51 88:52 89:52 90:52 91:53 92:54 93:55 94:56 95:57 96:58 97:59 98:59 99:59 100:60 101:61 102:62 103:63 104:64 105:65 106:66 107:67 108:68 109:69 110:70 111:71 112:71 113:71 114:71 115:72 116:72 117:73 118:74 119:75 120:76 121:77 122:78 123:79 124:80 125:80 126:80 127:80 128:80 129:81 130:82 131:83 132:84 133:84 134:84 135:85 136:86 137:87 138:88 139:89 140:90 141:91 142:92 143:93 144:93 145:94 146:95 147:96 148:97 149:98 150:99 151:100 152:101 153:102 154:103 155:103 156:104 157:105 158:106 159:107 160:108 161:109 162:110 163:111 164:112 165:112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.475700 140073664845568 tf_logging.py:115] token_is_max_context: 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2043 2020 1996 5879 2015 1999 13298 1029 102 1996 5879 2015 1006 5879 1024 2053 3126 2386 5104 1025 2413 1024 5879 5104 1025 3763 1024 5879 3490 1007 2020 1996 2111 2040 1999 1996 6049 1998 6252 4693 2435 2037 2171 2000 13298 1010 1037 2555 1999 2605 1012 2027 2020 9287 2013 15342 1006 1000 5879 1000 3310 2013 1000 15342 2386 1000 1007 10642 1998 8350 2013 5842 1010 10399 1998 5120 2040 1010 2104 2037 3003 4897 2080 1010 3530 2000 8415 10768 2389 3723 2000 2332 2798 3523 1997 2225 23151 7405 1012 2083 8213 1997 27574 1998 6809 2007 1996 3128 26165 1998 3142 1011 26522 4509 7080 1010 2037 8481 2052 6360 13590 2007 1996 8594 2075 2937 1011 2241 8578 1997 2225 23151 7405 1012 1996 5664 3451 1998 5636 4767 1997 1996 5879 2015 6003 3322 1999 1996 2034 2431 1997 1996 6049 2301 1010 1998 2009 2506 2000 19852 2058 1996 13034 4693 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.476541 140073664845568 tf_logging.py:115] input_ids: 101 2043 2020 1996 5879 2015 1999 13298 1029 102 1996 5879 2015 1006 5879 1024 2053 3126 2386 5104 1025 2413 1024 5879 5104 1025 3763 1024 5879 3490 1007 2020 1996 2111 2040 1999 1996 6049 1998 6252 4693 2435 2037 2171 2000 13298 1010 1037 2555 1999 2605 1012 2027 2020 9287 2013 15342 1006 1000 5879 1000 3310 2013 1000 15342 2386 1000 1007 10642 1998 8350 2013 5842 1010 10399 1998 5120 2040 1010 2104 2037 3003 4897 2080 1010 3530 2000 8415 10768 2389 3723 2000 2332 2798 3523 1997 2225 23151 7405 1012 2083 8213 1997 27574 1998 6809 2007 1996 3128 26165 1998 3142 1011 26522 4509 7080 1010 2037 8481 2052 6360 13590 2007 1996 8594 2075 2937 1011 2241 8578 1997 2225 23151 7405 1012 1996 5664 3451 1998 5636 4767 1997 1996 5879 2015 6003 3322 1999 1996 2034 2431 1997 1996 6049 2301 1010 1998 2009 2506 2000 19852 2058 1996 13034 4693 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.477351 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.478176 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.482184 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.482979 140073664845568 tf_logging.py:115] unique_id: 1000000002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.483708 140073664845568 tf_logging.py:115] example_index: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.484433 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] from which countries did the norse originate ? [SEP] the norman ##s ( norman : no ##ur ##man ##ds ; french : norman ##ds ; latin : norman ##ni ) were the people who in the 10th and 11th centuries gave their name to normandy , a region in france . they were descended from norse ( \" norman \" comes from \" norse ##man \" ) raiders and pirates from denmark , iceland and norway who , under their leader roll ##o , agreed to swear fe ##al ##ty to king charles iii of west fran ##cia . through generations of assimilation and mixing with the native frankish and roman - gaul ##ish populations , their descendants would gradually merge with the carol ##ing ##ian - based cultures of west fran ##cia . the distinct cultural and ethnic identity of the norman ##s emerged initially in the first half of the 10th century , and it continued to evolve over the succeeding centuries . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.485474 140073664845568 tf_logging.py:115] tokens: [CLS] from which countries did the norse originate ? [SEP] the norman ##s ( norman : no ##ur ##man ##ds ; french : norman ##ds ; latin : norman ##ni ) were the people who in the 10th and 11th centuries gave their name to normandy , a region in france . they were descended from norse ( \" norman \" comes from \" norse ##man \" ) raiders and pirates from denmark , iceland and norway who , under their leader roll ##o , agreed to swear fe ##al ##ty to king charles iii of west fran ##cia . through generations of assimilation and mixing with the native frankish and roman - gaul ##ish populations , their descendants would gradually merge with the carol ##ing ##ian - based cultures of west fran ##cia . the distinct cultural and ethnic identity of the norman ##s emerged initially in the first half of the 10th century , and it continued to evolve over the succeeding centuries . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 10:0 11:1 12:1 13:2 14:2 15:2 16:3 17:3 18:3 19:3 20:3 21:4 22:4 23:5 24:5 25:5 26:6 27:6 28:7 29:7 30:7 31:8 32:9 33:10 34:11 35:12 36:13 37:14 38:15 39:16 40:17 41:18 42:19 43:20 44:21 45:22 46:22 47:23 48:24 49:25 50:26 51:26 52:27 53:28 54:29 55:30 56:31 57:32 58:32 59:32 60:32 61:33 62:34 63:35 64:35 65:35 66:35 67:35 68:36 69:37 70:38 71:39 72:40 73:40 74:41 75:42 76:43 77:44 78:44 79:45 80:46 81:47 82:48 83:48 84:48 85:49 86:50 87:51 88:52 89:52 90:52 91:53 92:54 93:55 94:56 95:57 96:58 97:59 98:59 99:59 100:60 101:61 102:62 103:63 104:64 105:65 106:66 107:67 108:68 109:69 110:70 111:71 112:71 113:71 114:71 115:72 116:72 117:73 118:74 119:75 120:76 121:77 122:78 123:79 124:80 125:80 126:80 127:80 128:80 129:81 130:82 131:83 132:84 133:84 134:84 135:85 136:86 137:87 138:88 139:89 140:90 141:91 142:92 143:93 144:93 145:94 146:95 147:96 148:97 149:98 150:99 151:100 152:101 153:102 154:103 155:103 156:104 157:105 158:106 159:107 160:108 161:109 162:110 163:111 164:112 165:112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.486272 140073664845568 tf_logging.py:115] token_to_orig_map: 10:0 11:1 12:1 13:2 14:2 15:2 16:3 17:3 18:3 19:3 20:3 21:4 22:4 23:5 24:5 25:5 26:6 27:6 28:7 29:7 30:7 31:8 32:9 33:10 34:11 35:12 36:13 37:14 38:15 39:16 40:17 41:18 42:19 43:20 44:21 45:22 46:22 47:23 48:24 49:25 50:26 51:26 52:27 53:28 54:29 55:30 56:31 57:32 58:32 59:32 60:32 61:33 62:34 63:35 64:35 65:35 66:35 67:35 68:36 69:37 70:38 71:39 72:40 73:40 74:41 75:42 76:43 77:44 78:44 79:45 80:46 81:47 82:48 83:48 84:48 85:49 86:50 87:51 88:52 89:52 90:52 91:53 92:54 93:55 94:56 95:57 96:58 97:59 98:59 99:59 100:60 101:61 102:62 103:63 104:64 105:65 106:66 107:67 108:68 109:69 110:70 111:71 112:71 113:71 114:71 115:72 116:72 117:73 118:74 119:75 120:76 121:77 122:78 123:79 124:80 125:80 126:80 127:80 128:80 129:81 130:82 131:83 132:84 133:84 134:84 135:85 136:86 137:87 138:88 139:89 140:90 141:91 142:92 143:93 144:93 145:94 146:95 147:96 148:97 149:98 150:99 151:100 152:101 153:102 154:103 155:103 156:104 157:105 158:106 159:107 160:108 161:109 162:110 163:111 164:112 165:112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.487058 140073664845568 tf_logging.py:115] token_is_max_context: 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2013 2029 3032 2106 1996 15342 21754 1029 102 1996 5879 2015 1006 5879 1024 2053 3126 2386 5104 1025 2413 1024 5879 5104 1025 3763 1024 5879 3490 1007 2020 1996 2111 2040 1999 1996 6049 1998 6252 4693 2435 2037 2171 2000 13298 1010 1037 2555 1999 2605 1012 2027 2020 9287 2013 15342 1006 1000 5879 1000 3310 2013 1000 15342 2386 1000 1007 10642 1998 8350 2013 5842 1010 10399 1998 5120 2040 1010 2104 2037 3003 4897 2080 1010 3530 2000 8415 10768 2389 3723 2000 2332 2798 3523 1997 2225 23151 7405 1012 2083 8213 1997 27574 1998 6809 2007 1996 3128 26165 1998 3142 1011 26522 4509 7080 1010 2037 8481 2052 6360 13590 2007 1996 8594 2075 2937 1011 2241 8578 1997 2225 23151 7405 1012 1996 5664 3451 1998 5636 4767 1997 1996 5879 2015 6003 3322 1999 1996 2034 2431 1997 1996 6049 2301 1010 1998 2009 2506 2000 19852 2058 1996 13034 4693 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.487876 140073664845568 tf_logging.py:115] input_ids: 101 2013 2029 3032 2106 1996 15342 21754 1029 102 1996 5879 2015 1006 5879 1024 2053 3126 2386 5104 1025 2413 1024 5879 5104 1025 3763 1024 5879 3490 1007 2020 1996 2111 2040 1999 1996 6049 1998 6252 4693 2435 2037 2171 2000 13298 1010 1037 2555 1999 2605 1012 2027 2020 9287 2013 15342 1006 1000 5879 1000 3310 2013 1000 15342 2386 1000 1007 10642 1998 8350 2013 5842 1010 10399 1998 5120 2040 1010 2104 2037 3003 4897 2080 1010 3530 2000 8415 10768 2389 3723 2000 2332 2798 3523 1997 2225 23151 7405 1012 2083 8213 1997 27574 1998 6809 2007 1996 3128 26165 1998 3142 1011 26522 4509 7080 1010 2037 8481 2052 6360 13590 2007 1996 8594 2075 2937 1011 2241 8578 1997 2225 23151 7405 1012 1996 5664 3451 1998 5636 4767 1997 1996 5879 2015 6003 3322 1999 1996 2034 2431 1997 1996 6049 2301 1010 1998 2009 2506 2000 19852 2058 1996 13034 4693 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.488683 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.489484 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.493462 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.494242 140073664845568 tf_logging.py:115] unique_id: 1000000003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.494971 140073664845568 tf_logging.py:115] example_index: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.495688 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] who was the norse leader ? [SEP] the norman ##s ( norman : no ##ur ##man ##ds ; french : norman ##ds ; latin : norman ##ni ) were the people who in the 10th and 11th centuries gave their name to normandy , a region in france . they were descended from norse ( \" norman \" comes from \" norse ##man \" ) raiders and pirates from denmark , iceland and norway who , under their leader roll ##o , agreed to swear fe ##al ##ty to king charles iii of west fran ##cia . through generations of assimilation and mixing with the native frankish and roman - gaul ##ish populations , their descendants would gradually merge with the carol ##ing ##ian - based cultures of west fran ##cia . the distinct cultural and ethnic identity of the norman ##s emerged initially in the first half of the 10th century , and it continued to evolve over the succeeding centuries . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.496446 140073664845568 tf_logging.py:115] tokens: [CLS] who was the norse leader ? [SEP] the norman ##s ( norman : no ##ur ##man ##ds ; french : norman ##ds ; latin : norman ##ni ) were the people who in the 10th and 11th centuries gave their name to normandy , a region in france . they were descended from norse ( \" norman \" comes from \" norse ##man \" ) raiders and pirates from denmark , iceland and norway who , under their leader roll ##o , agreed to swear fe ##al ##ty to king charles iii of west fran ##cia . through generations of assimilation and mixing with the native frankish and roman - gaul ##ish populations , their descendants would gradually merge with the carol ##ing ##ian - based cultures of west fran ##cia . the distinct cultural and ethnic identity of the norman ##s emerged initially in the first half of the 10th century , and it continued to evolve over the succeeding centuries . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 8:0 9:1 10:1 11:2 12:2 13:2 14:3 15:3 16:3 17:3 18:3 19:4 20:4 21:5 22:5 23:5 24:6 25:6 26:7 27:7 28:7 29:8 30:9 31:10 32:11 33:12 34:13 35:14 36:15 37:16 38:17 39:18 40:19 41:20 42:21 43:22 44:22 45:23 46:24 47:25 48:26 49:26 50:27 51:28 52:29 53:30 54:31 55:32 56:32 57:32 58:32 59:33 60:34 61:35 62:35 63:35 64:35 65:35 66:36 67:37 68:38 69:39 70:40 71:40 72:41 73:42 74:43 75:44 76:44 77:45 78:46 79:47 80:48 81:48 82:48 83:49 84:50 85:51 86:52 87:52 88:52 89:53 90:54 91:55 92:56 93:57 94:58 95:59 96:59 97:59 98:60 99:61 100:62 101:63 102:64 103:65 104:66 105:67 106:68 107:69 108:70 109:71 110:71 111:71 112:71 113:72 114:72 115:73 116:74 117:75 118:76 119:77 120:78 121:79 122:80 123:80 124:80 125:80 126:80 127:81 128:82 129:83 130:84 131:84 132:84 133:85 134:86 135:87 136:88 137:89 138:90 139:91 140:92 141:93 142:93 143:94 144:95 145:96 146:97 147:98 148:99 149:100 150:101 151:102 152:103 153:103 154:104 155:105 156:106 157:107 158:108 159:109 160:110 161:111 162:112 163:112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.497213 140073664845568 tf_logging.py:115] token_to_orig_map: 8:0 9:1 10:1 11:2 12:2 13:2 14:3 15:3 16:3 17:3 18:3 19:4 20:4 21:5 22:5 23:5 24:6 25:6 26:7 27:7 28:7 29:8 30:9 31:10 32:11 33:12 34:13 35:14 36:15 37:16 38:17 39:18 40:19 41:20 42:21 43:22 44:22 45:23 46:24 47:25 48:26 49:26 50:27 51:28 52:29 53:30 54:31 55:32 56:32 57:32 58:32 59:33 60:34 61:35 62:35 63:35 64:35 65:35 66:36 67:37 68:38 69:39 70:40 71:40 72:41 73:42 74:43 75:44 76:44 77:45 78:46 79:47 80:48 81:48 82:48 83:49 84:50 85:51 86:52 87:52 88:52 89:53 90:54 91:55 92:56 93:57 94:58 95:59 96:59 97:59 98:60 99:61 100:62 101:63 102:64 103:65 104:66 105:67 106:68 107:69 108:70 109:71 110:71 111:71 112:71 113:72 114:72 115:73 116:74 117:75 118:76 119:77 120:78 121:79 122:80 123:80 124:80 125:80 126:80 127:81 128:82 129:83 130:84 131:84 132:84 133:85 134:86 135:87 136:88 137:89 138:90 139:91 140:92 141:93 142:93 143:94 144:95 145:96 146:97 147:98 148:99 149:100 150:101 151:102 152:103 153:103 154:104 155:105 156:106 157:107 158:108 159:109 160:110 161:111 162:112 163:112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.498038 140073664845568 tf_logging.py:115] token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2040 2001 1996 15342 3003 1029 102 1996 5879 2015 1006 5879 1024 2053 3126 2386 5104 1025 2413 1024 5879 5104 1025 3763 1024 5879 3490 1007 2020 1996 2111 2040 1999 1996 6049 1998 6252 4693 2435 2037 2171 2000 13298 1010 1037 2555 1999 2605 1012 2027 2020 9287 2013 15342 1006 1000 5879 1000 3310 2013 1000 15342 2386 1000 1007 10642 1998 8350 2013 5842 1010 10399 1998 5120 2040 1010 2104 2037 3003 4897 2080 1010 3530 2000 8415 10768 2389 3723 2000 2332 2798 3523 1997 2225 23151 7405 1012 2083 8213 1997 27574 1998 6809 2007 1996 3128 26165 1998 3142 1011 26522 4509 7080 1010 2037 8481 2052 6360 13590 2007 1996 8594 2075 2937 1011 2241 8578 1997 2225 23151 7405 1012 1996 5664 3451 1998 5636 4767 1997 1996 5879 2015 6003 3322 1999 1996 2034 2431 1997 1996 6049 2301 1010 1998 2009 2506 2000 19852 2058 1996 13034 4693 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.498876 140073664845568 tf_logging.py:115] input_ids: 101 2040 2001 1996 15342 3003 1029 102 1996 5879 2015 1006 5879 1024 2053 3126 2386 5104 1025 2413 1024 5879 5104 1025 3763 1024 5879 3490 1007 2020 1996 2111 2040 1999 1996 6049 1998 6252 4693 2435 2037 2171 2000 13298 1010 1037 2555 1999 2605 1012 2027 2020 9287 2013 15342 1006 1000 5879 1000 3310 2013 1000 15342 2386 1000 1007 10642 1998 8350 2013 5842 1010 10399 1998 5120 2040 1010 2104 2037 3003 4897 2080 1010 3530 2000 8415 10768 2389 3723 2000 2332 2798 3523 1997 2225 23151 7405 1012 2083 8213 1997 27574 1998 6809 2007 1996 3128 26165 1998 3142 1011 26522 4509 7080 1010 2037 8481 2052 6360 13590 2007 1996 8594 2075 2937 1011 2241 8578 1997 2225 23151 7405 1012 1996 5664 3451 1998 5636 4767 1997 1996 5879 2015 6003 3322 1999 1996 2034 2431 1997 1996 6049 2301 1010 1998 2009 2506 2000 19852 2058 1996 13034 4693 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.499815 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.500704 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.504643 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.505433 140073664845568 tf_logging.py:115] unique_id: 1000000004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.506163 140073664845568 tf_logging.py:115] example_index: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.506883 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] what century did the norman ##s first gain their separate identity ? [SEP] the norman ##s ( norman : no ##ur ##man ##ds ; french : norman ##ds ; latin : norman ##ni ) were the people who in the 10th and 11th centuries gave their name to normandy , a region in france . they were descended from norse ( \" norman \" comes from \" norse ##man \" ) raiders and pirates from denmark , iceland and norway who , under their leader roll ##o , agreed to swear fe ##al ##ty to king charles iii of west fran ##cia . through generations of assimilation and mixing with the native frankish and roman - gaul ##ish populations , their descendants would gradually merge with the carol ##ing ##ian - based cultures of west fran ##cia . the distinct cultural and ethnic identity of the norman ##s emerged initially in the first half of the 10th century , and it continued to evolve over the succeeding centuries . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.507645 140073664845568 tf_logging.py:115] tokens: [CLS] what century did the norman ##s first gain their separate identity ? [SEP] the norman ##s ( norman : no ##ur ##man ##ds ; french : norman ##ds ; latin : norman ##ni ) were the people who in the 10th and 11th centuries gave their name to normandy , a region in france . they were descended from norse ( \" norman \" comes from \" norse ##man \" ) raiders and pirates from denmark , iceland and norway who , under their leader roll ##o , agreed to swear fe ##al ##ty to king charles iii of west fran ##cia . through generations of assimilation and mixing with the native frankish and roman - gaul ##ish populations , their descendants would gradually merge with the carol ##ing ##ian - based cultures of west fran ##cia . the distinct cultural and ethnic identity of the norman ##s emerged initially in the first half of the 10th century , and it continued to evolve over the succeeding centuries . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 14:0 15:1 16:1 17:2 18:2 19:2 20:3 21:3 22:3 23:3 24:3 25:4 26:4 27:5 28:5 29:5 30:6 31:6 32:7 33:7 34:7 35:8 36:9 37:10 38:11 39:12 40:13 41:14 42:15 43:16 44:17 45:18 46:19 47:20 48:21 49:22 50:22 51:23 52:24 53:25 54:26 55:26 56:27 57:28 58:29 59:30 60:31 61:32 62:32 63:32 64:32 65:33 66:34 67:35 68:35 69:35 70:35 71:35 72:36 73:37 74:38 75:39 76:40 77:40 78:41 79:42 80:43 81:44 82:44 83:45 84:46 85:47 86:48 87:48 88:48 89:49 90:50 91:51 92:52 93:52 94:52 95:53 96:54 97:55 98:56 99:57 100:58 101:59 102:59 103:59 104:60 105:61 106:62 107:63 108:64 109:65 110:66 111:67 112:68 113:69 114:70 115:71 116:71 117:71 118:71 119:72 120:72 121:73 122:74 123:75 124:76 125:77 126:78 127:79 128:80 129:80 130:80 131:80 132:80 133:81 134:82 135:83 136:84 137:84 138:84 139:85 140:86 141:87 142:88 143:89 144:90 145:91 146:92 147:93 148:93 149:94 150:95 151:96 152:97 153:98 154:99 155:100 156:101 157:102 158:103 159:103 160:104 161:105 162:106 163:107 164:108 165:109 166:110 167:111 168:112 169:112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.508413 140073664845568 tf_logging.py:115] token_to_orig_map: 14:0 15:1 16:1 17:2 18:2 19:2 20:3 21:3 22:3 23:3 24:3 25:4 26:4 27:5 28:5 29:5 30:6 31:6 32:7 33:7 34:7 35:8 36:9 37:10 38:11 39:12 40:13 41:14 42:15 43:16 44:17 45:18 46:19 47:20 48:21 49:22 50:22 51:23 52:24 53:25 54:26 55:26 56:27 57:28 58:29 59:30 60:31 61:32 62:32 63:32 64:32 65:33 66:34 67:35 68:35 69:35 70:35 71:35 72:36 73:37 74:38 75:39 76:40 77:40 78:41 79:42 80:43 81:44 82:44 83:45 84:46 85:47 86:48 87:48 88:48 89:49 90:50 91:51 92:52 93:52 94:52 95:53 96:54 97:55 98:56 99:57 100:58 101:59 102:59 103:59 104:60 105:61 106:62 107:63 108:64 109:65 110:66 111:67 112:68 113:69 114:70 115:71 116:71 117:71 118:71 119:72 120:72 121:73 122:74 123:75 124:76 125:77 126:78 127:79 128:80 129:80 130:80 131:80 132:80 133:81 134:82 135:83 136:84 137:84 138:84 139:85 140:86 141:87 142:88 143:89 144:90 145:91 146:92 147:93 148:93 149:94 150:95 151:96 152:97 153:98 154:99 155:100 156:101 157:102 158:103 159:103 160:104 161:105 162:106 163:107 164:108 165:109 166:110 167:111 168:112 169:112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.509174 140073664845568 tf_logging.py:115] token_is_max_context: 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2054 2301 2106 1996 5879 2015 2034 5114 2037 3584 4767 1029 102 1996 5879 2015 1006 5879 1024 2053 3126 2386 5104 1025 2413 1024 5879 5104 1025 3763 1024 5879 3490 1007 2020 1996 2111 2040 1999 1996 6049 1998 6252 4693 2435 2037 2171 2000 13298 1010 1037 2555 1999 2605 1012 2027 2020 9287 2013 15342 1006 1000 5879 1000 3310 2013 1000 15342 2386 1000 1007 10642 1998 8350 2013 5842 1010 10399 1998 5120 2040 1010 2104 2037 3003 4897 2080 1010 3530 2000 8415 10768 2389 3723 2000 2332 2798 3523 1997 2225 23151 7405 1012 2083 8213 1997 27574 1998 6809 2007 1996 3128 26165 1998 3142 1011 26522 4509 7080 1010 2037 8481 2052 6360 13590 2007 1996 8594 2075 2937 1011 2241 8578 1997 2225 23151 7405 1012 1996 5664 3451 1998 5636 4767 1997 1996 5879 2015 6003 3322 1999 1996 2034 2431 1997 1996 6049 2301 1010 1998 2009 2506 2000 19852 2058 1996 13034 4693 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.510007 140073664845568 tf_logging.py:115] input_ids: 101 2054 2301 2106 1996 5879 2015 2034 5114 2037 3584 4767 1029 102 1996 5879 2015 1006 5879 1024 2053 3126 2386 5104 1025 2413 1024 5879 5104 1025 3763 1024 5879 3490 1007 2020 1996 2111 2040 1999 1996 6049 1998 6252 4693 2435 2037 2171 2000 13298 1010 1037 2555 1999 2605 1012 2027 2020 9287 2013 15342 1006 1000 5879 1000 3310 2013 1000 15342 2386 1000 1007 10642 1998 8350 2013 5842 1010 10399 1998 5120 2040 1010 2104 2037 3003 4897 2080 1010 3530 2000 8415 10768 2389 3723 2000 2332 2798 3523 1997 2225 23151 7405 1012 2083 8213 1997 27574 1998 6809 2007 1996 3128 26165 1998 3142 1011 26522 4509 7080 1010 2037 8481 2052 6360 13590 2007 1996 8594 2075 2937 1011 2241 8578 1997 2225 23151 7405 1012 1996 5664 3451 1998 5636 4767 1997 1996 5879 2015 6003 3322 1999 1996 2034 2431 1997 1996 6049 2301 1010 1998 2009 2506 2000 19852 2058 1996 13034 4693 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.510799 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.511605 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.515619 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.516427 140073664845568 tf_logging.py:115] unique_id: 1000000005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.517147 140073664845568 tf_logging.py:115] example_index: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.517906 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] who gave their name to normandy in the 1000 ' s and 1100 ' s [SEP] the norman ##s ( norman : no ##ur ##man ##ds ; french : norman ##ds ; latin : norman ##ni ) were the people who in the 10th and 11th centuries gave their name to normandy , a region in france . they were descended from norse ( \" norman \" comes from \" norse ##man \" ) raiders and pirates from denmark , iceland and norway who , under their leader roll ##o , agreed to swear fe ##al ##ty to king charles iii of west fran ##cia . through generations of assimilation and mixing with the native frankish and roman - gaul ##ish populations , their descendants would gradually merge with the carol ##ing ##ian - based cultures of west fran ##cia . the distinct cultural and ethnic identity of the norman ##s emerged initially in the first half of the 10th century , and it continued to evolve over the succeeding centuries . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.518675 140073664845568 tf_logging.py:115] tokens: [CLS] who gave their name to normandy in the 1000 ' s and 1100 ' s [SEP] the norman ##s ( norman : no ##ur ##man ##ds ; french : norman ##ds ; latin : norman ##ni ) were the people who in the 10th and 11th centuries gave their name to normandy , a region in france . they were descended from norse ( \" norman \" comes from \" norse ##man \" ) raiders and pirates from denmark , iceland and norway who , under their leader roll ##o , agreed to swear fe ##al ##ty to king charles iii of west fran ##cia . through generations of assimilation and mixing with the native frankish and roman - gaul ##ish populations , their descendants would gradually merge with the carol ##ing ##ian - based cultures of west fran ##cia . the distinct cultural and ethnic identity of the norman ##s emerged initially in the first half of the 10th century , and it continued to evolve over the succeeding centuries . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 17:0 18:1 19:1 20:2 21:2 22:2 23:3 24:3 25:3 26:3 27:3 28:4 29:4 30:5 31:5 32:5 33:6 34:6 35:7 36:7 37:7 38:8 39:9 40:10 41:11 42:12 43:13 44:14 45:15 46:16 47:17 48:18 49:19 50:20 51:21 52:22 53:22 54:23 55:24 56:25 57:26 58:26 59:27 60:28 61:29 62:30 63:31 64:32 65:32 66:32 67:32 68:33 69:34 70:35 71:35 72:35 73:35 74:35 75:36 76:37 77:38 78:39 79:40 80:40 81:41 82:42 83:43 84:44 85:44 86:45 87:46 88:47 89:48 90:48 91:48 92:49 93:50 94:51 95:52 96:52 97:52 98:53 99:54 100:55 101:56 102:57 103:58 104:59 105:59 106:59 107:60 108:61 109:62 110:63 111:64 112:65 113:66 114:67 115:68 116:69 117:70 118:71 119:71 120:71 121:71 122:72 123:72 124:73 125:74 126:75 127:76 128:77 129:78 130:79 131:80 132:80 133:80 134:80 135:80 136:81 137:82 138:83 139:84 140:84 141:84 142:85 143:86 144:87 145:88 146:89 147:90 148:91 149:92 150:93 151:93 152:94 153:95 154:96 155:97 156:98 157:99 158:100 159:101 160:102 161:103 162:103 163:104 164:105 165:106 166:107 167:108 168:109 169:110 170:111 171:112 172:112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.519444 140073664845568 tf_logging.py:115] token_to_orig_map: 17:0 18:1 19:1 20:2 21:2 22:2 23:3 24:3 25:3 26:3 27:3 28:4 29:4 30:5 31:5 32:5 33:6 34:6 35:7 36:7 37:7 38:8 39:9 40:10 41:11 42:12 43:13 44:14 45:15 46:16 47:17 48:18 49:19 50:20 51:21 52:22 53:22 54:23 55:24 56:25 57:26 58:26 59:27 60:28 61:29 62:30 63:31 64:32 65:32 66:32 67:32 68:33 69:34 70:35 71:35 72:35 73:35 74:35 75:36 76:37 77:38 78:39 79:40 80:40 81:41 82:42 83:43 84:44 85:44 86:45 87:46 88:47 89:48 90:48 91:48 92:49 93:50 94:51 95:52 96:52 97:52 98:53 99:54 100:55 101:56 102:57 103:58 104:59 105:59 106:59 107:60 108:61 109:62 110:63 111:64 112:65 113:66 114:67 115:68 116:69 117:70 118:71 119:71 120:71 121:71 122:72 123:72 124:73 125:74 126:75 127:76 128:77 129:78 130:79 131:80 132:80 133:80 134:80 135:80 136:81 137:82 138:83 139:84 140:84 141:84 142:85 143:86 144:87 145:88 146:89 147:90 148:91 149:92 150:93 151:93 152:94 153:95 154:96 155:97 156:98 157:99 158:100 159:101 160:102 161:103 162:103 163:104 164:105 165:106 166:107 167:108 168:109 169:110 170:111 171:112 172:112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.520207 140073664845568 tf_logging.py:115] token_is_max_context: 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2040 2435 2037 2171 2000 13298 1999 1996 6694 1005 1055 1998 22096 1005 1055 102 1996 5879 2015 1006 5879 1024 2053 3126 2386 5104 1025 2413 1024 5879 5104 1025 3763 1024 5879 3490 1007 2020 1996 2111 2040 1999 1996 6049 1998 6252 4693 2435 2037 2171 2000 13298 1010 1037 2555 1999 2605 1012 2027 2020 9287 2013 15342 1006 1000 5879 1000 3310 2013 1000 15342 2386 1000 1007 10642 1998 8350 2013 5842 1010 10399 1998 5120 2040 1010 2104 2037 3003 4897 2080 1010 3530 2000 8415 10768 2389 3723 2000 2332 2798 3523 1997 2225 23151 7405 1012 2083 8213 1997 27574 1998 6809 2007 1996 3128 26165 1998 3142 1011 26522 4509 7080 1010 2037 8481 2052 6360 13590 2007 1996 8594 2075 2937 1011 2241 8578 1997 2225 23151 7405 1012 1996 5664 3451 1998 5636 4767 1997 1996 5879 2015 6003 3322 1999 1996 2034 2431 1997 1996 6049 2301 1010 1998 2009 2506 2000 19852 2058 1996 13034 4693 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.521020 140073664845568 tf_logging.py:115] input_ids: 101 2040 2435 2037 2171 2000 13298 1999 1996 6694 1005 1055 1998 22096 1005 1055 102 1996 5879 2015 1006 5879 1024 2053 3126 2386 5104 1025 2413 1024 5879 5104 1025 3763 1024 5879 3490 1007 2020 1996 2111 2040 1999 1996 6049 1998 6252 4693 2435 2037 2171 2000 13298 1010 1037 2555 1999 2605 1012 2027 2020 9287 2013 15342 1006 1000 5879 1000 3310 2013 1000 15342 2386 1000 1007 10642 1998 8350 2013 5842 1010 10399 1998 5120 2040 1010 2104 2037 3003 4897 2080 1010 3530 2000 8415 10768 2389 3723 2000 2332 2798 3523 1997 2225 23151 7405 1012 2083 8213 1997 27574 1998 6809 2007 1996 3128 26165 1998 3142 1011 26522 4509 7080 1010 2037 8481 2052 6360 13590 2007 1996 8594 2075 2937 1011 2241 8578 1997 2225 23151 7405 1012 1996 5664 3451 1998 5636 4767 1997 1996 5879 2015 6003 3322 1999 1996 2034 2431 1997 1996 6049 2301 1010 1998 2009 2506 2000 19852 2058 1996 13034 4693 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.521856 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.522641 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.526504 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.527278 140073664845568 tf_logging.py:115] unique_id: 1000000006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.527996 140073664845568 tf_logging.py:115] example_index: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.528702 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] what is france a region of ? [SEP] the norman ##s ( norman : no ##ur ##man ##ds ; french : norman ##ds ; latin : norman ##ni ) were the people who in the 10th and 11th centuries gave their name to normandy , a region in france . they were descended from norse ( \" norman \" comes from \" norse ##man \" ) raiders and pirates from denmark , iceland and norway who , under their leader roll ##o , agreed to swear fe ##al ##ty to king charles iii of west fran ##cia . through generations of assimilation and mixing with the native frankish and roman - gaul ##ish populations , their descendants would gradually merge with the carol ##ing ##ian - based cultures of west fran ##cia . the distinct cultural and ethnic identity of the norman ##s emerged initially in the first half of the 10th century , and it continued to evolve over the succeeding centuries . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.529459 140073664845568 tf_logging.py:115] tokens: [CLS] what is france a region of ? [SEP] the norman ##s ( norman : no ##ur ##man ##ds ; french : norman ##ds ; latin : norman ##ni ) were the people who in the 10th and 11th centuries gave their name to normandy , a region in france . they were descended from norse ( \" norman \" comes from \" norse ##man \" ) raiders and pirates from denmark , iceland and norway who , under their leader roll ##o , agreed to swear fe ##al ##ty to king charles iii of west fran ##cia . through generations of assimilation and mixing with the native frankish and roman - gaul ##ish populations , their descendants would gradually merge with the carol ##ing ##ian - based cultures of west fran ##cia . the distinct cultural and ethnic identity of the norman ##s emerged initially in the first half of the 10th century , and it continued to evolve over the succeeding centuries . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 9:0 10:1 11:1 12:2 13:2 14:2 15:3 16:3 17:3 18:3 19:3 20:4 21:4 22:5 23:5 24:5 25:6 26:6 27:7 28:7 29:7 30:8 31:9 32:10 33:11 34:12 35:13 36:14 37:15 38:16 39:17 40:18 41:19 42:20 43:21 44:22 45:22 46:23 47:24 48:25 49:26 50:26 51:27 52:28 53:29 54:30 55:31 56:32 57:32 58:32 59:32 60:33 61:34 62:35 63:35 64:35 65:35 66:35 67:36 68:37 69:38 70:39 71:40 72:40 73:41 74:42 75:43 76:44 77:44 78:45 79:46 80:47 81:48 82:48 83:48 84:49 85:50 86:51 87:52 88:52 89:52 90:53 91:54 92:55 93:56 94:57 95:58 96:59 97:59 98:59 99:60 100:61 101:62 102:63 103:64 104:65 105:66 106:67 107:68 108:69 109:70 110:71 111:71 112:71 113:71 114:72 115:72 116:73 117:74 118:75 119:76 120:77 121:78 122:79 123:80 124:80 125:80 126:80 127:80 128:81 129:82 130:83 131:84 132:84 133:84 134:85 135:86 136:87 137:88 138:89 139:90 140:91 141:92 142:93 143:93 144:94 145:95 146:96 147:97 148:98 149:99 150:100 151:101 152:102 153:103 154:103 155:104 156:105 157:106 158:107 159:108 160:109 161:110 162:111 163:112 164:112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.530254 140073664845568 tf_logging.py:115] token_to_orig_map: 9:0 10:1 11:1 12:2 13:2 14:2 15:3 16:3 17:3 18:3 19:3 20:4 21:4 22:5 23:5 24:5 25:6 26:6 27:7 28:7 29:7 30:8 31:9 32:10 33:11 34:12 35:13 36:14 37:15 38:16 39:17 40:18 41:19 42:20 43:21 44:22 45:22 46:23 47:24 48:25 49:26 50:26 51:27 52:28 53:29 54:30 55:31 56:32 57:32 58:32 59:32 60:33 61:34 62:35 63:35 64:35 65:35 66:35 67:36 68:37 69:38 70:39 71:40 72:40 73:41 74:42 75:43 76:44 77:44 78:45 79:46 80:47 81:48 82:48 83:48 84:49 85:50 86:51 87:52 88:52 89:52 90:53 91:54 92:55 93:56 94:57 95:58 96:59 97:59 98:59 99:60 100:61 101:62 102:63 103:64 104:65 105:66 106:67 107:68 108:69 109:70 110:71 111:71 112:71 113:71 114:72 115:72 116:73 117:74 118:75 119:76 120:77 121:78 122:79 123:80 124:80 125:80 126:80 127:80 128:81 129:82 130:83 131:84 132:84 133:84 134:85 135:86 136:87 137:88 138:89 139:90 140:91 141:92 142:93 143:93 144:94 145:95 146:96 147:97 148:98 149:99 150:100 151:101 152:102 153:103 154:103 155:104 156:105 157:106 158:107 159:108 160:109 161:110 162:111 163:112 164:112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.531042 140073664845568 tf_logging.py:115] token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2054 2003 2605 1037 2555 1997 1029 102 1996 5879 2015 1006 5879 1024 2053 3126 2386 5104 1025 2413 1024 5879 5104 1025 3763 1024 5879 3490 1007 2020 1996 2111 2040 1999 1996 6049 1998 6252 4693 2435 2037 2171 2000 13298 1010 1037 2555 1999 2605 1012 2027 2020 9287 2013 15342 1006 1000 5879 1000 3310 2013 1000 15342 2386 1000 1007 10642 1998 8350 2013 5842 1010 10399 1998 5120 2040 1010 2104 2037 3003 4897 2080 1010 3530 2000 8415 10768 2389 3723 2000 2332 2798 3523 1997 2225 23151 7405 1012 2083 8213 1997 27574 1998 6809 2007 1996 3128 26165 1998 3142 1011 26522 4509 7080 1010 2037 8481 2052 6360 13590 2007 1996 8594 2075 2937 1011 2241 8578 1997 2225 23151 7405 1012 1996 5664 3451 1998 5636 4767 1997 1996 5879 2015 6003 3322 1999 1996 2034 2431 1997 1996 6049 2301 1010 1998 2009 2506 2000 19852 2058 1996 13034 4693 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.531862 140073664845568 tf_logging.py:115] input_ids: 101 2054 2003 2605 1037 2555 1997 1029 102 1996 5879 2015 1006 5879 1024 2053 3126 2386 5104 1025 2413 1024 5879 5104 1025 3763 1024 5879 3490 1007 2020 1996 2111 2040 1999 1996 6049 1998 6252 4693 2435 2037 2171 2000 13298 1010 1037 2555 1999 2605 1012 2027 2020 9287 2013 15342 1006 1000 5879 1000 3310 2013 1000 15342 2386 1000 1007 10642 1998 8350 2013 5842 1010 10399 1998 5120 2040 1010 2104 2037 3003 4897 2080 1010 3530 2000 8415 10768 2389 3723 2000 2332 2798 3523 1997 2225 23151 7405 1012 2083 8213 1997 27574 1998 6809 2007 1996 3128 26165 1998 3142 1011 26522 4509 7080 1010 2037 8481 2052 6360 13590 2007 1996 8594 2075 2937 1011 2241 8578 1997 2225 23151 7405 1012 1996 5664 3451 1998 5636 4767 1997 1996 5879 2015 6003 3322 1999 1996 2034 2431 1997 1996 6049 2301 1010 1998 2009 2506 2000 19852 2058 1996 13034 4693 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.532706 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.533505 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.537502 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.538294 140073664845568 tf_logging.py:115] unique_id: 1000000007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.539021 140073664845568 tf_logging.py:115] example_index: 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.539753 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] who did king charles iii swear fe ##al ##ty to ? [SEP] the norman ##s ( norman : no ##ur ##man ##ds ; french : norman ##ds ; latin : norman ##ni ) were the people who in the 10th and 11th centuries gave their name to normandy , a region in france . they were descended from norse ( \" norman \" comes from \" norse ##man \" ) raiders and pirates from denmark , iceland and norway who , under their leader roll ##o , agreed to swear fe ##al ##ty to king charles iii of west fran ##cia . through generations of assimilation and mixing with the native frankish and roman - gaul ##ish populations , their descendants would gradually merge with the carol ##ing ##ian - based cultures of west fran ##cia . the distinct cultural and ethnic identity of the norman ##s emerged initially in the first half of the 10th century , and it continued to evolve over the succeeding centuries . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.540510 140073664845568 tf_logging.py:115] tokens: [CLS] who did king charles iii swear fe ##al ##ty to ? [SEP] the norman ##s ( norman : no ##ur ##man ##ds ; french : norman ##ds ; latin : norman ##ni ) were the people who in the 10th and 11th centuries gave their name to normandy , a region in france . they were descended from norse ( \" norman \" comes from \" norse ##man \" ) raiders and pirates from denmark , iceland and norway who , under their leader roll ##o , agreed to swear fe ##al ##ty to king charles iii of west fran ##cia . through generations of assimilation and mixing with the native frankish and roman - gaul ##ish populations , their descendants would gradually merge with the carol ##ing ##ian - based cultures of west fran ##cia . the distinct cultural and ethnic identity of the norman ##s emerged initially in the first half of the 10th century , and it continued to evolve over the succeeding centuries . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 13:0 14:1 15:1 16:2 17:2 18:2 19:3 20:3 21:3 22:3 23:3 24:4 25:4 26:5 27:5 28:5 29:6 30:6 31:7 32:7 33:7 34:8 35:9 36:10 37:11 38:12 39:13 40:14 41:15 42:16 43:17 44:18 45:19 46:20 47:21 48:22 49:22 50:23 51:24 52:25 53:26 54:26 55:27 56:28 57:29 58:30 59:31 60:32 61:32 62:32 63:32 64:33 65:34 66:35 67:35 68:35 69:35 70:35 71:36 72:37 73:38 74:39 75:40 76:40 77:41 78:42 79:43 80:44 81:44 82:45 83:46 84:47 85:48 86:48 87:48 88:49 89:50 90:51 91:52 92:52 93:52 94:53 95:54 96:55 97:56 98:57 99:58 100:59 101:59 102:59 103:60 104:61 105:62 106:63 107:64 108:65 109:66 110:67 111:68 112:69 113:70 114:71 115:71 116:71 117:71 118:72 119:72 120:73 121:74 122:75 123:76 124:77 125:78 126:79 127:80 128:80 129:80 130:80 131:80 132:81 133:82 134:83 135:84 136:84 137:84 138:85 139:86 140:87 141:88 142:89 143:90 144:91 145:92 146:93 147:93 148:94 149:95 150:96 151:97 152:98 153:99 154:100 155:101 156:102 157:103 158:103 159:104 160:105 161:106 162:107 163:108 164:109 165:110 166:111 167:112 168:112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.541376 140073664845568 tf_logging.py:115] token_to_orig_map: 13:0 14:1 15:1 16:2 17:2 18:2 19:3 20:3 21:3 22:3 23:3 24:4 25:4 26:5 27:5 28:5 29:6 30:6 31:7 32:7 33:7 34:8 35:9 36:10 37:11 38:12 39:13 40:14 41:15 42:16 43:17 44:18 45:19 46:20 47:21 48:22 49:22 50:23 51:24 52:25 53:26 54:26 55:27 56:28 57:29 58:30 59:31 60:32 61:32 62:32 63:32 64:33 65:34 66:35 67:35 68:35 69:35 70:35 71:36 72:37 73:38 74:39 75:40 76:40 77:41 78:42 79:43 80:44 81:44 82:45 83:46 84:47 85:48 86:48 87:48 88:49 89:50 90:51 91:52 92:52 93:52 94:53 95:54 96:55 97:56 98:57 99:58 100:59 101:59 102:59 103:60 104:61 105:62 106:63 107:64 108:65 109:66 110:67 111:68 112:69 113:70 114:71 115:71 116:71 117:71 118:72 119:72 120:73 121:74 122:75 123:76 124:77 125:78 126:79 127:80 128:80 129:80 130:80 131:80 132:81 133:82 134:83 135:84 136:84 137:84 138:85 139:86 140:87 141:88 142:89 143:90 144:91 145:92 146:93 147:93 148:94 149:95 150:96 151:97 152:98 153:99 154:100 155:101 156:102 157:103 158:103 159:104 160:105 161:106 162:107 163:108 164:109 165:110 166:111 167:112 168:112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.542161 140073664845568 tf_logging.py:115] token_is_max_context: 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2040 2106 2332 2798 3523 8415 10768 2389 3723 2000 1029 102 1996 5879 2015 1006 5879 1024 2053 3126 2386 5104 1025 2413 1024 5879 5104 1025 3763 1024 5879 3490 1007 2020 1996 2111 2040 1999 1996 6049 1998 6252 4693 2435 2037 2171 2000 13298 1010 1037 2555 1999 2605 1012 2027 2020 9287 2013 15342 1006 1000 5879 1000 3310 2013 1000 15342 2386 1000 1007 10642 1998 8350 2013 5842 1010 10399 1998 5120 2040 1010 2104 2037 3003 4897 2080 1010 3530 2000 8415 10768 2389 3723 2000 2332 2798 3523 1997 2225 23151 7405 1012 2083 8213 1997 27574 1998 6809 2007 1996 3128 26165 1998 3142 1011 26522 4509 7080 1010 2037 8481 2052 6360 13590 2007 1996 8594 2075 2937 1011 2241 8578 1997 2225 23151 7405 1012 1996 5664 3451 1998 5636 4767 1997 1996 5879 2015 6003 3322 1999 1996 2034 2431 1997 1996 6049 2301 1010 1998 2009 2506 2000 19852 2058 1996 13034 4693 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.542976 140073664845568 tf_logging.py:115] input_ids: 101 2040 2106 2332 2798 3523 8415 10768 2389 3723 2000 1029 102 1996 5879 2015 1006 5879 1024 2053 3126 2386 5104 1025 2413 1024 5879 5104 1025 3763 1024 5879 3490 1007 2020 1996 2111 2040 1999 1996 6049 1998 6252 4693 2435 2037 2171 2000 13298 1010 1037 2555 1999 2605 1012 2027 2020 9287 2013 15342 1006 1000 5879 1000 3310 2013 1000 15342 2386 1000 1007 10642 1998 8350 2013 5842 1010 10399 1998 5120 2040 1010 2104 2037 3003 4897 2080 1010 3530 2000 8415 10768 2389 3723 2000 2332 2798 3523 1997 2225 23151 7405 1012 2083 8213 1997 27574 1998 6809 2007 1996 3128 26165 1998 3142 1011 26522 4509 7080 1010 2037 8481 2052 6360 13590 2007 1996 8594 2075 2937 1011 2241 8578 1997 2225 23151 7405 1012 1996 5664 3451 1998 5636 4767 1997 1996 5879 2015 6003 3322 1999 1996 2034 2431 1997 1996 6049 2301 1010 1998 2009 2506 2000 19852 2058 1996 13034 4693 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.543834 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.544615 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.548486 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.549274 140073664845568 tf_logging.py:115] unique_id: 1000000008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.550019 140073664845568 tf_logging.py:115] example_index: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.550741 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] when did the frankish identity emerge ? [SEP] the norman ##s ( norman : no ##ur ##man ##ds ; french : norman ##ds ; latin : norman ##ni ) were the people who in the 10th and 11th centuries gave their name to normandy , a region in france . they were descended from norse ( \" norman \" comes from \" norse ##man \" ) raiders and pirates from denmark , iceland and norway who , under their leader roll ##o , agreed to swear fe ##al ##ty to king charles iii of west fran ##cia . through generations of assimilation and mixing with the native frankish and roman - gaul ##ish populations , their descendants would gradually merge with the carol ##ing ##ian - based cultures of west fran ##cia . the distinct cultural and ethnic identity of the norman ##s emerged initially in the first half of the 10th century , and it continued to evolve over the succeeding centuries . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.551506 140073664845568 tf_logging.py:115] tokens: [CLS] when did the frankish identity emerge ? [SEP] the norman ##s ( norman : no ##ur ##man ##ds ; french : norman ##ds ; latin : norman ##ni ) were the people who in the 10th and 11th centuries gave their name to normandy , a region in france . they were descended from norse ( \" norman \" comes from \" norse ##man \" ) raiders and pirates from denmark , iceland and norway who , under their leader roll ##o , agreed to swear fe ##al ##ty to king charles iii of west fran ##cia . through generations of assimilation and mixing with the native frankish and roman - gaul ##ish populations , their descendants would gradually merge with the carol ##ing ##ian - based cultures of west fran ##cia . the distinct cultural and ethnic identity of the norman ##s emerged initially in the first half of the 10th century , and it continued to evolve over the succeeding centuries . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 9:0 10:1 11:1 12:2 13:2 14:2 15:3 16:3 17:3 18:3 19:3 20:4 21:4 22:5 23:5 24:5 25:6 26:6 27:7 28:7 29:7 30:8 31:9 32:10 33:11 34:12 35:13 36:14 37:15 38:16 39:17 40:18 41:19 42:20 43:21 44:22 45:22 46:23 47:24 48:25 49:26 50:26 51:27 52:28 53:29 54:30 55:31 56:32 57:32 58:32 59:32 60:33 61:34 62:35 63:35 64:35 65:35 66:35 67:36 68:37 69:38 70:39 71:40 72:40 73:41 74:42 75:43 76:44 77:44 78:45 79:46 80:47 81:48 82:48 83:48 84:49 85:50 86:51 87:52 88:52 89:52 90:53 91:54 92:55 93:56 94:57 95:58 96:59 97:59 98:59 99:60 100:61 101:62 102:63 103:64 104:65 105:66 106:67 107:68 108:69 109:70 110:71 111:71 112:71 113:71 114:72 115:72 116:73 117:74 118:75 119:76 120:77 121:78 122:79 123:80 124:80 125:80 126:80 127:80 128:81 129:82 130:83 131:84 132:84 133:84 134:85 135:86 136:87 137:88 138:89 139:90 140:91 141:92 142:93 143:93 144:94 145:95 146:96 147:97 148:98 149:99 150:100 151:101 152:102 153:103 154:103 155:104 156:105 157:106 158:107 159:108 160:109 161:110 162:111 163:112 164:112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.552276 140073664845568 tf_logging.py:115] token_to_orig_map: 9:0 10:1 11:1 12:2 13:2 14:2 15:3 16:3 17:3 18:3 19:3 20:4 21:4 22:5 23:5 24:5 25:6 26:6 27:7 28:7 29:7 30:8 31:9 32:10 33:11 34:12 35:13 36:14 37:15 38:16 39:17 40:18 41:19 42:20 43:21 44:22 45:22 46:23 47:24 48:25 49:26 50:26 51:27 52:28 53:29 54:30 55:31 56:32 57:32 58:32 59:32 60:33 61:34 62:35 63:35 64:35 65:35 66:35 67:36 68:37 69:38 70:39 71:40 72:40 73:41 74:42 75:43 76:44 77:44 78:45 79:46 80:47 81:48 82:48 83:48 84:49 85:50 86:51 87:52 88:52 89:52 90:53 91:54 92:55 93:56 94:57 95:58 96:59 97:59 98:59 99:60 100:61 101:62 102:63 103:64 104:65 105:66 106:67 107:68 108:69 109:70 110:71 111:71 112:71 113:71 114:72 115:72 116:73 117:74 118:75 119:76 120:77 121:78 122:79 123:80 124:80 125:80 126:80 127:80 128:81 129:82 130:83 131:84 132:84 133:84 134:85 135:86 136:87 137:88 138:89 139:90 140:91 141:92 142:93 143:93 144:94 145:95 146:96 147:97 148:98 149:99 150:100 151:101 152:102 153:103 154:103 155:104 156:105 157:106 158:107 159:108 160:109 161:110 162:111 163:112 164:112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.553063 140073664845568 tf_logging.py:115] token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2043 2106 1996 26165 4767 12636 1029 102 1996 5879 2015 1006 5879 1024 2053 3126 2386 5104 1025 2413 1024 5879 5104 1025 3763 1024 5879 3490 1007 2020 1996 2111 2040 1999 1996 6049 1998 6252 4693 2435 2037 2171 2000 13298 1010 1037 2555 1999 2605 1012 2027 2020 9287 2013 15342 1006 1000 5879 1000 3310 2013 1000 15342 2386 1000 1007 10642 1998 8350 2013 5842 1010 10399 1998 5120 2040 1010 2104 2037 3003 4897 2080 1010 3530 2000 8415 10768 2389 3723 2000 2332 2798 3523 1997 2225 23151 7405 1012 2083 8213 1997 27574 1998 6809 2007 1996 3128 26165 1998 3142 1011 26522 4509 7080 1010 2037 8481 2052 6360 13590 2007 1996 8594 2075 2937 1011 2241 8578 1997 2225 23151 7405 1012 1996 5664 3451 1998 5636 4767 1997 1996 5879 2015 6003 3322 1999 1996 2034 2431 1997 1996 6049 2301 1010 1998 2009 2506 2000 19852 2058 1996 13034 4693 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.553922 140073664845568 tf_logging.py:115] input_ids: 101 2043 2106 1996 26165 4767 12636 1029 102 1996 5879 2015 1006 5879 1024 2053 3126 2386 5104 1025 2413 1024 5879 5104 1025 3763 1024 5879 3490 1007 2020 1996 2111 2040 1999 1996 6049 1998 6252 4693 2435 2037 2171 2000 13298 1010 1037 2555 1999 2605 1012 2027 2020 9287 2013 15342 1006 1000 5879 1000 3310 2013 1000 15342 2386 1000 1007 10642 1998 8350 2013 5842 1010 10399 1998 5120 2040 1010 2104 2037 3003 4897 2080 1010 3530 2000 8415 10768 2389 3723 2000 2332 2798 3523 1997 2225 23151 7405 1012 2083 8213 1997 27574 1998 6809 2007 1996 3128 26165 1998 3142 1011 26522 4509 7080 1010 2037 8481 2052 6360 13590 2007 1996 8594 2075 2937 1011 2241 8578 1997 2225 23151 7405 1012 1996 5664 3451 1998 5636 4767 1997 1996 5879 2015 6003 3322 1999 1996 2034 2431 1997 1996 6049 2301 1010 1998 2009 2506 2000 19852 2058 1996 13034 4693 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.555213 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.556062 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.563304 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.564165 140073664845568 tf_logging.py:115] unique_id: 1000000009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.564924 140073664845568 tf_logging.py:115] example_index: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.565671 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] who was the duke in the battle of hastings ? [SEP] the norman dynasty had a major political , cultural and military impact on medieval europe and even the near east . the norman ##s were famed for their martial spirit and eventually for their christian pie ##ty , becoming expo ##nent ##s of the catholic orthodoxy into which they ass ##imi ##lated . they adopted the gallo - romance language of the frankish land they settled , their dialect becoming known as norman , norma ##und or norman french , an important literary language . the duchy of normandy , which they formed by treaty with the french crown , was a great fi ##ef of medieval france , and under richard i of normandy was forged into a co ##hesive and formidable principality in feudal tenure . the norman ##s are noted both for their culture , such as their unique romanesque architecture and musical traditions , and for their significant military accomplishments and innovations . norman adventurer ##s founded the kingdom of sicily under roger ii after conquer ##ing southern italy on the sara ##cens and byzantine ##s , and an expedition on behalf of their duke , william the conqueror , led to the norman conquest of england at the battle of hastings in 106 ##6 . norman cultural and military influence spread from these new european centres to the crusader states of the near east , where their prince bo ##hem ##ond i founded the principality of antioch in the levant , to scotland and wales in great britain , to ireland , and to the coasts of north africa and the canary islands . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.566577 140073664845568 tf_logging.py:115] tokens: [CLS] who was the duke in the battle of hastings ? [SEP] the norman dynasty had a major political , cultural and military impact on medieval europe and even the near east . the norman ##s were famed for their martial spirit and eventually for their christian pie ##ty , becoming expo ##nent ##s of the catholic orthodoxy into which they ass ##imi ##lated . they adopted the gallo - romance language of the frankish land they settled , their dialect becoming known as norman , norma ##und or norman french , an important literary language . the duchy of normandy , which they formed by treaty with the french crown , was a great fi ##ef of medieval france , and under richard i of normandy was forged into a co ##hesive and formidable principality in feudal tenure . the norman ##s are noted both for their culture , such as their unique romanesque architecture and musical traditions , and for their significant military accomplishments and innovations . norman adventurer ##s founded the kingdom of sicily under roger ii after conquer ##ing southern italy on the sara ##cens and byzantine ##s , and an expedition on behalf of their duke , william the conqueror , led to the norman conquest of england at the battle of hastings in 106 ##6 . norman cultural and military influence spread from these new european centres to the crusader states of the near east , where their prince bo ##hem ##ond i founded the principality of antioch in the levant , to scotland and wales in great britain , to ireland , and to the coasts of north africa and the canary islands . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 12:0 13:1 14:2 15:3 16:4 17:5 18:6 19:6 20:7 21:8 22:9 23:10 24:11 25:12 26:13 27:14 28:15 29:16 30:17 31:18 32:18 33:19 34:20 35:20 36:21 37:22 38:23 39:24 40:25 41:26 42:27 43:28 44:29 45:30 46:31 47:32 48:32 49:32 50:33 51:34 52:34 53:34 54:35 55:36 56:37 57:38 58:39 59:40 60:41 61:42 62:42 63:42 64:42 65:43 66:44 67:45 68:46 69:46 70:46 71:47 72:48 73:49 74:50 75:51 76:52 77:53 78:53 79:54 80:55 81:56 82:57 83:58 84:59 85:59 86:60 87:60 88:61 89:62 90:63 91:63 92:64 93:65 94:66 95:67 96:67 97:68 98:69 99:70 100:71 101:71 102:72 103:73 104:74 105:75 106:76 107:77 108:78 109:79 110:80 111:80 112:81 113:82 114:83 115:84 116:84 117:85 118:86 119:87 120:87 121:88 122:89 123:90 124:91 125:92 126:93 127:94 128:95 129:96 130:97 131:98 132:98 133:99 134:100 135:101 136:102 137:103 138:104 139:104 140:105 141:106 142:106 143:107 144:108 145:109 146:110 147:111 148:112 149:112 150:113 151:114 152:115 153:116 154:117 155:118 156:119 157:120 158:121 159:121 160:122 161:123 162:124 163:125 164:126 165:127 166:128 167:129 168:129 169:130 170:131 171:131 172:132 173:133 174:134 175:135 176:136 177:137 178:138 179:139 180:140 181:141 182:141 183:142 184:143 185:144 186:145 187:146 188:146 189:147 190:148 191:148 192:148 193:149 194:150 195:151 196:152 197:153 198:154 199:155 200:156 201:156 202:157 203:158 204:159 205:159 206:160 207:161 208:162 209:163 210:164 211:165 212:166 213:167 214:168 215:169 216:170 217:171 218:172 219:173 220:173 221:173 222:174 223:175 224:176 225:177 226:178 227:179 228:180 229:181 230:182 231:183 232:184 233:185 234:186 235:187 236:188 237:189 238:190 239:191 240:192 241:192 242:193 243:194 244:195 245:196 246:196 247:196 248:197 249:198 250:199 251:200 252:201 253:202 254:203 255:204 256:205 257:205 258:206 259:207 260:208 261:209 262:210 263:211 264:212 265:212 266:213 267:214 268:214 269:215 270:216 271:217 272:218 273:219 274:220 275:221 276:222 277:223 278:224 279:225 280:225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.567428 140073664845568 tf_logging.py:115] token_to_orig_map: 12:0 13:1 14:2 15:3 16:4 17:5 18:6 19:6 20:7 21:8 22:9 23:10 24:11 25:12 26:13 27:14 28:15 29:16 30:17 31:18 32:18 33:19 34:20 35:20 36:21 37:22 38:23 39:24 40:25 41:26 42:27 43:28 44:29 45:30 46:31 47:32 48:32 49:32 50:33 51:34 52:34 53:34 54:35 55:36 56:37 57:38 58:39 59:40 60:41 61:42 62:42 63:42 64:42 65:43 66:44 67:45 68:46 69:46 70:46 71:47 72:48 73:49 74:50 75:51 76:52 77:53 78:53 79:54 80:55 81:56 82:57 83:58 84:59 85:59 86:60 87:60 88:61 89:62 90:63 91:63 92:64 93:65 94:66 95:67 96:67 97:68 98:69 99:70 100:71 101:71 102:72 103:73 104:74 105:75 106:76 107:77 108:78 109:79 110:80 111:80 112:81 113:82 114:83 115:84 116:84 117:85 118:86 119:87 120:87 121:88 122:89 123:90 124:91 125:92 126:93 127:94 128:95 129:96 130:97 131:98 132:98 133:99 134:100 135:101 136:102 137:103 138:104 139:104 140:105 141:106 142:106 143:107 144:108 145:109 146:110 147:111 148:112 149:112 150:113 151:114 152:115 153:116 154:117 155:118 156:119 157:120 158:121 159:121 160:122 161:123 162:124 163:125 164:126 165:127 166:128 167:129 168:129 169:130 170:131 171:131 172:132 173:133 174:134 175:135 176:136 177:137 178:138 179:139 180:140 181:141 182:141 183:142 184:143 185:144 186:145 187:146 188:146 189:147 190:148 191:148 192:148 193:149 194:150 195:151 196:152 197:153 198:154 199:155 200:156 201:156 202:157 203:158 204:159 205:159 206:160 207:161 208:162 209:163 210:164 211:165 212:166 213:167 214:168 215:169 216:170 217:171 218:172 219:173 220:173 221:173 222:174 223:175 224:176 225:177 226:178 227:179 228:180 229:181 230:182 231:183 232:184 233:185 234:186 235:187 236:188 237:189 238:190 239:191 240:192 241:192 242:193 243:194 244:195 245:196 246:196 247:196 248:197 249:198 250:199 251:200 252:201 253:202 254:203 255:204 256:205 257:205 258:206 259:207 260:208 261:209 262:210 263:211 264:212 265:212 266:213 267:214 268:214 269:215 270:216 271:217 272:218 273:219 274:220 275:221 276:222 277:223 278:224 279:225 280:225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.568273 140073664845568 tf_logging.py:115] token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2040 2001 1996 3804 1999 1996 2645 1997 12296 1029 102 1996 5879 5321 2018 1037 2350 2576 1010 3451 1998 2510 4254 2006 5781 2885 1998 2130 1996 2379 2264 1012 1996 5879 2015 2020 15607 2005 2037 7761 4382 1998 2776 2005 2037 3017 11345 3723 1010 3352 16258 21576 2015 1997 1996 3234 26582 2046 2029 2027 4632 27605 13776 1012 2027 4233 1996 25624 1011 7472 2653 1997 1996 26165 2455 2027 3876 1010 2037 9329 3352 2124 2004 5879 1010 20692 8630 2030 5879 2413 1010 2019 2590 4706 2653 1012 1996 11068 1997 13298 1010 2029 2027 2719 2011 5036 2007 1996 2413 4410 1010 2001 1037 2307 10882 12879 1997 5781 2605 1010 1998 2104 2957 1045 1997 13298 2001 16158 2046 1037 2522 21579 1998 18085 18018 1999 16708 7470 1012 1996 5879 2015 2024 3264 2119 2005 2037 3226 1010 2107 2004 2037 4310 17135 4294 1998 3315 7443 1010 1998 2005 2037 3278 2510 17571 1998 15463 1012 5879 29506 2015 2631 1996 2983 1997 12071 2104 5074 2462 2044 16152 2075 2670 3304 2006 1996 7354 19023 1998 8734 2015 1010 1998 2019 5590 2006 6852 1997 2037 3804 1010 2520 1996 25466 1010 2419 2000 1996 5879 9187 1997 2563 2012 1996 2645 1997 12296 1999 10114 2575 1012 5879 3451 1998 2510 3747 3659 2013 2122 2047 2647 8941 2000 1996 25237 2163 1997 1996 2379 2264 1010 2073 2037 3159 8945 29122 15422 1045 2631 1996 18018 1997 19078 1999 1996 24485 1010 2000 3885 1998 3575 1999 2307 3725 1010 2000 3163 1010 1998 2000 1996 20266 1997 2167 3088 1998 1996 17154 3470 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.569167 140073664845568 tf_logging.py:115] input_ids: 101 2040 2001 1996 3804 1999 1996 2645 1997 12296 1029 102 1996 5879 5321 2018 1037 2350 2576 1010 3451 1998 2510 4254 2006 5781 2885 1998 2130 1996 2379 2264 1012 1996 5879 2015 2020 15607 2005 2037 7761 4382 1998 2776 2005 2037 3017 11345 3723 1010 3352 16258 21576 2015 1997 1996 3234 26582 2046 2029 2027 4632 27605 13776 1012 2027 4233 1996 25624 1011 7472 2653 1997 1996 26165 2455 2027 3876 1010 2037 9329 3352 2124 2004 5879 1010 20692 8630 2030 5879 2413 1010 2019 2590 4706 2653 1012 1996 11068 1997 13298 1010 2029 2027 2719 2011 5036 2007 1996 2413 4410 1010 2001 1037 2307 10882 12879 1997 5781 2605 1010 1998 2104 2957 1045 1997 13298 2001 16158 2046 1037 2522 21579 1998 18085 18018 1999 16708 7470 1012 1996 5879 2015 2024 3264 2119 2005 2037 3226 1010 2107 2004 2037 4310 17135 4294 1998 3315 7443 1010 1998 2005 2037 3278 2510 17571 1998 15463 1012 5879 29506 2015 2631 1996 2983 1997 12071 2104 5074 2462 2044 16152 2075 2670 3304 2006 1996 7354 19023 1998 8734 2015 1010 1998 2019 5590 2006 6852 1997 2037 3804 1010 2520 1996 25466 1010 2419 2000 1996 5879 9187 1997 2563 2012 1996 2645 1997 12296 1999 10114 2575 1012 5879 3451 1998 2510 3747 3659 2013 2122 2047 2647 8941 2000 1996 25237 2163 1997 1996 2379 2264 1010 2073 2037 3159 8945 29122 15422 1045 2631 1996 18018 1997 19078 1999 1996 24485 1010 2000 3885 1998 3575 1999 2307 3725 1010 2000 3163 1010 1998 2000 1996 20266 1997 2167 3088 1998 1996 17154 3470 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.570049 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.570890 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.578377 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.579349 140073664845568 tf_logging.py:115] unique_id: 1000000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.580105 140073664845568 tf_logging.py:115] example_index: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.580857 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] who ruled the duchy of normandy [SEP] the norman dynasty had a major political , cultural and military impact on medieval europe and even the near east . the norman ##s were famed for their martial spirit and eventually for their christian pie ##ty , becoming expo ##nent ##s of the catholic orthodoxy into which they ass ##imi ##lated . they adopted the gallo - romance language of the frankish land they settled , their dialect becoming known as norman , norma ##und or norman french , an important literary language . the duchy of normandy , which they formed by treaty with the french crown , was a great fi ##ef of medieval france , and under richard i of normandy was forged into a co ##hesive and formidable principality in feudal tenure . the norman ##s are noted both for their culture , such as their unique romanesque architecture and musical traditions , and for their significant military accomplishments and innovations . norman adventurer ##s founded the kingdom of sicily under roger ii after conquer ##ing southern italy on the sara ##cens and byzantine ##s , and an expedition on behalf of their duke , william the conqueror , led to the norman conquest of england at the battle of hastings in 106 ##6 . norman cultural and military influence spread from these new european centres to the crusader states of the near east , where their prince bo ##hem ##ond i founded the principality of antioch in the levant , to scotland and wales in great britain , to ireland , and to the coasts of north africa and the canary islands . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.581679 140073664845568 tf_logging.py:115] tokens: [CLS] who ruled the duchy of normandy [SEP] the norman dynasty had a major political , cultural and military impact on medieval europe and even the near east . the norman ##s were famed for their martial spirit and eventually for their christian pie ##ty , becoming expo ##nent ##s of the catholic orthodoxy into which they ass ##imi ##lated . they adopted the gallo - romance language of the frankish land they settled , their dialect becoming known as norman , norma ##und or norman french , an important literary language . the duchy of normandy , which they formed by treaty with the french crown , was a great fi ##ef of medieval france , and under richard i of normandy was forged into a co ##hesive and formidable principality in feudal tenure . the norman ##s are noted both for their culture , such as their unique romanesque architecture and musical traditions , and for their significant military accomplishments and innovations . norman adventurer ##s founded the kingdom of sicily under roger ii after conquer ##ing southern italy on the sara ##cens and byzantine ##s , and an expedition on behalf of their duke , william the conqueror , led to the norman conquest of england at the battle of hastings in 106 ##6 . norman cultural and military influence spread from these new european centres to the crusader states of the near east , where their prince bo ##hem ##ond i founded the principality of antioch in the levant , to scotland and wales in great britain , to ireland , and to the coasts of north africa and the canary islands . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 8:0 9:1 10:2 11:3 12:4 13:5 14:6 15:6 16:7 17:8 18:9 19:10 20:11 21:12 22:13 23:14 24:15 25:16 26:17 27:18 28:18 29:19 30:20 31:20 32:21 33:22 34:23 35:24 36:25 37:26 38:27 39:28 40:29 41:30 42:31 43:32 44:32 45:32 46:33 47:34 48:34 49:34 50:35 51:36 52:37 53:38 54:39 55:40 56:41 57:42 58:42 59:42 60:42 61:43 62:44 63:45 64:46 65:46 66:46 67:47 68:48 69:49 70:50 71:51 72:52 73:53 74:53 75:54 76:55 77:56 78:57 79:58 80:59 81:59 82:60 83:60 84:61 85:62 86:63 87:63 88:64 89:65 90:66 91:67 92:67 93:68 94:69 95:70 96:71 97:71 98:72 99:73 100:74 101:75 102:76 103:77 104:78 105:79 106:80 107:80 108:81 109:82 110:83 111:84 112:84 113:85 114:86 115:87 116:87 117:88 118:89 119:90 120:91 121:92 122:93 123:94 124:95 125:96 126:97 127:98 128:98 129:99 130:100 131:101 132:102 133:103 134:104 135:104 136:105 137:106 138:106 139:107 140:108 141:109 142:110 143:111 144:112 145:112 146:113 147:114 148:115 149:116 150:117 151:118 152:119 153:120 154:121 155:121 156:122 157:123 158:124 159:125 160:126 161:127 162:128 163:129 164:129 165:130 166:131 167:131 168:132 169:133 170:134 171:135 172:136 173:137 174:138 175:139 176:140 177:141 178:141 179:142 180:143 181:144 182:145 183:146 184:146 185:147 186:148 187:148 188:148 189:149 190:150 191:151 192:152 193:153 194:154 195:155 196:156 197:156 198:157 199:158 200:159 201:159 202:160 203:161 204:162 205:163 206:164 207:165 208:166 209:167 210:168 211:169 212:170 213:171 214:172 215:173 216:173 217:173 218:174 219:175 220:176 221:177 222:178 223:179 224:180 225:181 226:182 227:183 228:184 229:185 230:186 231:187 232:188 233:189 234:190 235:191 236:192 237:192 238:193 239:194 240:195 241:196 242:196 243:196 244:197 245:198 246:199 247:200 248:201 249:202 250:203 251:204 252:205 253:205 254:206 255:207 256:208 257:209 258:210 259:211 260:212 261:212 262:213 263:214 264:214 265:215 266:216 267:217 268:218 269:219 270:220 271:221 272:222 273:223 274:224 275:225 276:225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.582618 140073664845568 tf_logging.py:115] token_to_orig_map: 8:0 9:1 10:2 11:3 12:4 13:5 14:6 15:6 16:7 17:8 18:9 19:10 20:11 21:12 22:13 23:14 24:15 25:16 26:17 27:18 28:18 29:19 30:20 31:20 32:21 33:22 34:23 35:24 36:25 37:26 38:27 39:28 40:29 41:30 42:31 43:32 44:32 45:32 46:33 47:34 48:34 49:34 50:35 51:36 52:37 53:38 54:39 55:40 56:41 57:42 58:42 59:42 60:42 61:43 62:44 63:45 64:46 65:46 66:46 67:47 68:48 69:49 70:50 71:51 72:52 73:53 74:53 75:54 76:55 77:56 78:57 79:58 80:59 81:59 82:60 83:60 84:61 85:62 86:63 87:63 88:64 89:65 90:66 91:67 92:67 93:68 94:69 95:70 96:71 97:71 98:72 99:73 100:74 101:75 102:76 103:77 104:78 105:79 106:80 107:80 108:81 109:82 110:83 111:84 112:84 113:85 114:86 115:87 116:87 117:88 118:89 119:90 120:91 121:92 122:93 123:94 124:95 125:96 126:97 127:98 128:98 129:99 130:100 131:101 132:102 133:103 134:104 135:104 136:105 137:106 138:106 139:107 140:108 141:109 142:110 143:111 144:112 145:112 146:113 147:114 148:115 149:116 150:117 151:118 152:119 153:120 154:121 155:121 156:122 157:123 158:124 159:125 160:126 161:127 162:128 163:129 164:129 165:130 166:131 167:131 168:132 169:133 170:134 171:135 172:136 173:137 174:138 175:139 176:140 177:141 178:141 179:142 180:143 181:144 182:145 183:146 184:146 185:147 186:148 187:148 188:148 189:149 190:150 191:151 192:152 193:153 194:154 195:155 196:156 197:156 198:157 199:158 200:159 201:159 202:160 203:161 204:162 205:163 206:164 207:165 208:166 209:167 210:168 211:169 212:170 213:171 214:172 215:173 216:173 217:173 218:174 219:175 220:176 221:177 222:178 223:179 224:180 225:181 226:182 227:183 228:184 229:185 230:186 231:187 232:188 233:189 234:190 235:191 236:192 237:192 238:193 239:194 240:195 241:196 242:196 243:196 244:197 245:198 246:199 247:200 248:201 249:202 250:203 251:204 252:205 253:205 254:206 255:207 256:208 257:209 258:210 259:211 260:212 261:212 262:213 263:214 264:214 265:215 266:216 267:217 268:218 269:219 270:220 271:221 272:222 273:223 274:224 275:225 276:225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.583466 140073664845568 tf_logging.py:115] token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2040 5451 1996 11068 1997 13298 102 1996 5879 5321 2018 1037 2350 2576 1010 3451 1998 2510 4254 2006 5781 2885 1998 2130 1996 2379 2264 1012 1996 5879 2015 2020 15607 2005 2037 7761 4382 1998 2776 2005 2037 3017 11345 3723 1010 3352 16258 21576 2015 1997 1996 3234 26582 2046 2029 2027 4632 27605 13776 1012 2027 4233 1996 25624 1011 7472 2653 1997 1996 26165 2455 2027 3876 1010 2037 9329 3352 2124 2004 5879 1010 20692 8630 2030 5879 2413 1010 2019 2590 4706 2653 1012 1996 11068 1997 13298 1010 2029 2027 2719 2011 5036 2007 1996 2413 4410 1010 2001 1037 2307 10882 12879 1997 5781 2605 1010 1998 2104 2957 1045 1997 13298 2001 16158 2046 1037 2522 21579 1998 18085 18018 1999 16708 7470 1012 1996 5879 2015 2024 3264 2119 2005 2037 3226 1010 2107 2004 2037 4310 17135 4294 1998 3315 7443 1010 1998 2005 2037 3278 2510 17571 1998 15463 1012 5879 29506 2015 2631 1996 2983 1997 12071 2104 5074 2462 2044 16152 2075 2670 3304 2006 1996 7354 19023 1998 8734 2015 1010 1998 2019 5590 2006 6852 1997 2037 3804 1010 2520 1996 25466 1010 2419 2000 1996 5879 9187 1997 2563 2012 1996 2645 1997 12296 1999 10114 2575 1012 5879 3451 1998 2510 3747 3659 2013 2122 2047 2647 8941 2000 1996 25237 2163 1997 1996 2379 2264 1010 2073 2037 3159 8945 29122 15422 1045 2631 1996 18018 1997 19078 1999 1996 24485 1010 2000 3885 1998 3575 1999 2307 3725 1010 2000 3163 1010 1998 2000 1996 20266 1997 2167 3088 1998 1996 17154 3470 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.584356 140073664845568 tf_logging.py:115] input_ids: 101 2040 5451 1996 11068 1997 13298 102 1996 5879 5321 2018 1037 2350 2576 1010 3451 1998 2510 4254 2006 5781 2885 1998 2130 1996 2379 2264 1012 1996 5879 2015 2020 15607 2005 2037 7761 4382 1998 2776 2005 2037 3017 11345 3723 1010 3352 16258 21576 2015 1997 1996 3234 26582 2046 2029 2027 4632 27605 13776 1012 2027 4233 1996 25624 1011 7472 2653 1997 1996 26165 2455 2027 3876 1010 2037 9329 3352 2124 2004 5879 1010 20692 8630 2030 5879 2413 1010 2019 2590 4706 2653 1012 1996 11068 1997 13298 1010 2029 2027 2719 2011 5036 2007 1996 2413 4410 1010 2001 1037 2307 10882 12879 1997 5781 2605 1010 1998 2104 2957 1045 1997 13298 2001 16158 2046 1037 2522 21579 1998 18085 18018 1999 16708 7470 1012 1996 5879 2015 2024 3264 2119 2005 2037 3226 1010 2107 2004 2037 4310 17135 4294 1998 3315 7443 1010 1998 2005 2037 3278 2510 17571 1998 15463 1012 5879 29506 2015 2631 1996 2983 1997 12071 2104 5074 2462 2044 16152 2075 2670 3304 2006 1996 7354 19023 1998 8734 2015 1010 1998 2019 5590 2006 6852 1997 2037 3804 1010 2520 1996 25466 1010 2419 2000 1996 5879 9187 1997 2563 2012 1996 2645 1997 12296 1999 10114 2575 1012 5879 3451 1998 2510 3747 3659 2013 2122 2047 2647 8941 2000 1996 25237 2163 1997 1996 2379 2264 1010 2073 2037 3159 8945 29122 15422 1045 2631 1996 18018 1997 19078 1999 1996 24485 1010 2000 3885 1998 3575 1999 2307 3725 1010 2000 3163 1010 1998 2000 1996 20266 1997 2167 3088 1998 1996 17154 3470 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.585191 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.586042 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.592428 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.593243 140073664845568 tf_logging.py:115] unique_id: 1000000011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.594013 140073664845568 tf_logging.py:115] example_index: 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.594767 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] what religion were the norman ##s [SEP] the norman dynasty had a major political , cultural and military impact on medieval europe and even the near east . the norman ##s were famed for their martial spirit and eventually for their christian pie ##ty , becoming expo ##nent ##s of the catholic orthodoxy into which they ass ##imi ##lated . they adopted the gallo - romance language of the frankish land they settled , their dialect becoming known as norman , norma ##und or norman french , an important literary language . the duchy of normandy , which they formed by treaty with the french crown , was a great fi ##ef of medieval france , and under richard i of normandy was forged into a co ##hesive and formidable principality in feudal tenure . the norman ##s are noted both for their culture , such as their unique romanesque architecture and musical traditions , and for their significant military accomplishments and innovations . norman adventurer ##s founded the kingdom of sicily under roger ii after conquer ##ing southern italy on the sara ##cens and byzantine ##s , and an expedition on behalf of their duke , william the conqueror , led to the norman conquest of england at the battle of hastings in 106 ##6 . norman cultural and military influence spread from these new european centres to the crusader states of the near east , where their prince bo ##hem ##ond i founded the principality of antioch in the levant , to scotland and wales in great britain , to ireland , and to the coasts of north africa and the canary islands . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.595595 140073664845568 tf_logging.py:115] tokens: [CLS] what religion were the norman ##s [SEP] the norman dynasty had a major political , cultural and military impact on medieval europe and even the near east . the norman ##s were famed for their martial spirit and eventually for their christian pie ##ty , becoming expo ##nent ##s of the catholic orthodoxy into which they ass ##imi ##lated . they adopted the gallo - romance language of the frankish land they settled , their dialect becoming known as norman , norma ##und or norman french , an important literary language . the duchy of normandy , which they formed by treaty with the french crown , was a great fi ##ef of medieval france , and under richard i of normandy was forged into a co ##hesive and formidable principality in feudal tenure . the norman ##s are noted both for their culture , such as their unique romanesque architecture and musical traditions , and for their significant military accomplishments and innovations . norman adventurer ##s founded the kingdom of sicily under roger ii after conquer ##ing southern italy on the sara ##cens and byzantine ##s , and an expedition on behalf of their duke , william the conqueror , led to the norman conquest of england at the battle of hastings in 106 ##6 . norman cultural and military influence spread from these new european centres to the crusader states of the near east , where their prince bo ##hem ##ond i founded the principality of antioch in the levant , to scotland and wales in great britain , to ireland , and to the coasts of north africa and the canary islands . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 8:0 9:1 10:2 11:3 12:4 13:5 14:6 15:6 16:7 17:8 18:9 19:10 20:11 21:12 22:13 23:14 24:15 25:16 26:17 27:18 28:18 29:19 30:20 31:20 32:21 33:22 34:23 35:24 36:25 37:26 38:27 39:28 40:29 41:30 42:31 43:32 44:32 45:32 46:33 47:34 48:34 49:34 50:35 51:36 52:37 53:38 54:39 55:40 56:41 57:42 58:42 59:42 60:42 61:43 62:44 63:45 64:46 65:46 66:46 67:47 68:48 69:49 70:50 71:51 72:52 73:53 74:53 75:54 76:55 77:56 78:57 79:58 80:59 81:59 82:60 83:60 84:61 85:62 86:63 87:63 88:64 89:65 90:66 91:67 92:67 93:68 94:69 95:70 96:71 97:71 98:72 99:73 100:74 101:75 102:76 103:77 104:78 105:79 106:80 107:80 108:81 109:82 110:83 111:84 112:84 113:85 114:86 115:87 116:87 117:88 118:89 119:90 120:91 121:92 122:93 123:94 124:95 125:96 126:97 127:98 128:98 129:99 130:100 131:101 132:102 133:103 134:104 135:104 136:105 137:106 138:106 139:107 140:108 141:109 142:110 143:111 144:112 145:112 146:113 147:114 148:115 149:116 150:117 151:118 152:119 153:120 154:121 155:121 156:122 157:123 158:124 159:125 160:126 161:127 162:128 163:129 164:129 165:130 166:131 167:131 168:132 169:133 170:134 171:135 172:136 173:137 174:138 175:139 176:140 177:141 178:141 179:142 180:143 181:144 182:145 183:146 184:146 185:147 186:148 187:148 188:148 189:149 190:150 191:151 192:152 193:153 194:154 195:155 196:156 197:156 198:157 199:158 200:159 201:159 202:160 203:161 204:162 205:163 206:164 207:165 208:166 209:167 210:168 211:169 212:170 213:171 214:172 215:173 216:173 217:173 218:174 219:175 220:176 221:177 222:178 223:179 224:180 225:181 226:182 227:183 228:184 229:185 230:186 231:187 232:188 233:189 234:190 235:191 236:192 237:192 238:193 239:194 240:195 241:196 242:196 243:196 244:197 245:198 246:199 247:200 248:201 249:202 250:203 251:204 252:205 253:205 254:206 255:207 256:208 257:209 258:210 259:211 260:212 261:212 262:213 263:214 264:214 265:215 266:216 267:217 268:218 269:219 270:220 271:221 272:222 273:223 274:224 275:225 276:225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.596441 140073664845568 tf_logging.py:115] token_to_orig_map: 8:0 9:1 10:2 11:3 12:4 13:5 14:6 15:6 16:7 17:8 18:9 19:10 20:11 21:12 22:13 23:14 24:15 25:16 26:17 27:18 28:18 29:19 30:20 31:20 32:21 33:22 34:23 35:24 36:25 37:26 38:27 39:28 40:29 41:30 42:31 43:32 44:32 45:32 46:33 47:34 48:34 49:34 50:35 51:36 52:37 53:38 54:39 55:40 56:41 57:42 58:42 59:42 60:42 61:43 62:44 63:45 64:46 65:46 66:46 67:47 68:48 69:49 70:50 71:51 72:52 73:53 74:53 75:54 76:55 77:56 78:57 79:58 80:59 81:59 82:60 83:60 84:61 85:62 86:63 87:63 88:64 89:65 90:66 91:67 92:67 93:68 94:69 95:70 96:71 97:71 98:72 99:73 100:74 101:75 102:76 103:77 104:78 105:79 106:80 107:80 108:81 109:82 110:83 111:84 112:84 113:85 114:86 115:87 116:87 117:88 118:89 119:90 120:91 121:92 122:93 123:94 124:95 125:96 126:97 127:98 128:98 129:99 130:100 131:101 132:102 133:103 134:104 135:104 136:105 137:106 138:106 139:107 140:108 141:109 142:110 143:111 144:112 145:112 146:113 147:114 148:115 149:116 150:117 151:118 152:119 153:120 154:121 155:121 156:122 157:123 158:124 159:125 160:126 161:127 162:128 163:129 164:129 165:130 166:131 167:131 168:132 169:133 170:134 171:135 172:136 173:137 174:138 175:139 176:140 177:141 178:141 179:142 180:143 181:144 182:145 183:146 184:146 185:147 186:148 187:148 188:148 189:149 190:150 191:151 192:152 193:153 194:154 195:155 196:156 197:156 198:157 199:158 200:159 201:159 202:160 203:161 204:162 205:163 206:164 207:165 208:166 209:167 210:168 211:169 212:170 213:171 214:172 215:173 216:173 217:173 218:174 219:175 220:176 221:177 222:178 223:179 224:180 225:181 226:182 227:183 228:184 229:185 230:186 231:187 232:188 233:189 234:190 235:191 236:192 237:192 238:193 239:194 240:195 241:196 242:196 243:196 244:197 245:198 246:199 247:200 248:201 249:202 250:203 251:204 252:205 253:205 254:206 255:207 256:208 257:209 258:210 259:211 260:212 261:212 262:213 263:214 264:214 265:215 266:216 267:217 268:218 269:219 270:220 271:221 272:222 273:223 274:224 275:225 276:225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.597321 140073664845568 tf_logging.py:115] token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2054 4676 2020 1996 5879 2015 102 1996 5879 5321 2018 1037 2350 2576 1010 3451 1998 2510 4254 2006 5781 2885 1998 2130 1996 2379 2264 1012 1996 5879 2015 2020 15607 2005 2037 7761 4382 1998 2776 2005 2037 3017 11345 3723 1010 3352 16258 21576 2015 1997 1996 3234 26582 2046 2029 2027 4632 27605 13776 1012 2027 4233 1996 25624 1011 7472 2653 1997 1996 26165 2455 2027 3876 1010 2037 9329 3352 2124 2004 5879 1010 20692 8630 2030 5879 2413 1010 2019 2590 4706 2653 1012 1996 11068 1997 13298 1010 2029 2027 2719 2011 5036 2007 1996 2413 4410 1010 2001 1037 2307 10882 12879 1997 5781 2605 1010 1998 2104 2957 1045 1997 13298 2001 16158 2046 1037 2522 21579 1998 18085 18018 1999 16708 7470 1012 1996 5879 2015 2024 3264 2119 2005 2037 3226 1010 2107 2004 2037 4310 17135 4294 1998 3315 7443 1010 1998 2005 2037 3278 2510 17571 1998 15463 1012 5879 29506 2015 2631 1996 2983 1997 12071 2104 5074 2462 2044 16152 2075 2670 3304 2006 1996 7354 19023 1998 8734 2015 1010 1998 2019 5590 2006 6852 1997 2037 3804 1010 2520 1996 25466 1010 2419 2000 1996 5879 9187 1997 2563 2012 1996 2645 1997 12296 1999 10114 2575 1012 5879 3451 1998 2510 3747 3659 2013 2122 2047 2647 8941 2000 1996 25237 2163 1997 1996 2379 2264 1010 2073 2037 3159 8945 29122 15422 1045 2631 1996 18018 1997 19078 1999 1996 24485 1010 2000 3885 1998 3575 1999 2307 3725 1010 2000 3163 1010 1998 2000 1996 20266 1997 2167 3088 1998 1996 17154 3470 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.598256 140073664845568 tf_logging.py:115] input_ids: 101 2054 4676 2020 1996 5879 2015 102 1996 5879 5321 2018 1037 2350 2576 1010 3451 1998 2510 4254 2006 5781 2885 1998 2130 1996 2379 2264 1012 1996 5879 2015 2020 15607 2005 2037 7761 4382 1998 2776 2005 2037 3017 11345 3723 1010 3352 16258 21576 2015 1997 1996 3234 26582 2046 2029 2027 4632 27605 13776 1012 2027 4233 1996 25624 1011 7472 2653 1997 1996 26165 2455 2027 3876 1010 2037 9329 3352 2124 2004 5879 1010 20692 8630 2030 5879 2413 1010 2019 2590 4706 2653 1012 1996 11068 1997 13298 1010 2029 2027 2719 2011 5036 2007 1996 2413 4410 1010 2001 1037 2307 10882 12879 1997 5781 2605 1010 1998 2104 2957 1045 1997 13298 2001 16158 2046 1037 2522 21579 1998 18085 18018 1999 16708 7470 1012 1996 5879 2015 2024 3264 2119 2005 2037 3226 1010 2107 2004 2037 4310 17135 4294 1998 3315 7443 1010 1998 2005 2037 3278 2510 17571 1998 15463 1012 5879 29506 2015 2631 1996 2983 1997 12071 2104 5074 2462 2044 16152 2075 2670 3304 2006 1996 7354 19023 1998 8734 2015 1010 1998 2019 5590 2006 6852 1997 2037 3804 1010 2520 1996 25466 1010 2419 2000 1996 5879 9187 1997 2563 2012 1996 2645 1997 12296 1999 10114 2575 1012 5879 3451 1998 2510 3747 3659 2013 2122 2047 2647 8941 2000 1996 25237 2163 1997 1996 2379 2264 1010 2073 2037 3159 8945 29122 15422 1045 2631 1996 18018 1997 19078 1999 1996 24485 1010 2000 3885 1998 3575 1999 2307 3725 1010 2000 3163 1010 1998 2000 1996 20266 1997 2167 3088 1998 1996 17154 3470 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.599136 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.599982 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.606787 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.607646 140073664845568 tf_logging.py:115] unique_id: 1000000012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.608403 140073664845568 tf_logging.py:115] example_index: 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.609149 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] what type of major impact did the norman dynasty have on modern europe ? [SEP] the norman dynasty had a major political , cultural and military impact on medieval europe and even the near east . the norman ##s were famed for their martial spirit and eventually for their christian pie ##ty , becoming expo ##nent ##s of the catholic orthodoxy into which they ass ##imi ##lated . they adopted the gallo - romance language of the frankish land they settled , their dialect becoming known as norman , norma ##und or norman french , an important literary language . the duchy of normandy , which they formed by treaty with the french crown , was a great fi ##ef of medieval france , and under richard i of normandy was forged into a co ##hesive and formidable principality in feudal tenure . the norman ##s are noted both for their culture , such as their unique romanesque architecture and musical traditions , and for their significant military accomplishments and innovations . norman adventurer ##s founded the kingdom of sicily under roger ii after conquer ##ing southern italy on the sara ##cens and byzantine ##s , and an expedition on behalf of their duke , william the conqueror , led to the norman conquest of england at the battle of hastings in 106 ##6 . norman cultural and military influence spread from these new european centres to the crusader states of the near east , where their prince bo ##hem ##ond i founded the principality of antioch in the levant , to scotland and wales in great britain , to ireland , and to the coasts of north africa and the canary islands . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.610024 140073664845568 tf_logging.py:115] tokens: [CLS] what type of major impact did the norman dynasty have on modern europe ? [SEP] the norman dynasty had a major political , cultural and military impact on medieval europe and even the near east . the norman ##s were famed for their martial spirit and eventually for their christian pie ##ty , becoming expo ##nent ##s of the catholic orthodoxy into which they ass ##imi ##lated . they adopted the gallo - romance language of the frankish land they settled , their dialect becoming known as norman , norma ##und or norman french , an important literary language . the duchy of normandy , which they formed by treaty with the french crown , was a great fi ##ef of medieval france , and under richard i of normandy was forged into a co ##hesive and formidable principality in feudal tenure . the norman ##s are noted both for their culture , such as their unique romanesque architecture and musical traditions , and for their significant military accomplishments and innovations . norman adventurer ##s founded the kingdom of sicily under roger ii after conquer ##ing southern italy on the sara ##cens and byzantine ##s , and an expedition on behalf of their duke , william the conqueror , led to the norman conquest of england at the battle of hastings in 106 ##6 . norman cultural and military influence spread from these new european centres to the crusader states of the near east , where their prince bo ##hem ##ond i founded the principality of antioch in the levant , to scotland and wales in great britain , to ireland , and to the coasts of north africa and the canary islands . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 16:0 17:1 18:2 19:3 20:4 21:5 22:6 23:6 24:7 25:8 26:9 27:10 28:11 29:12 30:13 31:14 32:15 33:16 34:17 35:18 36:18 37:19 38:20 39:20 40:21 41:22 42:23 43:24 44:25 45:26 46:27 47:28 48:29 49:30 50:31 51:32 52:32 53:32 54:33 55:34 56:34 57:34 58:35 59:36 60:37 61:38 62:39 63:40 64:41 65:42 66:42 67:42 68:42 69:43 70:44 71:45 72:46 73:46 74:46 75:47 76:48 77:49 78:50 79:51 80:52 81:53 82:53 83:54 84:55 85:56 86:57 87:58 88:59 89:59 90:60 91:60 92:61 93:62 94:63 95:63 96:64 97:65 98:66 99:67 100:67 101:68 102:69 103:70 104:71 105:71 106:72 107:73 108:74 109:75 110:76 111:77 112:78 113:79 114:80 115:80 116:81 117:82 118:83 119:84 120:84 121:85 122:86 123:87 124:87 125:88 126:89 127:90 128:91 129:92 130:93 131:94 132:95 133:96 134:97 135:98 136:98 137:99 138:100 139:101 140:102 141:103 142:104 143:104 144:105 145:106 146:106 147:107 148:108 149:109 150:110 151:111 152:112 153:112 154:113 155:114 156:115 157:116 158:117 159:118 160:119 161:120 162:121 163:121 164:122 165:123 166:124 167:125 168:126 169:127 170:128 171:129 172:129 173:130 174:131 175:131 176:132 177:133 178:134 179:135 180:136 181:137 182:138 183:139 184:140 185:141 186:141 187:142 188:143 189:144 190:145 191:146 192:146 193:147 194:148 195:148 196:148 197:149 198:150 199:151 200:152 201:153 202:154 203:155 204:156 205:156 206:157 207:158 208:159 209:159 210:160 211:161 212:162 213:163 214:164 215:165 216:166 217:167 218:168 219:169 220:170 221:171 222:172 223:173 224:173 225:173 226:174 227:175 228:176 229:177 230:178 231:179 232:180 233:181 234:182 235:183 236:184 237:185 238:186 239:187 240:188 241:189 242:190 243:191 244:192 245:192 246:193 247:194 248:195 249:196 250:196 251:196 252:197 253:198 254:199 255:200 256:201 257:202 258:203 259:204 260:205 261:205 262:206 263:207 264:208 265:209 266:210 267:211 268:212 269:212 270:213 271:214 272:214 273:215 274:216 275:217 276:218 277:219 278:220 279:221 280:222 281:223 282:224 283:225 284:225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.610879 140073664845568 tf_logging.py:115] token_to_orig_map: 16:0 17:1 18:2 19:3 20:4 21:5 22:6 23:6 24:7 25:8 26:9 27:10 28:11 29:12 30:13 31:14 32:15 33:16 34:17 35:18 36:18 37:19 38:20 39:20 40:21 41:22 42:23 43:24 44:25 45:26 46:27 47:28 48:29 49:30 50:31 51:32 52:32 53:32 54:33 55:34 56:34 57:34 58:35 59:36 60:37 61:38 62:39 63:40 64:41 65:42 66:42 67:42 68:42 69:43 70:44 71:45 72:46 73:46 74:46 75:47 76:48 77:49 78:50 79:51 80:52 81:53 82:53 83:54 84:55 85:56 86:57 87:58 88:59 89:59 90:60 91:60 92:61 93:62 94:63 95:63 96:64 97:65 98:66 99:67 100:67 101:68 102:69 103:70 104:71 105:71 106:72 107:73 108:74 109:75 110:76 111:77 112:78 113:79 114:80 115:80 116:81 117:82 118:83 119:84 120:84 121:85 122:86 123:87 124:87 125:88 126:89 127:90 128:91 129:92 130:93 131:94 132:95 133:96 134:97 135:98 136:98 137:99 138:100 139:101 140:102 141:103 142:104 143:104 144:105 145:106 146:106 147:107 148:108 149:109 150:110 151:111 152:112 153:112 154:113 155:114 156:115 157:116 158:117 159:118 160:119 161:120 162:121 163:121 164:122 165:123 166:124 167:125 168:126 169:127 170:128 171:129 172:129 173:130 174:131 175:131 176:132 177:133 178:134 179:135 180:136 181:137 182:138 183:139 184:140 185:141 186:141 187:142 188:143 189:144 190:145 191:146 192:146 193:147 194:148 195:148 196:148 197:149 198:150 199:151 200:152 201:153 202:154 203:155 204:156 205:156 206:157 207:158 208:159 209:159 210:160 211:161 212:162 213:163 214:164 215:165 216:166 217:167 218:168 219:169 220:170 221:171 222:172 223:173 224:173 225:173 226:174 227:175 228:176 229:177 230:178 231:179 232:180 233:181 234:182 235:183 236:184 237:185 238:186 239:187 240:188 241:189 242:190 243:191 244:192 245:192 246:193 247:194 248:195 249:196 250:196 251:196 252:197 253:198 254:199 255:200 256:201 257:202 258:203 259:204 260:205 261:205 262:206 263:207 264:208 265:209 266:210 267:211 268:212 269:212 270:213 271:214 272:214 273:215 274:216 275:217 276:218 277:219 278:220 279:221 280:222 281:223 282:224 283:225 284:225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.611729 140073664845568 tf_logging.py:115] token_is_max_context: 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2054 2828 1997 2350 4254 2106 1996 5879 5321 2031 2006 2715 2885 1029 102 1996 5879 5321 2018 1037 2350 2576 1010 3451 1998 2510 4254 2006 5781 2885 1998 2130 1996 2379 2264 1012 1996 5879 2015 2020 15607 2005 2037 7761 4382 1998 2776 2005 2037 3017 11345 3723 1010 3352 16258 21576 2015 1997 1996 3234 26582 2046 2029 2027 4632 27605 13776 1012 2027 4233 1996 25624 1011 7472 2653 1997 1996 26165 2455 2027 3876 1010 2037 9329 3352 2124 2004 5879 1010 20692 8630 2030 5879 2413 1010 2019 2590 4706 2653 1012 1996 11068 1997 13298 1010 2029 2027 2719 2011 5036 2007 1996 2413 4410 1010 2001 1037 2307 10882 12879 1997 5781 2605 1010 1998 2104 2957 1045 1997 13298 2001 16158 2046 1037 2522 21579 1998 18085 18018 1999 16708 7470 1012 1996 5879 2015 2024 3264 2119 2005 2037 3226 1010 2107 2004 2037 4310 17135 4294 1998 3315 7443 1010 1998 2005 2037 3278 2510 17571 1998 15463 1012 5879 29506 2015 2631 1996 2983 1997 12071 2104 5074 2462 2044 16152 2075 2670 3304 2006 1996 7354 19023 1998 8734 2015 1010 1998 2019 5590 2006 6852 1997 2037 3804 1010 2520 1996 25466 1010 2419 2000 1996 5879 9187 1997 2563 2012 1996 2645 1997 12296 1999 10114 2575 1012 5879 3451 1998 2510 3747 3659 2013 2122 2047 2647 8941 2000 1996 25237 2163 1997 1996 2379 2264 1010 2073 2037 3159 8945 29122 15422 1045 2631 1996 18018 1997 19078 1999 1996 24485 1010 2000 3885 1998 3575 1999 2307 3725 1010 2000 3163 1010 1998 2000 1996 20266 1997 2167 3088 1998 1996 17154 3470 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.612620 140073664845568 tf_logging.py:115] input_ids: 101 2054 2828 1997 2350 4254 2106 1996 5879 5321 2031 2006 2715 2885 1029 102 1996 5879 5321 2018 1037 2350 2576 1010 3451 1998 2510 4254 2006 5781 2885 1998 2130 1996 2379 2264 1012 1996 5879 2015 2020 15607 2005 2037 7761 4382 1998 2776 2005 2037 3017 11345 3723 1010 3352 16258 21576 2015 1997 1996 3234 26582 2046 2029 2027 4632 27605 13776 1012 2027 4233 1996 25624 1011 7472 2653 1997 1996 26165 2455 2027 3876 1010 2037 9329 3352 2124 2004 5879 1010 20692 8630 2030 5879 2413 1010 2019 2590 4706 2653 1012 1996 11068 1997 13298 1010 2029 2027 2719 2011 5036 2007 1996 2413 4410 1010 2001 1037 2307 10882 12879 1997 5781 2605 1010 1998 2104 2957 1045 1997 13298 2001 16158 2046 1037 2522 21579 1998 18085 18018 1999 16708 7470 1012 1996 5879 2015 2024 3264 2119 2005 2037 3226 1010 2107 2004 2037 4310 17135 4294 1998 3315 7443 1010 1998 2005 2037 3278 2510 17571 1998 15463 1012 5879 29506 2015 2631 1996 2983 1997 12071 2104 5074 2462 2044 16152 2075 2670 3304 2006 1996 7354 19023 1998 8734 2015 1010 1998 2019 5590 2006 6852 1997 2037 3804 1010 2520 1996 25466 1010 2419 2000 1996 5879 9187 1997 2563 2012 1996 2645 1997 12296 1999 10114 2575 1012 5879 3451 1998 2510 3747 3659 2013 2122 2047 2647 8941 2000 1996 25237 2163 1997 1996 2379 2264 1010 2073 2037 3159 8945 29122 15422 1045 2631 1996 18018 1997 19078 1999 1996 24485 1010 2000 3885 1998 3575 1999 2307 3725 1010 2000 3163 1010 1998 2000 1996 20266 1997 2167 3088 1998 1996 17154 3470 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.613486 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.614514 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.620997 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.621866 140073664845568 tf_logging.py:115] unique_id: 1000000013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.622650 140073664845568 tf_logging.py:115] example_index: 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.623407 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] who was famed for their christian spirit ? [SEP] the norman dynasty had a major political , cultural and military impact on medieval europe and even the near east . the norman ##s were famed for their martial spirit and eventually for their christian pie ##ty , becoming expo ##nent ##s of the catholic orthodoxy into which they ass ##imi ##lated . they adopted the gallo - romance language of the frankish land they settled , their dialect becoming known as norman , norma ##und or norman french , an important literary language . the duchy of normandy , which they formed by treaty with the french crown , was a great fi ##ef of medieval france , and under richard i of normandy was forged into a co ##hesive and formidable principality in feudal tenure . the norman ##s are noted both for their culture , such as their unique romanesque architecture and musical traditions , and for their significant military accomplishments and innovations . norman adventurer ##s founded the kingdom of sicily under roger ii after conquer ##ing southern italy on the sara ##cens and byzantine ##s , and an expedition on behalf of their duke , william the conqueror , led to the norman conquest of england at the battle of hastings in 106 ##6 . norman cultural and military influence spread from these new european centres to the crusader states of the near east , where their prince bo ##hem ##ond i founded the principality of antioch in the levant , to scotland and wales in great britain , to ireland , and to the coasts of north africa and the canary islands . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.624236 140073664845568 tf_logging.py:115] tokens: [CLS] who was famed for their christian spirit ? [SEP] the norman dynasty had a major political , cultural and military impact on medieval europe and even the near east . the norman ##s were famed for their martial spirit and eventually for their christian pie ##ty , becoming expo ##nent ##s of the catholic orthodoxy into which they ass ##imi ##lated . they adopted the gallo - romance language of the frankish land they settled , their dialect becoming known as norman , norma ##und or norman french , an important literary language . the duchy of normandy , which they formed by treaty with the french crown , was a great fi ##ef of medieval france , and under richard i of normandy was forged into a co ##hesive and formidable principality in feudal tenure . the norman ##s are noted both for their culture , such as their unique romanesque architecture and musical traditions , and for their significant military accomplishments and innovations . norman adventurer ##s founded the kingdom of sicily under roger ii after conquer ##ing southern italy on the sara ##cens and byzantine ##s , and an expedition on behalf of their duke , william the conqueror , led to the norman conquest of england at the battle of hastings in 106 ##6 . norman cultural and military influence spread from these new european centres to the crusader states of the near east , where their prince bo ##hem ##ond i founded the principality of antioch in the levant , to scotland and wales in great britain , to ireland , and to the coasts of north africa and the canary islands . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 10:0 11:1 12:2 13:3 14:4 15:5 16:6 17:6 18:7 19:8 20:9 21:10 22:11 23:12 24:13 25:14 26:15 27:16 28:17 29:18 30:18 31:19 32:20 33:20 34:21 35:22 36:23 37:24 38:25 39:26 40:27 41:28 42:29 43:30 44:31 45:32 46:32 47:32 48:33 49:34 50:34 51:34 52:35 53:36 54:37 55:38 56:39 57:40 58:41 59:42 60:42 61:42 62:42 63:43 64:44 65:45 66:46 67:46 68:46 69:47 70:48 71:49 72:50 73:51 74:52 75:53 76:53 77:54 78:55 79:56 80:57 81:58 82:59 83:59 84:60 85:60 86:61 87:62 88:63 89:63 90:64 91:65 92:66 93:67 94:67 95:68 96:69 97:70 98:71 99:71 100:72 101:73 102:74 103:75 104:76 105:77 106:78 107:79 108:80 109:80 110:81 111:82 112:83 113:84 114:84 115:85 116:86 117:87 118:87 119:88 120:89 121:90 122:91 123:92 124:93 125:94 126:95 127:96 128:97 129:98 130:98 131:99 132:100 133:101 134:102 135:103 136:104 137:104 138:105 139:106 140:106 141:107 142:108 143:109 144:110 145:111 146:112 147:112 148:113 149:114 150:115 151:116 152:117 153:118 154:119 155:120 156:121 157:121 158:122 159:123 160:124 161:125 162:126 163:127 164:128 165:129 166:129 167:130 168:131 169:131 170:132 171:133 172:134 173:135 174:136 175:137 176:138 177:139 178:140 179:141 180:141 181:142 182:143 183:144 184:145 185:146 186:146 187:147 188:148 189:148 190:148 191:149 192:150 193:151 194:152 195:153 196:154 197:155 198:156 199:156 200:157 201:158 202:159 203:159 204:160 205:161 206:162 207:163 208:164 209:165 210:166 211:167 212:168 213:169 214:170 215:171 216:172 217:173 218:173 219:173 220:174 221:175 222:176 223:177 224:178 225:179 226:180 227:181 228:182 229:183 230:184 231:185 232:186 233:187 234:188 235:189 236:190 237:191 238:192 239:192 240:193 241:194 242:195 243:196 244:196 245:196 246:197 247:198 248:199 249:200 250:201 251:202 252:203 253:204 254:205 255:205 256:206 257:207 258:208 259:209 260:210 261:211 262:212 263:212 264:213 265:214 266:214 267:215 268:216 269:217 270:218 271:219 272:220 273:221 274:222 275:223 276:224 277:225 278:225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.625087 140073664845568 tf_logging.py:115] token_to_orig_map: 10:0 11:1 12:2 13:3 14:4 15:5 16:6 17:6 18:7 19:8 20:9 21:10 22:11 23:12 24:13 25:14 26:15 27:16 28:17 29:18 30:18 31:19 32:20 33:20 34:21 35:22 36:23 37:24 38:25 39:26 40:27 41:28 42:29 43:30 44:31 45:32 46:32 47:32 48:33 49:34 50:34 51:34 52:35 53:36 54:37 55:38 56:39 57:40 58:41 59:42 60:42 61:42 62:42 63:43 64:44 65:45 66:46 67:46 68:46 69:47 70:48 71:49 72:50 73:51 74:52 75:53 76:53 77:54 78:55 79:56 80:57 81:58 82:59 83:59 84:60 85:60 86:61 87:62 88:63 89:63 90:64 91:65 92:66 93:67 94:67 95:68 96:69 97:70 98:71 99:71 100:72 101:73 102:74 103:75 104:76 105:77 106:78 107:79 108:80 109:80 110:81 111:82 112:83 113:84 114:84 115:85 116:86 117:87 118:87 119:88 120:89 121:90 122:91 123:92 124:93 125:94 126:95 127:96 128:97 129:98 130:98 131:99 132:100 133:101 134:102 135:103 136:104 137:104 138:105 139:106 140:106 141:107 142:108 143:109 144:110 145:111 146:112 147:112 148:113 149:114 150:115 151:116 152:117 153:118 154:119 155:120 156:121 157:121 158:122 159:123 160:124 161:125 162:126 163:127 164:128 165:129 166:129 167:130 168:131 169:131 170:132 171:133 172:134 173:135 174:136 175:137 176:138 177:139 178:140 179:141 180:141 181:142 182:143 183:144 184:145 185:146 186:146 187:147 188:148 189:148 190:148 191:149 192:150 193:151 194:152 195:153 196:154 197:155 198:156 199:156 200:157 201:158 202:159 203:159 204:160 205:161 206:162 207:163 208:164 209:165 210:166 211:167 212:168 213:169 214:170 215:171 216:172 217:173 218:173 219:173 220:174 221:175 222:176 223:177 224:178 225:179 226:180 227:181 228:182 229:183 230:184 231:185 232:186 233:187 234:188 235:189 236:190 237:191 238:192 239:192 240:193 241:194 242:195 243:196 244:196 245:196 246:197 247:198 248:199 249:200 250:201 251:202 252:203 253:204 254:205 255:205 256:206 257:207 258:208 259:209 260:210 261:211 262:212 263:212 264:213 265:214 266:214 267:215 268:216 269:217 270:218 271:219 272:220 273:221 274:222 275:223 276:224 277:225 278:225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.625963 140073664845568 tf_logging.py:115] token_is_max_context: 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2040 2001 15607 2005 2037 3017 4382 1029 102 1996 5879 5321 2018 1037 2350 2576 1010 3451 1998 2510 4254 2006 5781 2885 1998 2130 1996 2379 2264 1012 1996 5879 2015 2020 15607 2005 2037 7761 4382 1998 2776 2005 2037 3017 11345 3723 1010 3352 16258 21576 2015 1997 1996 3234 26582 2046 2029 2027 4632 27605 13776 1012 2027 4233 1996 25624 1011 7472 2653 1997 1996 26165 2455 2027 3876 1010 2037 9329 3352 2124 2004 5879 1010 20692 8630 2030 5879 2413 1010 2019 2590 4706 2653 1012 1996 11068 1997 13298 1010 2029 2027 2719 2011 5036 2007 1996 2413 4410 1010 2001 1037 2307 10882 12879 1997 5781 2605 1010 1998 2104 2957 1045 1997 13298 2001 16158 2046 1037 2522 21579 1998 18085 18018 1999 16708 7470 1012 1996 5879 2015 2024 3264 2119 2005 2037 3226 1010 2107 2004 2037 4310 17135 4294 1998 3315 7443 1010 1998 2005 2037 3278 2510 17571 1998 15463 1012 5879 29506 2015 2631 1996 2983 1997 12071 2104 5074 2462 2044 16152 2075 2670 3304 2006 1996 7354 19023 1998 8734 2015 1010 1998 2019 5590 2006 6852 1997 2037 3804 1010 2520 1996 25466 1010 2419 2000 1996 5879 9187 1997 2563 2012 1996 2645 1997 12296 1999 10114 2575 1012 5879 3451 1998 2510 3747 3659 2013 2122 2047 2647 8941 2000 1996 25237 2163 1997 1996 2379 2264 1010 2073 2037 3159 8945 29122 15422 1045 2631 1996 18018 1997 19078 1999 1996 24485 1010 2000 3885 1998 3575 1999 2307 3725 1010 2000 3163 1010 1998 2000 1996 20266 1997 2167 3088 1998 1996 17154 3470 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.626841 140073664845568 tf_logging.py:115] input_ids: 101 2040 2001 15607 2005 2037 3017 4382 1029 102 1996 5879 5321 2018 1037 2350 2576 1010 3451 1998 2510 4254 2006 5781 2885 1998 2130 1996 2379 2264 1012 1996 5879 2015 2020 15607 2005 2037 7761 4382 1998 2776 2005 2037 3017 11345 3723 1010 3352 16258 21576 2015 1997 1996 3234 26582 2046 2029 2027 4632 27605 13776 1012 2027 4233 1996 25624 1011 7472 2653 1997 1996 26165 2455 2027 3876 1010 2037 9329 3352 2124 2004 5879 1010 20692 8630 2030 5879 2413 1010 2019 2590 4706 2653 1012 1996 11068 1997 13298 1010 2029 2027 2719 2011 5036 2007 1996 2413 4410 1010 2001 1037 2307 10882 12879 1997 5781 2605 1010 1998 2104 2957 1045 1997 13298 2001 16158 2046 1037 2522 21579 1998 18085 18018 1999 16708 7470 1012 1996 5879 2015 2024 3264 2119 2005 2037 3226 1010 2107 2004 2037 4310 17135 4294 1998 3315 7443 1010 1998 2005 2037 3278 2510 17571 1998 15463 1012 5879 29506 2015 2631 1996 2983 1997 12071 2104 5074 2462 2044 16152 2075 2670 3304 2006 1996 7354 19023 1998 8734 2015 1010 1998 2019 5590 2006 6852 1997 2037 3804 1010 2520 1996 25466 1010 2419 2000 1996 5879 9187 1997 2563 2012 1996 2645 1997 12296 1999 10114 2575 1012 5879 3451 1998 2510 3747 3659 2013 2122 2047 2647 8941 2000 1996 25237 2163 1997 1996 2379 2264 1010 2073 2037 3159 8945 29122 15422 1045 2631 1996 18018 1997 19078 1999 1996 24485 1010 2000 3885 1998 3575 1999 2307 3725 1010 2000 3163 1010 1998 2000 1996 20266 1997 2167 3088 1998 1996 17154 3470 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.627677 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.628510 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.635013 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.635848 140073664845568 tf_logging.py:115] unique_id: 1000000014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.636677 140073664845568 tf_logging.py:115] example_index: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.637428 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] who ass ##imi ##lt ##ed the roman language ? [SEP] the norman dynasty had a major political , cultural and military impact on medieval europe and even the near east . the norman ##s were famed for their martial spirit and eventually for their christian pie ##ty , becoming expo ##nent ##s of the catholic orthodoxy into which they ass ##imi ##lated . they adopted the gallo - romance language of the frankish land they settled , their dialect becoming known as norman , norma ##und or norman french , an important literary language . the duchy of normandy , which they formed by treaty with the french crown , was a great fi ##ef of medieval france , and under richard i of normandy was forged into a co ##hesive and formidable principality in feudal tenure . the norman ##s are noted both for their culture , such as their unique romanesque architecture and musical traditions , and for their significant military accomplishments and innovations . norman adventurer ##s founded the kingdom of sicily under roger ii after conquer ##ing southern italy on the sara ##cens and byzantine ##s , and an expedition on behalf of their duke , william the conqueror , led to the norman conquest of england at the battle of hastings in 106 ##6 . norman cultural and military influence spread from these new european centres to the crusader states of the near east , where their prince bo ##hem ##ond i founded the principality of antioch in the levant , to scotland and wales in great britain , to ireland , and to the coasts of north africa and the canary islands . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.638331 140073664845568 tf_logging.py:115] tokens: [CLS] who ass ##imi ##lt ##ed the roman language ? [SEP] the norman dynasty had a major political , cultural and military impact on medieval europe and even the near east . the norman ##s were famed for their martial spirit and eventually for their christian pie ##ty , becoming expo ##nent ##s of the catholic orthodoxy into which they ass ##imi ##lated . they adopted the gallo - romance language of the frankish land they settled , their dialect becoming known as norman , norma ##und or norman french , an important literary language . the duchy of normandy , which they formed by treaty with the french crown , was a great fi ##ef of medieval france , and under richard i of normandy was forged into a co ##hesive and formidable principality in feudal tenure . the norman ##s are noted both for their culture , such as their unique romanesque architecture and musical traditions , and for their significant military accomplishments and innovations . norman adventurer ##s founded the kingdom of sicily under roger ii after conquer ##ing southern italy on the sara ##cens and byzantine ##s , and an expedition on behalf of their duke , william the conqueror , led to the norman conquest of england at the battle of hastings in 106 ##6 . norman cultural and military influence spread from these new european centres to the crusader states of the near east , where their prince bo ##hem ##ond i founded the principality of antioch in the levant , to scotland and wales in great britain , to ireland , and to the coasts of north africa and the canary islands . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 11:0 12:1 13:2 14:3 15:4 16:5 17:6 18:6 19:7 20:8 21:9 22:10 23:11 24:12 25:13 26:14 27:15 28:16 29:17 30:18 31:18 32:19 33:20 34:20 35:21 36:22 37:23 38:24 39:25 40:26 41:27 42:28 43:29 44:30 45:31 46:32 47:32 48:32 49:33 50:34 51:34 52:34 53:35 54:36 55:37 56:38 57:39 58:40 59:41 60:42 61:42 62:42 63:42 64:43 65:44 66:45 67:46 68:46 69:46 70:47 71:48 72:49 73:50 74:51 75:52 76:53 77:53 78:54 79:55 80:56 81:57 82:58 83:59 84:59 85:60 86:60 87:61 88:62 89:63 90:63 91:64 92:65 93:66 94:67 95:67 96:68 97:69 98:70 99:71 100:71 101:72 102:73 103:74 104:75 105:76 106:77 107:78 108:79 109:80 110:80 111:81 112:82 113:83 114:84 115:84 116:85 117:86 118:87 119:87 120:88 121:89 122:90 123:91 124:92 125:93 126:94 127:95 128:96 129:97 130:98 131:98 132:99 133:100 134:101 135:102 136:103 137:104 138:104 139:105 140:106 141:106 142:107 143:108 144:109 145:110 146:111 147:112 148:112 149:113 150:114 151:115 152:116 153:117 154:118 155:119 156:120 157:121 158:121 159:122 160:123 161:124 162:125 163:126 164:127 165:128 166:129 167:129 168:130 169:131 170:131 171:132 172:133 173:134 174:135 175:136 176:137 177:138 178:139 179:140 180:141 181:141 182:142 183:143 184:144 185:145 186:146 187:146 188:147 189:148 190:148 191:148 192:149 193:150 194:151 195:152 196:153 197:154 198:155 199:156 200:156 201:157 202:158 203:159 204:159 205:160 206:161 207:162 208:163 209:164 210:165 211:166 212:167 213:168 214:169 215:170 216:171 217:172 218:173 219:173 220:173 221:174 222:175 223:176 224:177 225:178 226:179 227:180 228:181 229:182 230:183 231:184 232:185 233:186 234:187 235:188 236:189 237:190 238:191 239:192 240:192 241:193 242:194 243:195 244:196 245:196 246:196 247:197 248:198 249:199 250:200 251:201 252:202 253:203 254:204 255:205 256:205 257:206 258:207 259:208 260:209 261:210 262:211 263:212 264:212 265:213 266:214 267:214 268:215 269:216 270:217 271:218 272:219 273:220 274:221 275:222 276:223 277:224 278:225 279:225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.639175 140073664845568 tf_logging.py:115] token_to_orig_map: 11:0 12:1 13:2 14:3 15:4 16:5 17:6 18:6 19:7 20:8 21:9 22:10 23:11 24:12 25:13 26:14 27:15 28:16 29:17 30:18 31:18 32:19 33:20 34:20 35:21 36:22 37:23 38:24 39:25 40:26 41:27 42:28 43:29 44:30 45:31 46:32 47:32 48:32 49:33 50:34 51:34 52:34 53:35 54:36 55:37 56:38 57:39 58:40 59:41 60:42 61:42 62:42 63:42 64:43 65:44 66:45 67:46 68:46 69:46 70:47 71:48 72:49 73:50 74:51 75:52 76:53 77:53 78:54 79:55 80:56 81:57 82:58 83:59 84:59 85:60 86:60 87:61 88:62 89:63 90:63 91:64 92:65 93:66 94:67 95:67 96:68 97:69 98:70 99:71 100:71 101:72 102:73 103:74 104:75 105:76 106:77 107:78 108:79 109:80 110:80 111:81 112:82 113:83 114:84 115:84 116:85 117:86 118:87 119:87 120:88 121:89 122:90 123:91 124:92 125:93 126:94 127:95 128:96 129:97 130:98 131:98 132:99 133:100 134:101 135:102 136:103 137:104 138:104 139:105 140:106 141:106 142:107 143:108 144:109 145:110 146:111 147:112 148:112 149:113 150:114 151:115 152:116 153:117 154:118 155:119 156:120 157:121 158:121 159:122 160:123 161:124 162:125 163:126 164:127 165:128 166:129 167:129 168:130 169:131 170:131 171:132 172:133 173:134 174:135 175:136 176:137 177:138 178:139 179:140 180:141 181:141 182:142 183:143 184:144 185:145 186:146 187:146 188:147 189:148 190:148 191:148 192:149 193:150 194:151 195:152 196:153 197:154 198:155 199:156 200:156 201:157 202:158 203:159 204:159 205:160 206:161 207:162 208:163 209:164 210:165 211:166 212:167 213:168 214:169 215:170 216:171 217:172 218:173 219:173 220:173 221:174 222:175 223:176 224:177 225:178 226:179 227:180 228:181 229:182 230:183 231:184 232:185 233:186 234:187 235:188 236:189 237:190 238:191 239:192 240:192 241:193 242:194 243:195 244:196 245:196 246:196 247:197 248:198 249:199 250:200 251:201 252:202 253:203 254:204 255:205 256:205 257:206 258:207 259:208 260:209 261:210 262:211 263:212 264:212 265:213 266:214 267:214 268:215 269:216 270:217 271:218 272:219 273:220 274:221 275:222 276:223 277:224 278:225 279:225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.656285 140073664845568 tf_logging.py:115] token_is_max_context: 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2040 4632 27605 7096 2098 1996 3142 2653 1029 102 1996 5879 5321 2018 1037 2350 2576 1010 3451 1998 2510 4254 2006 5781 2885 1998 2130 1996 2379 2264 1012 1996 5879 2015 2020 15607 2005 2037 7761 4382 1998 2776 2005 2037 3017 11345 3723 1010 3352 16258 21576 2015 1997 1996 3234 26582 2046 2029 2027 4632 27605 13776 1012 2027 4233 1996 25624 1011 7472 2653 1997 1996 26165 2455 2027 3876 1010 2037 9329 3352 2124 2004 5879 1010 20692 8630 2030 5879 2413 1010 2019 2590 4706 2653 1012 1996 11068 1997 13298 1010 2029 2027 2719 2011 5036 2007 1996 2413 4410 1010 2001 1037 2307 10882 12879 1997 5781 2605 1010 1998 2104 2957 1045 1997 13298 2001 16158 2046 1037 2522 21579 1998 18085 18018 1999 16708 7470 1012 1996 5879 2015 2024 3264 2119 2005 2037 3226 1010 2107 2004 2037 4310 17135 4294 1998 3315 7443 1010 1998 2005 2037 3278 2510 17571 1998 15463 1012 5879 29506 2015 2631 1996 2983 1997 12071 2104 5074 2462 2044 16152 2075 2670 3304 2006 1996 7354 19023 1998 8734 2015 1010 1998 2019 5590 2006 6852 1997 2037 3804 1010 2520 1996 25466 1010 2419 2000 1996 5879 9187 1997 2563 2012 1996 2645 1997 12296 1999 10114 2575 1012 5879 3451 1998 2510 3747 3659 2013 2122 2047 2647 8941 2000 1996 25237 2163 1997 1996 2379 2264 1010 2073 2037 3159 8945 29122 15422 1045 2631 1996 18018 1997 19078 1999 1996 24485 1010 2000 3885 1998 3575 1999 2307 3725 1010 2000 3163 1010 1998 2000 1996 20266 1997 2167 3088 1998 1996 17154 3470 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.657188 140073664845568 tf_logging.py:115] input_ids: 101 2040 4632 27605 7096 2098 1996 3142 2653 1029 102 1996 5879 5321 2018 1037 2350 2576 1010 3451 1998 2510 4254 2006 5781 2885 1998 2130 1996 2379 2264 1012 1996 5879 2015 2020 15607 2005 2037 7761 4382 1998 2776 2005 2037 3017 11345 3723 1010 3352 16258 21576 2015 1997 1996 3234 26582 2046 2029 2027 4632 27605 13776 1012 2027 4233 1996 25624 1011 7472 2653 1997 1996 26165 2455 2027 3876 1010 2037 9329 3352 2124 2004 5879 1010 20692 8630 2030 5879 2413 1010 2019 2590 4706 2653 1012 1996 11068 1997 13298 1010 2029 2027 2719 2011 5036 2007 1996 2413 4410 1010 2001 1037 2307 10882 12879 1997 5781 2605 1010 1998 2104 2957 1045 1997 13298 2001 16158 2046 1037 2522 21579 1998 18085 18018 1999 16708 7470 1012 1996 5879 2015 2024 3264 2119 2005 2037 3226 1010 2107 2004 2037 4310 17135 4294 1998 3315 7443 1010 1998 2005 2037 3278 2510 17571 1998 15463 1012 5879 29506 2015 2631 1996 2983 1997 12071 2104 5074 2462 2044 16152 2075 2670 3304 2006 1996 7354 19023 1998 8734 2015 1010 1998 2019 5590 2006 6852 1997 2037 3804 1010 2520 1996 25466 1010 2419 2000 1996 5879 9187 1997 2563 2012 1996 2645 1997 12296 1999 10114 2575 1012 5879 3451 1998 2510 3747 3659 2013 2122 2047 2647 8941 2000 1996 25237 2163 1997 1996 2379 2264 1010 2073 2037 3159 8945 29122 15422 1045 2631 1996 18018 1997 19078 1999 1996 24485 1010 2000 3885 1998 3575 1999 2307 3725 1010 2000 3163 1010 1998 2000 1996 20266 1997 2167 3088 1998 1996 17154 3470 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.658076 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.658922 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.665259 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.666524 140073664845568 tf_logging.py:115] unique_id: 1000000015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.667322 140073664845568 tf_logging.py:115] example_index: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.668104 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] who ruled the country of normandy ? [SEP] the norman dynasty had a major political , cultural and military impact on medieval europe and even the near east . the norman ##s were famed for their martial spirit and eventually for their christian pie ##ty , becoming expo ##nent ##s of the catholic orthodoxy into which they ass ##imi ##lated . they adopted the gallo - romance language of the frankish land they settled , their dialect becoming known as norman , norma ##und or norman french , an important literary language . the duchy of normandy , which they formed by treaty with the french crown , was a great fi ##ef of medieval france , and under richard i of normandy was forged into a co ##hesive and formidable principality in feudal tenure . the norman ##s are noted both for their culture , such as their unique romanesque architecture and musical traditions , and for their significant military accomplishments and innovations . norman adventurer ##s founded the kingdom of sicily under roger ii after conquer ##ing southern italy on the sara ##cens and byzantine ##s , and an expedition on behalf of their duke , william the conqueror , led to the norman conquest of england at the battle of hastings in 106 ##6 . norman cultural and military influence spread from these new european centres to the crusader states of the near east , where their prince bo ##hem ##ond i founded the principality of antioch in the levant , to scotland and wales in great britain , to ireland , and to the coasts of north africa and the canary islands . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.668951 140073664845568 tf_logging.py:115] tokens: [CLS] who ruled the country of normandy ? [SEP] the norman dynasty had a major political , cultural and military impact on medieval europe and even the near east . the norman ##s were famed for their martial spirit and eventually for their christian pie ##ty , becoming expo ##nent ##s of the catholic orthodoxy into which they ass ##imi ##lated . they adopted the gallo - romance language of the frankish land they settled , their dialect becoming known as norman , norma ##und or norman french , an important literary language . the duchy of normandy , which they formed by treaty with the french crown , was a great fi ##ef of medieval france , and under richard i of normandy was forged into a co ##hesive and formidable principality in feudal tenure . the norman ##s are noted both for their culture , such as their unique romanesque architecture and musical traditions , and for their significant military accomplishments and innovations . norman adventurer ##s founded the kingdom of sicily under roger ii after conquer ##ing southern italy on the sara ##cens and byzantine ##s , and an expedition on behalf of their duke , william the conqueror , led to the norman conquest of england at the battle of hastings in 106 ##6 . norman cultural and military influence spread from these new european centres to the crusader states of the near east , where their prince bo ##hem ##ond i founded the principality of antioch in the levant , to scotland and wales in great britain , to ireland , and to the coasts of north africa and the canary islands . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 9:0 10:1 11:2 12:3 13:4 14:5 15:6 16:6 17:7 18:8 19:9 20:10 21:11 22:12 23:13 24:14 25:15 26:16 27:17 28:18 29:18 30:19 31:20 32:20 33:21 34:22 35:23 36:24 37:25 38:26 39:27 40:28 41:29 42:30 43:31 44:32 45:32 46:32 47:33 48:34 49:34 50:34 51:35 52:36 53:37 54:38 55:39 56:40 57:41 58:42 59:42 60:42 61:42 62:43 63:44 64:45 65:46 66:46 67:46 68:47 69:48 70:49 71:50 72:51 73:52 74:53 75:53 76:54 77:55 78:56 79:57 80:58 81:59 82:59 83:60 84:60 85:61 86:62 87:63 88:63 89:64 90:65 91:66 92:67 93:67 94:68 95:69 96:70 97:71 98:71 99:72 100:73 101:74 102:75 103:76 104:77 105:78 106:79 107:80 108:80 109:81 110:82 111:83 112:84 113:84 114:85 115:86 116:87 117:87 118:88 119:89 120:90 121:91 122:92 123:93 124:94 125:95 126:96 127:97 128:98 129:98 130:99 131:100 132:101 133:102 134:103 135:104 136:104 137:105 138:106 139:106 140:107 141:108 142:109 143:110 144:111 145:112 146:112 147:113 148:114 149:115 150:116 151:117 152:118 153:119 154:120 155:121 156:121 157:122 158:123 159:124 160:125 161:126 162:127 163:128 164:129 165:129 166:130 167:131 168:131 169:132 170:133 171:134 172:135 173:136 174:137 175:138 176:139 177:140 178:141 179:141 180:142 181:143 182:144 183:145 184:146 185:146 186:147 187:148 188:148 189:148 190:149 191:150 192:151 193:152 194:153 195:154 196:155 197:156 198:156 199:157 200:158 201:159 202:159 203:160 204:161 205:162 206:163 207:164 208:165 209:166 210:167 211:168 212:169 213:170 214:171 215:172 216:173 217:173 218:173 219:174 220:175 221:176 222:177 223:178 224:179 225:180 226:181 227:182 228:183 229:184 230:185 231:186 232:187 233:188 234:189 235:190 236:191 237:192 238:192 239:193 240:194 241:195 242:196 243:196 244:196 245:197 246:198 247:199 248:200 249:201 250:202 251:203 252:204 253:205 254:205 255:206 256:207 257:208 258:209 259:210 260:211 261:212 262:212 263:213 264:214 265:214 266:215 267:216 268:217 269:218 270:219 271:220 272:221 273:222 274:223 275:224 276:225 277:225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.669827 140073664845568 tf_logging.py:115] token_to_orig_map: 9:0 10:1 11:2 12:3 13:4 14:5 15:6 16:6 17:7 18:8 19:9 20:10 21:11 22:12 23:13 24:14 25:15 26:16 27:17 28:18 29:18 30:19 31:20 32:20 33:21 34:22 35:23 36:24 37:25 38:26 39:27 40:28 41:29 42:30 43:31 44:32 45:32 46:32 47:33 48:34 49:34 50:34 51:35 52:36 53:37 54:38 55:39 56:40 57:41 58:42 59:42 60:42 61:42 62:43 63:44 64:45 65:46 66:46 67:46 68:47 69:48 70:49 71:50 72:51 73:52 74:53 75:53 76:54 77:55 78:56 79:57 80:58 81:59 82:59 83:60 84:60 85:61 86:62 87:63 88:63 89:64 90:65 91:66 92:67 93:67 94:68 95:69 96:70 97:71 98:71 99:72 100:73 101:74 102:75 103:76 104:77 105:78 106:79 107:80 108:80 109:81 110:82 111:83 112:84 113:84 114:85 115:86 116:87 117:87 118:88 119:89 120:90 121:91 122:92 123:93 124:94 125:95 126:96 127:97 128:98 129:98 130:99 131:100 132:101 133:102 134:103 135:104 136:104 137:105 138:106 139:106 140:107 141:108 142:109 143:110 144:111 145:112 146:112 147:113 148:114 149:115 150:116 151:117 152:118 153:119 154:120 155:121 156:121 157:122 158:123 159:124 160:125 161:126 162:127 163:128 164:129 165:129 166:130 167:131 168:131 169:132 170:133 171:134 172:135 173:136 174:137 175:138 176:139 177:140 178:141 179:141 180:142 181:143 182:144 183:145 184:146 185:146 186:147 187:148 188:148 189:148 190:149 191:150 192:151 193:152 194:153 195:154 196:155 197:156 198:156 199:157 200:158 201:159 202:159 203:160 204:161 205:162 206:163 207:164 208:165 209:166 210:167 211:168 212:169 213:170 214:171 215:172 216:173 217:173 218:173 219:174 220:175 221:176 222:177 223:178 224:179 225:180 226:181 227:182 228:183 229:184 230:185 231:186 232:187 233:188 234:189 235:190 236:191 237:192 238:192 239:193 240:194 241:195 242:196 243:196 244:196 245:197 246:198 247:199 248:200 249:201 250:202 251:203 252:204 253:205 254:205 255:206 256:207 257:208 258:209 259:210 260:211 261:212 262:212 263:213 264:214 265:214 266:215 267:216 268:217 269:218 270:219 271:220 272:221 273:222 274:223 275:224 276:225 277:225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.670706 140073664845568 tf_logging.py:115] token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2040 5451 1996 2406 1997 13298 1029 102 1996 5879 5321 2018 1037 2350 2576 1010 3451 1998 2510 4254 2006 5781 2885 1998 2130 1996 2379 2264 1012 1996 5879 2015 2020 15607 2005 2037 7761 4382 1998 2776 2005 2037 3017 11345 3723 1010 3352 16258 21576 2015 1997 1996 3234 26582 2046 2029 2027 4632 27605 13776 1012 2027 4233 1996 25624 1011 7472 2653 1997 1996 26165 2455 2027 3876 1010 2037 9329 3352 2124 2004 5879 1010 20692 8630 2030 5879 2413 1010 2019 2590 4706 2653 1012 1996 11068 1997 13298 1010 2029 2027 2719 2011 5036 2007 1996 2413 4410 1010 2001 1037 2307 10882 12879 1997 5781 2605 1010 1998 2104 2957 1045 1997 13298 2001 16158 2046 1037 2522 21579 1998 18085 18018 1999 16708 7470 1012 1996 5879 2015 2024 3264 2119 2005 2037 3226 1010 2107 2004 2037 4310 17135 4294 1998 3315 7443 1010 1998 2005 2037 3278 2510 17571 1998 15463 1012 5879 29506 2015 2631 1996 2983 1997 12071 2104 5074 2462 2044 16152 2075 2670 3304 2006 1996 7354 19023 1998 8734 2015 1010 1998 2019 5590 2006 6852 1997 2037 3804 1010 2520 1996 25466 1010 2419 2000 1996 5879 9187 1997 2563 2012 1996 2645 1997 12296 1999 10114 2575 1012 5879 3451 1998 2510 3747 3659 2013 2122 2047 2647 8941 2000 1996 25237 2163 1997 1996 2379 2264 1010 2073 2037 3159 8945 29122 15422 1045 2631 1996 18018 1997 19078 1999 1996 24485 1010 2000 3885 1998 3575 1999 2307 3725 1010 2000 3163 1010 1998 2000 1996 20266 1997 2167 3088 1998 1996 17154 3470 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.671610 140073664845568 tf_logging.py:115] input_ids: 101 2040 5451 1996 2406 1997 13298 1029 102 1996 5879 5321 2018 1037 2350 2576 1010 3451 1998 2510 4254 2006 5781 2885 1998 2130 1996 2379 2264 1012 1996 5879 2015 2020 15607 2005 2037 7761 4382 1998 2776 2005 2037 3017 11345 3723 1010 3352 16258 21576 2015 1997 1996 3234 26582 2046 2029 2027 4632 27605 13776 1012 2027 4233 1996 25624 1011 7472 2653 1997 1996 26165 2455 2027 3876 1010 2037 9329 3352 2124 2004 5879 1010 20692 8630 2030 5879 2413 1010 2019 2590 4706 2653 1012 1996 11068 1997 13298 1010 2029 2027 2719 2011 5036 2007 1996 2413 4410 1010 2001 1037 2307 10882 12879 1997 5781 2605 1010 1998 2104 2957 1045 1997 13298 2001 16158 2046 1037 2522 21579 1998 18085 18018 1999 16708 7470 1012 1996 5879 2015 2024 3264 2119 2005 2037 3226 1010 2107 2004 2037 4310 17135 4294 1998 3315 7443 1010 1998 2005 2037 3278 2510 17571 1998 15463 1012 5879 29506 2015 2631 1996 2983 1997 12071 2104 5074 2462 2044 16152 2075 2670 3304 2006 1996 7354 19023 1998 8734 2015 1010 1998 2019 5590 2006 6852 1997 2037 3804 1010 2520 1996 25466 1010 2419 2000 1996 5879 9187 1997 2563 2012 1996 2645 1997 12296 1999 10114 2575 1012 5879 3451 1998 2510 3747 3659 2013 2122 2047 2647 8941 2000 1996 25237 2163 1997 1996 2379 2264 1010 2073 2037 3159 8945 29122 15422 1045 2631 1996 18018 1997 19078 1999 1996 24485 1010 2000 3885 1998 3575 1999 2307 3725 1010 2000 3163 1010 1998 2000 1996 20266 1997 2167 3088 1998 1996 17154 3470 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.672503 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.673371 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.679864 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.680914 140073664845568 tf_logging.py:115] unique_id: 1000000016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.681978 140073664845568 tf_logging.py:115] example_index: 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.682893 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] what principality did william the conquer ##er found ? [SEP] the norman dynasty had a major political , cultural and military impact on medieval europe and even the near east . the norman ##s were famed for their martial spirit and eventually for their christian pie ##ty , becoming expo ##nent ##s of the catholic orthodoxy into which they ass ##imi ##lated . they adopted the gallo - romance language of the frankish land they settled , their dialect becoming known as norman , norma ##und or norman french , an important literary language . the duchy of normandy , which they formed by treaty with the french crown , was a great fi ##ef of medieval france , and under richard i of normandy was forged into a co ##hesive and formidable principality in feudal tenure . the norman ##s are noted both for their culture , such as their unique romanesque architecture and musical traditions , and for their significant military accomplishments and innovations . norman adventurer ##s founded the kingdom of sicily under roger ii after conquer ##ing southern italy on the sara ##cens and byzantine ##s , and an expedition on behalf of their duke , william the conqueror , led to the norman conquest of england at the battle of hastings in 106 ##6 . norman cultural and military influence spread from these new european centres to the crusader states of the near east , where their prince bo ##hem ##ond i founded the principality of antioch in the levant , to scotland and wales in great britain , to ireland , and to the coasts of north africa and the canary islands . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.684062 140073664845568 tf_logging.py:115] tokens: [CLS] what principality did william the conquer ##er found ? [SEP] the norman dynasty had a major political , cultural and military impact on medieval europe and even the near east . the norman ##s were famed for their martial spirit and eventually for their christian pie ##ty , becoming expo ##nent ##s of the catholic orthodoxy into which they ass ##imi ##lated . they adopted the gallo - romance language of the frankish land they settled , their dialect becoming known as norman , norma ##und or norman french , an important literary language . the duchy of normandy , which they formed by treaty with the french crown , was a great fi ##ef of medieval france , and under richard i of normandy was forged into a co ##hesive and formidable principality in feudal tenure . the norman ##s are noted both for their culture , such as their unique romanesque architecture and musical traditions , and for their significant military accomplishments and innovations . norman adventurer ##s founded the kingdom of sicily under roger ii after conquer ##ing southern italy on the sara ##cens and byzantine ##s , and an expedition on behalf of their duke , william the conqueror , led to the norman conquest of england at the battle of hastings in 106 ##6 . norman cultural and military influence spread from these new european centres to the crusader states of the near east , where their prince bo ##hem ##ond i founded the principality of antioch in the levant , to scotland and wales in great britain , to ireland , and to the coasts of north africa and the canary islands . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 11:0 12:1 13:2 14:3 15:4 16:5 17:6 18:6 19:7 20:8 21:9 22:10 23:11 24:12 25:13 26:14 27:15 28:16 29:17 30:18 31:18 32:19 33:20 34:20 35:21 36:22 37:23 38:24 39:25 40:26 41:27 42:28 43:29 44:30 45:31 46:32 47:32 48:32 49:33 50:34 51:34 52:34 53:35 54:36 55:37 56:38 57:39 58:40 59:41 60:42 61:42 62:42 63:42 64:43 65:44 66:45 67:46 68:46 69:46 70:47 71:48 72:49 73:50 74:51 75:52 76:53 77:53 78:54 79:55 80:56 81:57 82:58 83:59 84:59 85:60 86:60 87:61 88:62 89:63 90:63 91:64 92:65 93:66 94:67 95:67 96:68 97:69 98:70 99:71 100:71 101:72 102:73 103:74 104:75 105:76 106:77 107:78 108:79 109:80 110:80 111:81 112:82 113:83 114:84 115:84 116:85 117:86 118:87 119:87 120:88 121:89 122:90 123:91 124:92 125:93 126:94 127:95 128:96 129:97 130:98 131:98 132:99 133:100 134:101 135:102 136:103 137:104 138:104 139:105 140:106 141:106 142:107 143:108 144:109 145:110 146:111 147:112 148:112 149:113 150:114 151:115 152:116 153:117 154:118 155:119 156:120 157:121 158:121 159:122 160:123 161:124 162:125 163:126 164:127 165:128 166:129 167:129 168:130 169:131 170:131 171:132 172:133 173:134 174:135 175:136 176:137 177:138 178:139 179:140 180:141 181:141 182:142 183:143 184:144 185:145 186:146 187:146 188:147 189:148 190:148 191:148 192:149 193:150 194:151 195:152 196:153 197:154 198:155 199:156 200:156 201:157 202:158 203:159 204:159 205:160 206:161 207:162 208:163 209:164 210:165 211:166 212:167 213:168 214:169 215:170 216:171 217:172 218:173 219:173 220:173 221:174 222:175 223:176 224:177 225:178 226:179 227:180 228:181 229:182 230:183 231:184 232:185 233:186 234:187 235:188 236:189 237:190 238:191 239:192 240:192 241:193 242:194 243:195 244:196 245:196 246:196 247:197 248:198 249:199 250:200 251:201 252:202 253:203 254:204 255:205 256:205 257:206 258:207 259:208 260:209 261:210 262:211 263:212 264:212 265:213 266:214 267:214 268:215 269:216 270:217 271:218 272:219 273:220 274:221 275:222 276:223 277:224 278:225 279:225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.685392 140073664845568 tf_logging.py:115] token_to_orig_map: 11:0 12:1 13:2 14:3 15:4 16:5 17:6 18:6 19:7 20:8 21:9 22:10 23:11 24:12 25:13 26:14 27:15 28:16 29:17 30:18 31:18 32:19 33:20 34:20 35:21 36:22 37:23 38:24 39:25 40:26 41:27 42:28 43:29 44:30 45:31 46:32 47:32 48:32 49:33 50:34 51:34 52:34 53:35 54:36 55:37 56:38 57:39 58:40 59:41 60:42 61:42 62:42 63:42 64:43 65:44 66:45 67:46 68:46 69:46 70:47 71:48 72:49 73:50 74:51 75:52 76:53 77:53 78:54 79:55 80:56 81:57 82:58 83:59 84:59 85:60 86:60 87:61 88:62 89:63 90:63 91:64 92:65 93:66 94:67 95:67 96:68 97:69 98:70 99:71 100:71 101:72 102:73 103:74 104:75 105:76 106:77 107:78 108:79 109:80 110:80 111:81 112:82 113:83 114:84 115:84 116:85 117:86 118:87 119:87 120:88 121:89 122:90 123:91 124:92 125:93 126:94 127:95 128:96 129:97 130:98 131:98 132:99 133:100 134:101 135:102 136:103 137:104 138:104 139:105 140:106 141:106 142:107 143:108 144:109 145:110 146:111 147:112 148:112 149:113 150:114 151:115 152:116 153:117 154:118 155:119 156:120 157:121 158:121 159:122 160:123 161:124 162:125 163:126 164:127 165:128 166:129 167:129 168:130 169:131 170:131 171:132 172:133 173:134 174:135 175:136 176:137 177:138 178:139 179:140 180:141 181:141 182:142 183:143 184:144 185:145 186:146 187:146 188:147 189:148 190:148 191:148 192:149 193:150 194:151 195:152 196:153 197:154 198:155 199:156 200:156 201:157 202:158 203:159 204:159 205:160 206:161 207:162 208:163 209:164 210:165 211:166 212:167 213:168 214:169 215:170 216:171 217:172 218:173 219:173 220:173 221:174 222:175 223:176 224:177 225:178 226:179 227:180 228:181 229:182 230:183 231:184 232:185 233:186 234:187 235:188 236:189 237:190 238:191 239:192 240:192 241:193 242:194 243:195 244:196 245:196 246:196 247:197 248:198 249:199 250:200 251:201 252:202 253:203 254:204 255:205 256:205 257:206 258:207 259:208 260:209 261:210 262:211 263:212 264:212 265:213 266:214 267:214 268:215 269:216 270:217 271:218 272:219 273:220 274:221 275:222 276:223 277:224 278:225 279:225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.686789 140073664845568 tf_logging.py:115] token_is_max_context: 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2054 18018 2106 2520 1996 16152 2121 2179 1029 102 1996 5879 5321 2018 1037 2350 2576 1010 3451 1998 2510 4254 2006 5781 2885 1998 2130 1996 2379 2264 1012 1996 5879 2015 2020 15607 2005 2037 7761 4382 1998 2776 2005 2037 3017 11345 3723 1010 3352 16258 21576 2015 1997 1996 3234 26582 2046 2029 2027 4632 27605 13776 1012 2027 4233 1996 25624 1011 7472 2653 1997 1996 26165 2455 2027 3876 1010 2037 9329 3352 2124 2004 5879 1010 20692 8630 2030 5879 2413 1010 2019 2590 4706 2653 1012 1996 11068 1997 13298 1010 2029 2027 2719 2011 5036 2007 1996 2413 4410 1010 2001 1037 2307 10882 12879 1997 5781 2605 1010 1998 2104 2957 1045 1997 13298 2001 16158 2046 1037 2522 21579 1998 18085 18018 1999 16708 7470 1012 1996 5879 2015 2024 3264 2119 2005 2037 3226 1010 2107 2004 2037 4310 17135 4294 1998 3315 7443 1010 1998 2005 2037 3278 2510 17571 1998 15463 1012 5879 29506 2015 2631 1996 2983 1997 12071 2104 5074 2462 2044 16152 2075 2670 3304 2006 1996 7354 19023 1998 8734 2015 1010 1998 2019 5590 2006 6852 1997 2037 3804 1010 2520 1996 25466 1010 2419 2000 1996 5879 9187 1997 2563 2012 1996 2645 1997 12296 1999 10114 2575 1012 5879 3451 1998 2510 3747 3659 2013 2122 2047 2647 8941 2000 1996 25237 2163 1997 1996 2379 2264 1010 2073 2037 3159 8945 29122 15422 1045 2631 1996 18018 1997 19078 1999 1996 24485 1010 2000 3885 1998 3575 1999 2307 3725 1010 2000 3163 1010 1998 2000 1996 20266 1997 2167 3088 1998 1996 17154 3470 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.688057 140073664845568 tf_logging.py:115] input_ids: 101 2054 18018 2106 2520 1996 16152 2121 2179 1029 102 1996 5879 5321 2018 1037 2350 2576 1010 3451 1998 2510 4254 2006 5781 2885 1998 2130 1996 2379 2264 1012 1996 5879 2015 2020 15607 2005 2037 7761 4382 1998 2776 2005 2037 3017 11345 3723 1010 3352 16258 21576 2015 1997 1996 3234 26582 2046 2029 2027 4632 27605 13776 1012 2027 4233 1996 25624 1011 7472 2653 1997 1996 26165 2455 2027 3876 1010 2037 9329 3352 2124 2004 5879 1010 20692 8630 2030 5879 2413 1010 2019 2590 4706 2653 1012 1996 11068 1997 13298 1010 2029 2027 2719 2011 5036 2007 1996 2413 4410 1010 2001 1037 2307 10882 12879 1997 5781 2605 1010 1998 2104 2957 1045 1997 13298 2001 16158 2046 1037 2522 21579 1998 18085 18018 1999 16708 7470 1012 1996 5879 2015 2024 3264 2119 2005 2037 3226 1010 2107 2004 2037 4310 17135 4294 1998 3315 7443 1010 1998 2005 2037 3278 2510 17571 1998 15463 1012 5879 29506 2015 2631 1996 2983 1997 12071 2104 5074 2462 2044 16152 2075 2670 3304 2006 1996 7354 19023 1998 8734 2015 1010 1998 2019 5590 2006 6852 1997 2037 3804 1010 2520 1996 25466 1010 2419 2000 1996 5879 9187 1997 2563 2012 1996 2645 1997 12296 1999 10114 2575 1012 5879 3451 1998 2510 3747 3659 2013 2122 2047 2647 8941 2000 1996 25237 2163 1997 1996 2379 2264 1010 2073 2037 3159 8945 29122 15422 1045 2631 1996 18018 1997 19078 1999 1996 24485 1010 2000 3885 1998 3575 1999 2307 3725 1010 2000 3163 1010 1998 2000 1996 20266 1997 2167 3088 1998 1996 17154 3470 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.689121 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.690289 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.693680 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.694737 140073664845568 tf_logging.py:115] unique_id: 1000000017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.695657 140073664845568 tf_logging.py:115] example_index: 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.696472 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] what is the original meaning of the word norman ? [SEP] the english name \" norman ##s \" comes from the french words norman ##s / norman ##z , plural of norman ##t , modern french norman ##d , which is itself borrowed from old low franco ##nian nor ##tman ##n \" north ##man \" or directly from old norse nor ## ##ma ## ##r , latin ##ized variously as nor ##tman ##nus , norman ##nus , or nord ##mann ##us ( recorded in medieval latin , 9th century ) to mean \" norse ##man , viking \" . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.697427 140073664845568 tf_logging.py:115] tokens: [CLS] what is the original meaning of the word norman ? [SEP] the english name \" norman ##s \" comes from the french words norman ##s / norman ##z , plural of norman ##t , modern french norman ##d , which is itself borrowed from old low franco ##nian nor ##tman ##n \" north ##man \" or directly from old norse nor ## ##ma ## ##r , latin ##ized variously as nor ##tman ##nus , norman ##nus , or nord ##mann ##us ( recorded in medieval latin , 9th century ) to mean \" norse ##man , viking \" . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 12:0 13:1 14:2 15:3 16:3 17:3 18:3 19:4 20:5 21:6 22:7 23:8 24:9 25:9 26:9 27:9 28:9 29:9 30:10 31:11 32:12 33:12 34:12 35:13 36:14 37:15 38:15 39:15 40:16 41:17 42:18 43:19 44:20 45:21 46:22 47:23 48:23 49:24 50:24 51:24 52:25 53:25 54:25 55:25 56:26 57:27 58:28 59:29 60:30 61:31 62:31 63:31 64:31 65:31 66:31 67:32 68:32 69:33 70:34 71:35 72:35 73:35 74:35 75:36 76:36 77:36 78:37 79:38 80:38 81:38 82:39 83:39 84:40 85:41 86:42 87:42 88:43 89:44 90:44 91:45 92:46 93:47 94:47 95:47 96:47 97:48 98:48 99:48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.698452 140073664845568 tf_logging.py:115] token_to_orig_map: 12:0 13:1 14:2 15:3 16:3 17:3 18:3 19:4 20:5 21:6 22:7 23:8 24:9 25:9 26:9 27:9 28:9 29:9 30:10 31:11 32:12 33:12 34:12 35:13 36:14 37:15 38:15 39:15 40:16 41:17 42:18 43:19 44:20 45:21 46:22 47:23 48:23 49:24 50:24 51:24 52:25 53:25 54:25 55:25 56:26 57:27 58:28 59:29 60:30 61:31 62:31 63:31 64:31 65:31 66:31 67:32 68:32 69:33 70:34 71:35 72:35 73:35 74:35 75:36 76:36 77:36 78:37 79:38 80:38 81:38 82:39 83:39 84:40 85:41 86:42 87:42 88:43 89:44 90:44 91:45 92:46 93:47 94:47 95:47 96:47 97:48 98:48 99:48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.699588 140073664845568 tf_logging.py:115] token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2054 2003 1996 2434 3574 1997 1996 2773 5879 1029 102 1996 2394 2171 1000 5879 2015 1000 3310 2013 1996 2413 2616 5879 2015 1013 5879 2480 1010 13994 1997 5879 2102 1010 2715 2413 5879 2094 1010 2029 2003 2993 11780 2013 2214 2659 9341 11148 4496 22942 2078 1000 2167 2386 1000 2030 3495 2013 2214 15342 4496 29668 2863 29668 2099 1010 3763 3550 17611 2004 4496 22942 10182 1010 5879 10182 1010 2030 13926 5804 2271 1006 2680 1999 5781 3763 1010 6280 2301 1007 2000 2812 1000 15342 2386 1010 12886 1000 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.700528 140073664845568 tf_logging.py:115] input_ids: 101 2054 2003 1996 2434 3574 1997 1996 2773 5879 1029 102 1996 2394 2171 1000 5879 2015 1000 3310 2013 1996 2413 2616 5879 2015 1013 5879 2480 1010 13994 1997 5879 2102 1010 2715 2413 5879 2094 1010 2029 2003 2993 11780 2013 2214 2659 9341 11148 4496 22942 2078 1000 2167 2386 1000 2030 3495 2013 2214 15342 4496 29668 2863 29668 2099 1010 3763 3550 17611 2004 4496 22942 10182 1010 5879 10182 1010 2030 13926 5804 2271 1006 2680 1999 5781 3763 1010 6280 2301 1007 2000 2812 1000 15342 2386 1010 12886 1000 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.701428 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.702497 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.705597 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.706604 140073664845568 tf_logging.py:115] unique_id: 1000000018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.707611 140073664845568 tf_logging.py:115] example_index: 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.708414 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] when was the latin version of the word norman first recorded ? [SEP] the english name \" norman ##s \" comes from the french words norman ##s / norman ##z , plural of norman ##t , modern french norman ##d , which is itself borrowed from old low franco ##nian nor ##tman ##n \" north ##man \" or directly from old norse nor ## ##ma ## ##r , latin ##ized variously as nor ##tman ##nus , norman ##nus , or nord ##mann ##us ( recorded in medieval latin , 9th century ) to mean \" norse ##man , viking \" . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.709378 140073664845568 tf_logging.py:115] tokens: [CLS] when was the latin version of the word norman first recorded ? [SEP] the english name \" norman ##s \" comes from the french words norman ##s / norman ##z , plural of norman ##t , modern french norman ##d , which is itself borrowed from old low franco ##nian nor ##tman ##n \" north ##man \" or directly from old norse nor ## ##ma ## ##r , latin ##ized variously as nor ##tman ##nus , norman ##nus , or nord ##mann ##us ( recorded in medieval latin , 9th century ) to mean \" norse ##man , viking \" . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 14:0 15:1 16:2 17:3 18:3 19:3 20:3 21:4 22:5 23:6 24:7 25:8 26:9 27:9 28:9 29:9 30:9 31:9 32:10 33:11 34:12 35:12 36:12 37:13 38:14 39:15 40:15 41:15 42:16 43:17 44:18 45:19 46:20 47:21 48:22 49:23 50:23 51:24 52:24 53:24 54:25 55:25 56:25 57:25 58:26 59:27 60:28 61:29 62:30 63:31 64:31 65:31 66:31 67:31 68:31 69:32 70:32 71:33 72:34 73:35 74:35 75:35 76:35 77:36 78:36 79:36 80:37 81:38 82:38 83:38 84:39 85:39 86:40 87:41 88:42 89:42 90:43 91:44 92:44 93:45 94:46 95:47 96:47 97:47 98:47 99:48 100:48 101:48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.710617 140073664845568 tf_logging.py:115] token_to_orig_map: 14:0 15:1 16:2 17:3 18:3 19:3 20:3 21:4 22:5 23:6 24:7 25:8 26:9 27:9 28:9 29:9 30:9 31:9 32:10 33:11 34:12 35:12 36:12 37:13 38:14 39:15 40:15 41:15 42:16 43:17 44:18 45:19 46:20 47:21 48:22 49:23 50:23 51:24 52:24 53:24 54:25 55:25 56:25 57:25 58:26 59:27 60:28 61:29 62:30 63:31 64:31 65:31 66:31 67:31 68:31 69:32 70:32 71:33 72:34 73:35 74:35 75:35 76:35 77:36 78:36 79:36 80:37 81:38 82:38 83:38 84:39 85:39 86:40 87:41 88:42 89:42 90:43 91:44 92:44 93:45 94:46 95:47 96:47 97:47 98:47 99:48 100:48 101:48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.711462 140073664845568 tf_logging.py:115] token_is_max_context: 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2043 2001 1996 3763 2544 1997 1996 2773 5879 2034 2680 1029 102 1996 2394 2171 1000 5879 2015 1000 3310 2013 1996 2413 2616 5879 2015 1013 5879 2480 1010 13994 1997 5879 2102 1010 2715 2413 5879 2094 1010 2029 2003 2993 11780 2013 2214 2659 9341 11148 4496 22942 2078 1000 2167 2386 1000 2030 3495 2013 2214 15342 4496 29668 2863 29668 2099 1010 3763 3550 17611 2004 4496 22942 10182 1010 5879 10182 1010 2030 13926 5804 2271 1006 2680 1999 5781 3763 1010 6280 2301 1007 2000 2812 1000 15342 2386 1010 12886 1000 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.712491 140073664845568 tf_logging.py:115] input_ids: 101 2043 2001 1996 3763 2544 1997 1996 2773 5879 2034 2680 1029 102 1996 2394 2171 1000 5879 2015 1000 3310 2013 1996 2413 2616 5879 2015 1013 5879 2480 1010 13994 1997 5879 2102 1010 2715 2413 5879 2094 1010 2029 2003 2993 11780 2013 2214 2659 9341 11148 4496 22942 2078 1000 2167 2386 1000 2030 3495 2013 2214 15342 4496 29668 2863 29668 2099 1010 3763 3550 17611 2004 4496 22942 10182 1010 5879 10182 1010 2030 13926 5804 2271 1006 2680 1999 5781 3763 1010 6280 2301 1007 2000 2812 1000 15342 2386 1010 12886 1000 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.713549 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.714549 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.717643 140073664845568 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:unique_id: 1000000019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.718831 140073664845568 tf_logging.py:115] unique_id: 1000000019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:example_index: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.719957 140073664845568 tf_logging.py:115] example_index: 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:doc_span_index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.720940 140073664845568 tf_logging.py:115] doc_span_index: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] what name comes from the english words norman ##s / norman ##z ? [SEP] the english name \" norman ##s \" comes from the french words norman ##s / norman ##z , plural of norman ##t , modern french norman ##d , which is itself borrowed from old low franco ##nian nor ##tman ##n \" north ##man \" or directly from old norse nor ## ##ma ## ##r , latin ##ized variously as nor ##tman ##nus , norman ##nus , or nord ##mann ##us ( recorded in medieval latin , 9th century ) to mean \" norse ##man , viking \" . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.721980 140073664845568 tf_logging.py:115] tokens: [CLS] what name comes from the english words norman ##s / norman ##z ? [SEP] the english name \" norman ##s \" comes from the french words norman ##s / norman ##z , plural of norman ##t , modern french norman ##d , which is itself borrowed from old low franco ##nian nor ##tman ##n \" north ##man \" or directly from old norse nor ## ##ma ## ##r , latin ##ized variously as nor ##tman ##nus , norman ##nus , or nord ##mann ##us ( recorded in medieval latin , 9th century ) to mean \" norse ##man , viking \" . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_to_orig_map: 15:0 16:1 17:2 18:3 19:3 20:3 21:3 22:4 23:5 24:6 25:7 26:8 27:9 28:9 29:9 30:9 31:9 32:9 33:10 34:11 35:12 36:12 37:12 38:13 39:14 40:15 41:15 42:15 43:16 44:17 45:18 46:19 47:20 48:21 49:22 50:23 51:23 52:24 53:24 54:24 55:25 56:25 57:25 58:25 59:26 60:27 61:28 62:29 63:30 64:31 65:31 66:31 67:31 68:31 69:31 70:32 71:32 72:33 73:34 74:35 75:35 76:35 77:35 78:36 79:36 80:36 81:37 82:38 83:38 84:38 85:39 86:39 87:40 88:41 89:42 90:42 91:43 92:44 93:44 94:45 95:46 96:47 97:47 98:47 99:47 100:48 101:48 102:48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.723255 140073664845568 tf_logging.py:115] token_to_orig_map: 15:0 16:1 17:2 18:3 19:3 20:3 21:3 22:4 23:5 24:6 25:7 26:8 27:9 28:9 29:9 30:9 31:9 32:9 33:10 34:11 35:12 36:12 37:12 38:13 39:14 40:15 41:15 42:15 43:16 44:17 45:18 46:19 47:20 48:21 49:22 50:23 51:23 52:24 53:24 54:24 55:25 56:25 57:25 58:25 59:26 60:27 61:28 62:29 63:30 64:31 65:31 66:31 67:31 68:31 69:31 70:32 71:32 72:33 73:34 74:35 75:35 76:35 77:35 78:36 79:36 80:36 81:37 82:38 83:38 84:38 85:39 86:39 87:40 88:41 89:42 90:42 91:43 92:44 93:44 94:45 95:46 96:47 97:47 98:47 99:47 100:48 101:48 102:48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:token_is_max_context: 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.724104 140073664845568 tf_logging.py:115] token_is_max_context: 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2054 2171 3310 2013 1996 2394 2616 5879 2015 1013 5879 2480 1029 102 1996 2394 2171 1000 5879 2015 1000 3310 2013 1996 2413 2616 5879 2015 1013 5879 2480 1010 13994 1997 5879 2102 1010 2715 2413 5879 2094 1010 2029 2003 2993 11780 2013 2214 2659 9341 11148 4496 22942 2078 1000 2167 2386 1000 2030 3495 2013 2214 15342 4496 29668 2863 29668 2099 1010 3763 3550 17611 2004 4496 22942 10182 1010 5879 10182 1010 2030 13926 5804 2271 1006 2680 1999 5781 3763 1010 6280 2301 1007 2000 2812 1000 15342 2386 1010 12886 1000 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.725162 140073664845568 tf_logging.py:115] input_ids: 101 2054 2171 3310 2013 1996 2394 2616 5879 2015 1013 5879 2480 1029 102 1996 2394 2171 1000 5879 2015 1000 3310 2013 1996 2413 2616 5879 2015 1013 5879 2480 1010 13994 1997 5879 2102 1010 2715 2413 5879 2094 1010 2029 2003 2993 11780 2013 2214 2659 9341 11148 4496 22942 2078 1000 2167 2386 1000 2030 3495 2013 2214 15342 4496 29668 2863 29668 2099 1010 3763 3550 17611 2004 4496 22942 10182 1010 5879 10182 1010 2030 13926 5804 2271 1006 2680 1999 5781 3763 1010 6280 2301 1007 2000 2812 1000 15342 2386 1010 12886 1000 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.726297 140073664845568 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:17.727299 140073664845568 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:***** Running predictions *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:59.380409 140073664845568 tf_logging.py:115] ***** Running predictions *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  Num orig examples = 11873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:59.381721 140073664845568 tf_logging.py:115]   Num orig examples = 11873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  Num split examples = 12232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:59.382847 140073664845568 tf_logging.py:115]   Num split examples = 12232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  Batch size = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:59.383727 140073664845568 tf_logging.py:115]   Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:59.411225 140073664845568 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running infer on CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:59.412524 140073664845568 tf_logging.py:115] Running infer on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Features ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:59.414312 140073664845568 tf_logging.py:115] *** Features ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = input_ids, shape = (?, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:59.416674 140073664845568 tf_logging.py:115]   name = input_ids, shape = (?, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = input_mask, shape = (?, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:59.417669 140073664845568 tf_logging.py:115]   name = input_mask, shape = (?, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = segment_ids, shape = (?, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:59.418783 140073664845568 tf_logging.py:115]   name = segment_ids, shape = (?, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = unique_ids, shape = (?,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:42:59.419845 140073664845568 tf_logging.py:115]   name = unique_ids, shape = (?,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/embeddings/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/embeddings/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.673314 140073664845568 tf_logging.py:115] Initialize variable bert/embeddings/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/embeddings/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/embeddings/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/embeddings/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.677891 140073664845568 tf_logging.py:115] Initialize variable bert/embeddings/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/embeddings/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/embeddings/position_embeddings:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/embeddings/position_embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.682230 140073664845568 tf_logging.py:115] Initialize variable bert/embeddings/position_embeddings:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/embeddings/position_embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/embeddings/token_type_embeddings:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/embeddings/token_type_embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.686530 140073664845568 tf_logging.py:115] Initialize variable bert/embeddings/token_type_embeddings:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/embeddings/token_type_embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/embeddings/word_embeddings:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/embeddings/word_embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.690775 140073664845568 tf_logging.py:115] Initialize variable bert/embeddings/word_embeddings:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/embeddings/word_embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_0/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.694984 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_0/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_0/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.699137 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_0/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_0/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.703408 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_0/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_0/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.707576 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_0/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_0/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.711660 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_0/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_0/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.715854 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_0/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_0/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.719968 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_0/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_0/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.724126 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_0/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_0/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.728317 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_0/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_0/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.732555 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_0/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_0/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.737092 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_0/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_0/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.741234 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_0/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_0/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.745425 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_0/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_0/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.749507 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_0/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_0/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.753779 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_0/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_0/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.757881 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_0/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_0/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_1/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.762114 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_1/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_1/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.766283 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_1/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_1/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.770486 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_1/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_1/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.774781 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_1/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_1/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.778872 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_1/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_1/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.783654 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_1/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_1/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.787782 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_1/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_1/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.792086 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_1/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_1/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.796356 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_1/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_1/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.800554 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_1/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_1/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.804660 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_1/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_1/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.808858 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_1/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_1/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.813046 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_1/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_1/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.817140 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_1/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_1/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.821340 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_1/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_1/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.825477 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_1/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_1/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_10/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.829671 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_10/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_10/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.833840 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_10/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_10/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.838066 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_10/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_10/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.842236 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_10/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_10/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.847148 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_10/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_10/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.851230 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_10/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_10/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.855310 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_10/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_10/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.859457 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_10/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_10/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.863584 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_10/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_10/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.867732 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_10/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_10/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.871820 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_10/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_10/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.876084 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_10/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_10/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.880317 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_10/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_10/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.884539 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_10/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_10/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.888757 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_10/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_10/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.892951 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_10/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_10/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_11/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.897674 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_11/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_11/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.901849 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_11/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_11/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.906060 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_11/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_11/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.910279 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_11/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_11/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.914448 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_11/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_11/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.918740 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_11/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_11/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.922875 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_11/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_11/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.926982 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_11/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_11/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.931231 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_11/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_11/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.935446 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_11/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_11/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.939659 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_11/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_11/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.944442 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_11/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_11/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.948656 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_11/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_11/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.952799 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_11/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_11/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.956982 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_11/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_11/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.961359 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_11/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_11/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_2/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.965526 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_2/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_2/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.969733 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_2/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_2/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.973926 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_2/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_2/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.978046 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_2/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_2/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.982301 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_2/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_2/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.986449 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_2/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_2/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.990775 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_2/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_2/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.994936 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_2/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_2/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:01.999149 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_2/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_2/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.003510 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_2/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_2/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.007835 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_2/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_2/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.012063 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_2/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_2/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.016313 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_2/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_2/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.020421 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_2/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_2/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.025134 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_2/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_2/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.029308 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_2/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_2/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_3/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.033693 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_3/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_3/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.037995 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_3/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_3/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.042158 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_3/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_3/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.046391 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_3/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_3/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.050492 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_3/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_3/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.054674 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_3/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_3/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.058791 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_3/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_3/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.062982 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_3/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_3/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.067209 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_3/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_3/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.071374 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_3/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_3/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.075625 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_3/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_3/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.079769 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_3/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_3/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.084141 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_3/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_3/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.088245 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_3/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_3/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.092396 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_3/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_3/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.096782 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_3/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_3/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_4/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.100889 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_4/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_4/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.105139 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_4/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_4/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.109291 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_4/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_4/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.113453 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_4/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_4/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.117863 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_4/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_4/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.122206 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_4/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_4/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.126414 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_4/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_4/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.130603 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_4/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_4/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.134860 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_4/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_4/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.139083 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_4/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_4/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.143427 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_4/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_4/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.148245 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_4/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_4/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.152436 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_4/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_4/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.156611 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_4/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_4/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.160823 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_4/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_4/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.165122 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_4/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_4/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_5/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.169361 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_5/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_5/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.173632 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_5/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_5/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.177822 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_5/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_5/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.182038 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_5/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_5/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.186323 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_5/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_5/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.190583 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_5/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_5/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.194739 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_5/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_5/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.198952 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_5/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_5/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.203202 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_5/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_5/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.207502 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_5/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_5/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.211715 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_5/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_5/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.215850 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_5/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_5/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.220119 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_5/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_5/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.224294 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_5/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_5/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.228462 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_5/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_5/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.232830 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_5/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_5/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_6/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.237343 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_6/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_6/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.241650 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_6/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_6/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.245864 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_6/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_6/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.250160 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_6/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_6/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.254351 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_6/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_6/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.258504 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_6/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_6/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.262754 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_6/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_6/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.267041 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_6/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_6/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.271315 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_6/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_6/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.276142 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_6/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_6/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.280368 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_6/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_6/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.284577 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_6/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_6/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.288729 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_6/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_6/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.293077 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_6/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_6/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.297461 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_6/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_6/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.302185 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_6/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_6/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_7/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.306872 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_7/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_7/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.311084 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_7/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_7/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.315371 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_7/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_7/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.319825 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_7/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_7/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.324229 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_7/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_7/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.328702 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_7/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_7/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.332975 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_7/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_7/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.337297 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_7/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_7/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.341648 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_7/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_7/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.346033 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_7/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_7/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.350328 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_7/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_7/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.354550 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_7/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_7/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.358890 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_7/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_7/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.363158 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_7/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_7/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.367405 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_7/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_7/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.371756 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_7/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_7/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_8/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.376094 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_8/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_8/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.380453 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_8/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_8/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.384670 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_8/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_8/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.389011 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_8/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_8/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.393281 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_8/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_8/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.397498 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_8/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_8/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.402280 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_8/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_8/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.406552 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_8/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_8/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.410729 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_8/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_8/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.415194 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_8/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_8/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.419643 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_8/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_8/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.424293 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_8/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_8/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.428758 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_8/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_8/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.433537 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_8/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_8/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.438342 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_8/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_8/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.442920 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_8/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_8/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_9/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.447552 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_9/attention/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_9/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.452166 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_9/attention/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_9/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.456691 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_9/attention/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_9/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.461296 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_9/attention/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_9/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.465883 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_9/attention/self/key/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/self/key/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_9/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.470563 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_9/attention/self/key/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/self/key/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_9/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.475167 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_9/attention/self/query/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/self/query/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_9/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.479804 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_9/attention/self/query/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/self/query/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_9/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.484305 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_9/attention/self/value/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/self/value/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_9/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.488793 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_9/attention/self/value/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/attention/self/value/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_9/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.493527 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_9/intermediate/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/intermediate/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_9/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.498171 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_9/intermediate/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/intermediate/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_9/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.502540 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_9/output/LayerNorm/beta:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/output/LayerNorm/beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_9/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.507166 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_9/output/LayerNorm/gamma:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/output/LayerNorm/gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_9/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/output/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.511519 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_9/output/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/output/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/encoder/layer_9/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/output/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.516061 140073664845568 tf_logging.py:115] Initialize variable bert/encoder/layer_9/output/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/encoder/layer_9/output/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/pooler/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/pooler/dense/bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.520589 140073664845568 tf_logging.py:115] Initialize variable bert/pooler/dense/bias:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/pooler/dense/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable bert/pooler/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/pooler/dense/kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.525222 140073664845568 tf_logging.py:115] Initialize variable bert/pooler/dense/kernel:0 from checkpoint models/model_repo/uncased_L-12_H-768_A-12/bert_model.ckpt with bert/pooler/dense/kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:**** Trainable Variables ****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.526164 140073664845568 tf_logging.py:115] **** Trainable Variables ****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.527170 140073664845568 tf_logging.py:115]   name = bert/embeddings/word_embeddings:0, shape = (30522, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.528124 140073664845568 tf_logging.py:115]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.529153 140073664845568 tf_logging.py:115]   name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.530262 140073664845568 tf_logging.py:115]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.531181 140073664845568 tf_logging.py:115]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.532244 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.533319 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.534343 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.535312 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.536230 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.536995 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.537841 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.538618 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.539308 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.540124 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.541053 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.541759 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.542558 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.543318 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.544103 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.544832 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.545571 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.546484 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.547275 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.548244 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.551381 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.552272 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.553134 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.554117 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.554915 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.555810 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.556612 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.557341 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.558010 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.558753 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.559434 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.560103 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.560929 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.561709 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.562460 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.564049 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.564877 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.565604 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.566328 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.567117 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.567823 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.568732 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.569551 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.570449 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.571253 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.572009 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.572887 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.573761 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.574469 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.575267 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.575953 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.576720 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.577520 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.578364 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.579181 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.579913 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.580615 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.581397 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.582345 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.583143 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.583910 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.584702 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.585406 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.586179 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.586884 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.587634 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.588281 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.589178 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.589958 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.590827 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.591524 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.592386 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.593226 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.594078 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.594890 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.595637 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.596374 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.597135 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.597960 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.598851 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.599663 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.600482 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.601196 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.601906 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.602932 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.603922 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.604644 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.605372 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.606129 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.606894 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.607604 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.608612 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.609545 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.610294 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.611034 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.611722 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.612483 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.613228 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.613924 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.614617 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.615395 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.616097 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.617169 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.617865 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.618654 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.619365 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.620185 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.620843 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.621728 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.622545 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.623462 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.624177 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.625085 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.626238 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.627007 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.627899 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.628648 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.629431 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.630267 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.631096 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.631821 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.632722 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.633413 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.634238 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.634915 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.635617 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.636268 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.636991 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.637679 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.665893 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.667069 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.667973 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.668815 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.669752 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.670857 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.671605 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.672508 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.673374 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.674338 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.675136 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.675889 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.676608 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.677570 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.678286 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.679047 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.679711 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.680410 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.681222 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.682179 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.682956 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.683712 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.684358 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.685223 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.685953 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.686716 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.687503 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.688271 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.688968 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.689705 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.690527 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.691301 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.692031 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.692779 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.693522 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.694259 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.694964 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.695676 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.696331 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.697118 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.697925 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.698720 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.699507 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.700203 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.700954 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.701711 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.702448 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.703215 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.703876 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.704608 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.705339 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.706122 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.706861 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.707653 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.708301 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.709114 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.709885 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.710694 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.711335 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.712176 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.712937 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.713685 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.714505 140073664845568 tf_logging.py:115]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.715270 140073664845568 tf_logging.py:115]   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.715975 140073664845568 tf_logging.py:115]   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = cls/squad/output_weights:0, shape = (2, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.716804 140073664845568 tf_logging.py:115]   name = cls/squad/output_weights:0, shape = (2, 768)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = cls/squad/output_bias:0, shape = (2,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.717633 140073664845568 tf_logging.py:115]   name = cls/squad/output_bias:0, shape = (2,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:02.718617 140073664845568 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:03.467662 140073664845568 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from squad/output/jupyter/model.ckpt-21719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:03.472226 140073664845568 tf_logging.py:115] Restoring parameters from squad/output/jupyter/model.ckpt-21719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:03.937889 140073664845568 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:03.976104 140073664845568 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing example: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:04.580048 140073664845568 tf_logging.py:115] Processing example: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing example: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:13.970776 140073664845568 tf_logging.py:115] Processing example: 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing example: 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:23.394426 140073664845568 tf_logging.py:115] Processing example: 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing example: 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:32.856932 140073664845568 tf_logging.py:115] Processing example: 3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing example: 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:42.339996 140073664845568 tf_logging.py:115] Processing example: 4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing example: 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:43:51.850759 140073664845568 tf_logging.py:115] Processing example: 5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing example: 6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:44:01.357291 140073664845568 tf_logging.py:115] Processing example: 6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing example: 7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:44:10.849937 140073664845568 tf_logging.py:115] Processing example: 7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing example: 8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:44:20.369075 140073664845568 tf_logging.py:115] Processing example: 8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing example: 9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:44:29.878819 140073664845568 tf_logging.py:115] Processing example: 9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing example: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:44:39.384795 140073664845568 tf_logging.py:115] Processing example: 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing example: 11000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:44:48.908746 140073664845568 tf_logging.py:115] Processing example: 11000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing example: 12000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:44:58.413126 140073664845568 tf_logging.py:115] Processing example: 12000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing predictions to: squad/output/jupyter/predictions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:45:00.546499 140073664845568 tf_logging.py:115] Writing predictions to: squad/output/jupyter/predictions.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing nbest to: squad/output/jupyter/nbest_predictions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0501 20:45:00.547411 140073664845568 tf_logging.py:115] Writing nbest to: squad/output/jupyter/nbest_predictions.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anmehra/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  flags.mark_flag_as_required(\"vocab_file\")\n",
    "  flags.mark_flag_as_required(\"bert_config_file\")\n",
    "  flags.mark_flag_as_required(\"output_dir\")\n",
    "  tf.app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# <span style=\"color:navy\"> Test Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Please check the bert_squad2.0_prediction.ipynb - Created seperate file to keep manage jupyter easily"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
